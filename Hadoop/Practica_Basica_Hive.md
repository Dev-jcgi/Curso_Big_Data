# ğŸš€ GuÃ­a Definitiva: Hadoop 3.4.0 + Hive 3.3.1

> **AnÃ¡lisis de Ventas con SoluciÃ³n Completa de Errores Comunes**

**Autor:** GuÃ­a PrÃ¡ctica Hadoop
**Fecha:** Febrero 2026
**Versiones:** Hadoop 3.4.0 | Hive 3.3.1 | Java 8

---

## ğŸ› ï¸ PASO 0: SoluciÃ³n de Errores al Ejecutar Hive con Hadoop

> âš ï¸ **IMPORTANTE:** Esta secciÃ³n resuelve todos los problemas comunes que bloquean Hive

â±ï¸ **Tiempo estimado:** 5-10 minutos

### ğŸ“Œ Problemas que Resolveremos:

| # | Error                            | SoluciÃ³n                     |
| - | -------------------------------- | ----------------------------- |
| 1 | Java 17 incompatible             | Forzar Java 8                 |
| 2 | "Permission denied: user=dr.who" | Configurar usuario web        |
| 3 | "Return Code 2"                  | Configurar MapReduce con YARN |
| 4 | Permisos HDFS insuficientes      | Limpiar y configurar permisos |

---

### Paso 1: Crear hive-env.sh desde la Plantilla

```bash
# Crear archivo de configuraciÃ³n de Hive desde template
cp /opt/hive/conf/hive-env.sh.template /opt/hive/conf/hive-env.sh
```

---

### Paso 2: Editar Archivos de Entorno

#### ğŸ”§ Configurar Variables de Entorno en Hive

**Archivo:** `/opt/hive/conf/hive-env.sh`

```bash
# Editar el archivo con nano o vim
nano /opt/hive/conf/hive-env.sh

# Agregar o verificar estas lÃ­neas al final:
export JAVA_HOME=/opt/jdk1.8.0_202
export HADOOP_HOME=/opt/hadoop/hadoop-3.4.0
export HIVE_HOME=/opt/hive
```

> **ğŸ“ Nota:** Guarda los cambios (Ctrl+O, Enter, Ctrl+X en nano)

---

### Paso 3: Verificar Variables de Entorno

```bash
# Verificar que las variables estÃ©n configuradas correctamente
echo $JAVA_HOME
# Esperado: /opt/jdk1.8.0_202

echo $HADOOP_HOME
# Esperado: /opt/hadoop/hadoop-3.4.0

echo $HIVE_HOME
# Esperado: /opt/hive
```

---

### Paso 4: Configurar MapReduce (mapred-site.xml)

#### ğŸ”§ Configurar Framework MapReduce con YARN

**Archivo:** `/opt/hadoop/hadoop-3.4.0/etc/hadoop/mapred-site.xml`

```bash
# Abrir archivo de configuraciÃ³n
sudo nano /opt/hadoop/hadoop-3.4.0/etc/hadoop/mapred-site.xml
```

**Agregar dentro de `<configuration>`:**

```xml
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
<property>
    <name>mapreduce.application.classpath</name>
    <value>$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*</value>
</property>
```

**ğŸ’¡ ExplicaciÃ³n:** Configura MapReduce para ejecutarse sobre YARN (Resource Manager) en lugar de modo local, evitando errores "Return Code 2".

---

### Paso 5: Configurar Usuario Web (core-site.xml)

#### ğŸ”§ Evitar Error "dr.who"

**Archivo:** `/opt/hadoop/hadoop-3.4.0/etc/hadoop/core-site.xml`

```bash
# Abrir archivo de configuraciÃ³n
sudo nano /opt/hadoop/hadoop-3.4.0/etc/hadoop/core-site.xml
```

**Agregar dentro de `<configuration>`:**

```xml
<property>
    <name>hadoop.http.staticuser.user</name>
    <value>hadoop</value>
    <description>Usuario para interfaz web HDFS - Evita error dr.who</description>
</property>
```

**ğŸ’¡ ExplicaciÃ³n:** Por defecto, Hadoop usa el usuario ficticio "dr.who" para la interfaz web, causando errores de permisos. Esta configuraciÃ³n fuerza el uso del usuario real (hadoop) para todas las operaciones web.

---

### Paso 6: Limpiar Permisos de Carpetas Temporales

> **âš ï¸ ADVERTENCIA:** Este comando eliminarÃ¡ TODOS los archivos en HDFS. Solo ejecutar en ambiente de desarrollo/prueba.

```bash
# Limpiar filesystem HDFS (elimina todo)
hdfs dfs -rm -r /
```

**ğŸ’¡ ExplicaciÃ³n:** Elimina archivos corruptos o con permisos incorrectos. En producciÃ³n, usar comandos mÃ¡s especÃ­ficos.

---

### Paso 7: Reiniciar Servicios Hadoop

#### ğŸ”„ Detener Todos los Servicios

```bash
# Detener HDFS, YARN y todos los servicios
stop-all.sh
```

#### ğŸš€ Iniciar HDFS

```bash
# Iniciar NameNode, DataNode y SecondaryNameNode
start-dfs.sh
```

#### ğŸš€ Iniciar YARN

```bash
# Iniciar ResourceManager y NodeManager
start-yarn.sh
```

#### âœ… Verificar Servicios Activos

```bash
# Verificar que todos los servicios estÃ©n corriendo
jps
```

**Salida esperada:**

```
12345 NameNode
12346 DataNode
12347 ResourceManager
12348 NodeManager
12349 SecondaryNameNode
12350 Jps
```

> **ğŸ’¡ Nota:** Los nÃºmeros de proceso (PIDs) variarÃ¡n. Lo importante es que aparezcan los 5 servicios principales.

---

### Paso 8: Configurar Permisos HDFS (DespuÃ©s del Reinicio)

```bash
# Dar permisos completos al filesystem HDFS
hdfs dfs -chmod -R 777 /

# Crear directorio staging para YARN
hdfs dfs -mkdir -p /tmp/hadoop-yarn/staging
hdfs dfs -chmod -R 777 /tmp/hadoop-yarn/staging
```

**ğŸ’¡ ExplicaciÃ³n:** YARN necesita permisos de escritura en `/tmp/hadoop-yarn/staging` para almacenar archivos temporales de jobs MapReduce.

**âœ… Verificar estructura creada:**

```bash
hdfs dfs -ls /
hdfs dfs -ls /tmp/hadoop-yarn/
```

---

### Paso 9: Conectar a Hive

```bash
# Conectar a Hive directamente (abre la terminal interactiva)
hive
```

**âœ… Verificar conexiÃ³n:**

```sql
-- Dentro de Hive, ejecutar:
SHOW DATABASES;
```

**Salida esperada:**

```
OK
default
Time taken: 0.5 seconds, Fetched: 1 row(s)
```

---

### ğŸ‰ ConfiguraciÃ³n Completa

Si todos los pasos anteriores se ejecutaron correctamente, deberÃ­as tener:

âœ… Variables de entorno configuradas (Java 8, Hadoop, Hive)
âœ… MapReduce configurado para ejecutarse con YARN
âœ… Usuario web de Hadoop configurado correctamente
âœ… Servicios Hadoop y YARN corriendo
âœ… Permisos HDFS configurados
âœ… Hive conectado y funcionando

Ahora puedes proceder a cargar datos y ejecutar consultas sin errores.

---

## ğŸ“Š PASO 1: Cargar Datos en HDFS

â±ï¸ **Tiempo estimado:** 1 minuto

### 1.1 Crear Directorio en HDFS

```bash
# Crear directorio para almacenar los datos de ventas
hdfs dfs -mkdir -p /demo/ventas
```

**âœ… Verificar creaciÃ³n:**

```bash
hdfs dfs -ls /demo
```

**Salida esperada:**

```
drwxr-xr-x   - hadoop supergroup          0 2026-02-01 10:00 /demo/ventas
```

### 1.2 Cargar Dataset Directamente

> **Nota:** Los datos se cargan desde STDIN sin archivo intermedio

```bash
hdfs dfs -put - /demo/ventas/datos.txt << 'EOF'
1001	Laptop	Dell	1200	2024-01-15	Norte
1002	Mouse	Logitech	25	2024-01-15	Sur
1003	Teclado	HP	45	2024-01-16	Este
1004	Monitor	Samsung	350	2024-01-16	Norte
1005	Laptop	HP	1100	2024-01-17	Oeste
1006	Mouse	Dell	30	2024-01-17	Norte
1007	Teclado	Logitech	50	2024-01-18	Sur
1008	Monitor	LG	400	2024-01-18	Este
1009	Laptop	Lenovo	1300	2024-01-19	Norte
1010	Mouse	HP	20	2024-01-19	Sur
1011	Teclado	Dell	40	2024-01-20	Oeste
1012	Monitor	Dell	380	2024-01-20	Norte
1013	Laptop	Asus	1250	2024-01-21	Este
1014	Mouse	Lenovo	28	2024-01-21	Norte
1015	Teclado	Samsung	42	2024-01-22	Sur
EOF
```

### 1.3 Verificar Datos Cargados

```bash
# Ver contenido completo del archivo
hdfs dfs -cat /demo/ventas/datos.txt

# Contar lÃ­neas (debe mostrar 15)
hdfs dfs -cat /demo/ventas/datos.txt | wc -l

# Ver primeras 5 lÃ­neas
hdfs dfs -cat /demo/ventas/datos.txt | head -5
```

**âœ… VerificaciÃ³n de integridad:**

```bash
# Confirmar que hay exactamente 15 registros
hdfs dfs -cat /demo/ventas/datos.txt | wc -l
# Salida esperada: 15
```

### ğŸ“‹ Estructura del Dataset

| Campo        | Tipo   | DescripciÃ³n            | Ejemplo    |
| ------------ | ------ | ----------------------- | ---------- |
| `id`       | INT    | Identificador Ãºnico    | 1001       |
| `producto` | STRING | CategorÃ­a del producto | Laptop     |
| `marca`    | STRING | Fabricante              | Dell       |
| `precio`   | DOUBLE | Precio en USD           | 1200       |
| `fecha`    | STRING | Fecha de venta          | 2024-01-15 |
| `region`   | STRING | Zona geogrÃ¡fica        | Norte      |

**Total de registros:** 15

---

## ğŸ PASO 2: EjecuciÃ³n de Consultas (Hive)

â±ï¸ **Tiempo estimado:** 5 minutos

---

### 2.1 âš ï¸ CONFIGURACIÃ“N OBLIGATORIA (Evitar "Return Code 2")

> **CRÃTICO:** Ejecutar estos comandos ANTES de cualquier consulta

```sql
-- Deshabilitar modo de ejecuciÃ³n local
SET hive.exec.mode.local.auto=false;

-- Forzar uso de YARN para MapReduce
SET mapreduce.framework.name=yarn;
```

**ğŸ’¡ ExplicaciÃ³n:**

- Sin estos comandos, Hive intenta ejecutar queries en memoria local
- Esto causa "Return Code 2" en consultas con GROUP BY
- Forzamos que YARN distribuya el trabajo correctamente

---

### 2.2 Crear Base de Datos y Tabla

#### Paso 1: Crear Base de Datos

```sql
CREATE DATABASE IF NOT EXISTS tienda;
USE tienda;
```

#### Paso 2: Crear Tabla Externa

```sql
CREATE EXTERNAL TABLE ventas (
    id INT,
    producto STRING,
    marca STRING,
    precio DOUBLE,
    fecha STRING,
    region STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE
LOCATION '/demo/ventas/';
```

#### Paso 3: Verificar Tabla

```sql
-- Ver estructura de la tabla
DESCRIBE ventas;
```

**Salida esperada:**

```
id                      int
producto                string
marca                   string
precio                  double
fecha                   string
region                  string
```

```sql
-- Ver primeros 5 registros
SELECT * FROM ventas LIMIT 5;
```

**Salida esperada:**

```
1001  Laptop   Dell      1200.0  2024-01-15  Norte
1002  Mouse    Logitech  25.0    2024-01-15  Sur
1003  Teclado  HP        45.0    2024-01-16  Este
1004  Monitor  Samsung   350.0   2024-01-16  Norte
1005  Laptop   HP        1100.0  2024-01-17  Oeste
```

```sql
-- Contar registros totales (debe ser 15)
SELECT COUNT(*) as total FROM ventas;
```

**Salida esperada:**

```
total
15
```

---

### 2.3 Consulta Principal: AgregaciÃ³n de Ventas

#### ğŸ“ SQL:

```sql
SELECT 
    producto,
    COUNT(*) as cantidad_vendida,
    ROUND(SUM(precio), 2) as total_ingresos,
    ROUND(AVG(precio), 2) as precio_promedio
FROM ventas
GROUP BY producto
ORDER BY total_ingresos DESC;
```

#### ğŸ“Š Resultado Esperado:

| producto | cantidad_vendida | total_ingresos | precio_promedio |
| -------- | ---------------- | -------------- | --------------- |
| Laptop   | 4                | 4850.00        | 1212.50         |
| Monitor  | 3                | 1130.00        | 376.67          |
| Teclado  | 4                | 177.00         | 44.25           |
| Mouse    | 4                | 103.00         | 25.75           |

#### ğŸ¯ Flujo MapReduce:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT (HDFS)â”‚  15 registros en /demo/ventas/datos.txt
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  (Datos distribuidos en bloques)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MAPPER PHASE    â”‚  Lee datos en paralelo y emite pares <producto, precio>
â”‚   (Map Task)     â”‚  Ejemplo: "Laptop" â†’ ("Laptop", 1200)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SHUFFLE & SORT   â”‚  Agrupa todos los valores por clave (producto)
â”‚  (Framework)     â”‚  Ejemplo: "Laptop" â†’ [1200, 1100, 1300, 1250]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REDUCER PHASE    â”‚  Calcula agregaciones: COUNT, SUM, AVG
â”‚  (Reduce Task)   â”‚  Ejemplo: Laptop â†’ count=4, sum=4850, avg=1212.50
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚OUTPUT (HDFS)â”‚  4 filas con resultados agregados y ordenados
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ’¡ Concepto Big Data:**

- Esta consulta ejecuta **1 Job MapReduce** gestionado por YARN
- Los datos se procesan de forma **distribuida** y **paralela** entre mÃºltiples nodos
- El framework maneja automÃ¡ticamente la distribuciÃ³n, fallos y optimizaciÃ³n

---

## ğŸ” PASO 3: Monitoreo y Resultados

â±ï¸ **Tiempo:** Continuo durante ejecuciÃ³n

### 3.1 Interfaces Web de Monitoreo

| Servicio                        | URL                                           | InformaciÃ³n Visible                       |
| ------------------------------- | --------------------------------------------- | ------------------------------------------ |
| **YARN Resource Manager** | [http://localhost:8088](http://localhost:8088)   | Jobs MapReduce, Mappers, Reducers, Memoria |
| **HDFS NameNode**         | [http://localhost:9870](http://localhost:9870)   | Explorador de archivos, Bloques, Nodos     |
| **Job History Server**    | [http://localhost:19888](http://localhost:19888) | Historial de jobs completados              |

### 3.2 Monitoreo desde Terminal

#### Ver aplicaciones YARN activas:

```bash
# Listar aplicaciones en ejecuciÃ³n
watch -n 2 'yarn application -list'

# Ver estado de una aplicaciÃ³n especÃ­fica
yarn application -status application_1234567890_0001
```

#### Ver logs de aplicaciones YARN:

```bash
# Logs de una aplicaciÃ³n especÃ­fica (reemplazar con ID real)
yarn logs -applicationId application_1234567890_0001

# Ver logs de la Ãºltima aplicaciÃ³n ejecutada
yarn logs -applicationId $(yarn application -list -appStates FINISHED | tail -1 | awk '{print $1}')
```

### 3.3 MÃ©tricas a Observar

#### âœ… **En YARN Web UI (http://localhost:8088):**

| MÃ©trica                 | UbicaciÃ³n                       | QuÃ© observar                              |
| ------------------------ | -------------------------------- | ------------------------------------------ |
| **Jobs MapReduce** | Applications â†’ Running          | Estado de ejecuciÃ³n en tiempo real        |
| **Mappers**        | Application Details â†’ Tasks     | NÃºmero de map tasks (tÃ­picamente 1-4)    |
| **Reducers**       | Application Details â†’ Tasks     | NÃºmero de reduce tasks (tÃ­picamente 1-2) |
| **Memoria**        | Application Details â†’ Resources | RAM consumida vs disponible                |
| **Progreso**       | Application Progress             | % Map â†’ % Shuffle â†’ % Reduce             |
| **Estado Final**   | Application State                | RUNNING â†’ SUCCEEDED (o FAILED)            |

#### âœ… **En HDFS Web UI (http://localhost:9870):**

| MÃ©trica               | UbicaciÃ³n          | QuÃ© observar                       |
| ---------------------- | ------------------- | ----------------------------------- |
| **Archivos**     | Utilities â†’ Browse | Navegar a /demo/ventas/datos.txt    |
| **Bloques**      | File Details        | NÃºmero de bloques y ubicaciÃ³n     |
| **ReplicaciÃ³n** | File Details        | Factor de replicaciÃ³n (default: 3) |
| **DataNodes**    | Datanodes Tab       | Nodos activos y capacidad           |
| **Espacio**      | Overview            | Capacidad usada/disponible          |

---

## ğŸ“¤ PASO 4: Exportar Resultados

â±ï¸ **Tiempo estimado:** 1 minuto

### 4.1 Exportar a Directorio Local (CSV)

> **ğŸ“Œ PropÃ³sito:** Guardar resultados en el sistema de archivos local para anÃ¡lisis externo

#### En Hive:

```sql
INSERT OVERWRITE LOCAL DIRECTORY '/tmp/resumen_ventas'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
SELECT 
    producto,
    COUNT(*) as cantidad,
    ROUND(SUM(precio), 2) as total
FROM ventas
GROUP BY producto
ORDER BY total DESC;
```

**ğŸ’¡ Nota:** El keyword `LOCAL` hace que Hive escriba en el filesystem local, no en HDFS.

#### En Terminal:

```bash
# Ver resultados
cat /tmp/resumen_ventas/000000_0

# O con formato:
column -t -s',' /tmp/resumen_ventas/000000_0
```

### 4.2 Exportar a HDFS (para compartir)

> **ğŸ“Œ PropÃ³sito:** Guardar resultados en HDFS para compartir con otros usuarios o procesos

#### En Hive:

```sql
INSERT OVERWRITE DIRECTORY '/demo/resultados/por_producto'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
SELECT 
    producto,
    COUNT(*) as cantidad,
    ROUND(SUM(precio), 2) as total
FROM ventas
GROUP BY producto
ORDER BY total DESC;
```

**ğŸ’¡ Nota:** Sin `LOCAL`, Hive escribe directamente en HDFS. Los resultados serÃ¡n accesibles desde cualquier nodo del cluster.

#### En Terminal:

```bash
# Ver resultado en HDFS
hdfs dfs -cat /demo/resultados/por_producto/*

# Descargar localmente (especificar ruta absoluta)
hdfs dfs -get /demo/resultados/por_producto/000000_0 /home/hadoop/resumen.csv

# Ver contenido del archivo descargado
cat /home/hadoop/resumen.csv
```

---

## ğŸ§¹ LIMPIEZA (Opcional)

â±ï¸ **Tiempo estimado:** 2 minutos

> **âš ï¸ Advertencia:** Solo ejecutar despuÃ©s de completar toda la prÃ¡ctica

---

### Detener Servicios

```bash
# 1. Salir de Hive (si estÃ¡s dentro de la sesiÃ³n interactiva)
quit;

# 2. Detener servicios individualmente
stop-yarn.sh     # Detiene ResourceManager y NodeManager
stop-dfs.sh      # Detiene NameNode, DataNode, SecondaryNameNode

# O detener todo a la vez (alternativa)
stop-all.sh
```

**âœ… Verificar detenciÃ³n:**

```bash
jps
# Solo debe aparecer: Jps
```

---

### Limpiar Datos

#### En Hive:

```sql
-- Eliminar tabla
DROP TABLE IF EXISTS ventas;

-- Eliminar base de datos
DROP DATABASE IF EXISTS tienda;

-- Salir
quit;
```

#### En Terminal:

```bash
# Eliminar datos en HDFS
hdfs dfs -rm -r /demo/

# Eliminar resultados locales exportados
hdfs dfs -rm -r /tmp/resumen_ventas/

# Limpiar archivos locales
rm -rf /tmp/resumen_ventas/
rm -f /home/hadoop/resumen.csv
```

---

## ğŸ“– CONSULTAS ADICIONALES (Bonus)

> **ğŸ¯ Objetivo:** Estas consultas demuestran capacidades avanzadas de Hive y patrones de anÃ¡lisis comunes en Big Data

> **ğŸ“ Requisitos:** Ejecutar despuÃ©s del PASO 3 (tabla `ventas` debe existir)

---

### âœ… Consulta 2: Ventas por regiÃ³n

```sql
SELECT 
    region,
    COUNT(*) as num_ventas,
    ROUND(SUM(precio), 2) as ingresos_totales,
    ROUND(AVG(precio), 2) as ticket_promedio
FROM ventas
GROUP BY region
ORDER BY ingresos_totales DESC;
```

**Resultado esperado:**

```
Norte    7    3653.00    521.86
Este     3    1795.00    598.33
Sur      3     117.00     39.00
Oeste    2    1185.00    592.50
```

---

### âœ… Consulta 3: Marca mÃ¡s vendida por producto

**ğŸ“Š PropÃ³sito:** AnÃ¡lisis multi-dimensional (producto + marca)

```sql
SELECT 
    producto,
    marca,
    COUNT(*) as ventas,
    ROUND(SUM(precio), 2) as ingresos
FROM ventas
GROUP BY producto, marca
ORDER BY producto, ventas DESC;
```

**ğŸ¯ Concepto:** El `GROUP BY` con mÃºltiples columnas crea subcategorÃ­as para anÃ¡lisis mÃ¡s detallado.

---

### âœ… Consulta 4: AnÃ¡lisis temporal (por fecha)

**ğŸ“Š PropÃ³sito:** Identificar tendencias diarias de ventas

```sql
SELECT 
    fecha,
    COUNT(*) as ventas_dia,
    ROUND(SUM(precio), 2) as ingresos_dia,
    COUNT(DISTINCT producto) as productos_diferentes
FROM ventas
GROUP BY fecha
ORDER BY fecha;
```

---

### âœ… Consulta 5: Top productos mÃ¡s caros

**ğŸ“Š PropÃ³sito:** Filtrado y ranking de registros individuales

```sql
SELECT 
    producto,
    marca,
    precio,
    region,
    fecha
FROM ventas
WHERE precio > 100
ORDER BY precio DESC
LIMIT 10;
```

**ğŸ¯ Concepto:** Esta consulta NO usa MapReduce (no hay GROUP BY), se ejecuta mÃ¡s rÃ¡pido como simple filtrado.

---

### âœ… Consulta 6: EstadÃ­sticas avanzadas

```sql
SELECT 
    producto,
    COUNT(*) as cantidad,
    MIN(precio) as precio_min,
    MAX(precio) as precio_max,
    ROUND(AVG(precio), 2) as precio_prom,
    ROUND(STDDEV(precio), 2) as desviacion,
    PERCENTILE_APPROX(precio, 0.5) as mediana
FROM ventas
GROUP BY producto
ORDER BY cantidad DESC;
```

**ğŸ¯ Concepto:** Las funciones estadÃ­sticas (AVG, STDDEV, PERCENTILE) se calculan **distribuidas** entre mÃºltiples reducers.

---

### âœ… Consulta 7: Crear tabla de resumen (para reusar)

**ğŸ“Š PropÃ³sito:** Materializar resultados para consultas futuras mÃ¡s rÃ¡pidas

```sql
-- Crear tabla con resultados agregados (CTAS: Create Table As Select)
CREATE TABLE resumen_ventas AS
SELECT 
    producto,
    COUNT(*) as cantidad,
    ROUND(SUM(precio), 2) as ingresos,
    ROUND(AVG(precio), 2) as precio_prom
FROM ventas
GROUP BY producto;

-- Ver resultados
SELECT * FROM resumen_ventas;

-- Esta tabla ahora estÃ¡ en HDFS y se puede consultar rÃ¡pidamente sin re-calcular
DESCRIBE FORMATTED resumen_ventas;
```

**ğŸ¯ Concepto:** Las tablas materializadas son una tÃ©cnica de optimizaciÃ³n comÃºn en Big Data. Ejecutas el cÃ¡lculo costoso una vez y reutilizas los resultados.

---

### âœ… Consulta 8: Filtrado con HAVING

**ğŸ“Š PropÃ³sito:** Filtrar DESPUÃ‰S de la agregaciÃ³n (diferente a WHERE)

```sql
-- Solo productos con mÃ¡s de 2 ventas
SELECT 
    producto,
    marca,
    COUNT(*) as ventas,
    ROUND(AVG(precio), 2) as precio_prom
FROM ventas
GROUP BY producto, marca
HAVING COUNT(*) >= 2
ORDER BY ventas DESC;
```

**ğŸ¯ Concepto:**

- `WHERE` filtra **antes** de agrupar (filas individuales)
- `HAVING` filtra **despuÃ©s** de agrupar (grupos completos)
- En este caso, eliminamos combinaciones producto-marca con menos de 2 ventas

---

## ğŸ“š RESUMEN DE SOLUCIONES

> **ğŸ¯ Referencia RÃ¡pida:** Usa esta secciÃ³n como troubleshooting guide cuando encuentres errores

---

### âœ… Errores Resueltos

| # | Error Original                   | Causa RaÃ­z                                              | SoluciÃ³n Aplicada                                                  |
| - | -------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------------- |
| 1 | Java 17 causa fallos             | Incompatibilidad de bytecode con bibliotecas Hadoop/Hive | Forzar Java 8 en `hadoop-env.sh` y `hive-env.sh`                |
| 2 | "Permission denied: user=dr.who" | Usuario ficticio default en web UI                       | Agregar `hadoop.http.staticuser.user=hadoop` en `core-site.xml` |
| 3 | "Return Code 2" en queries       | Hive intenta ejecuciÃ³n local en lugar de YARN           | `SET hive.exec.mode.local.auto=false` antes de consultas          |
| 4 | Permisos en staging              | Directorio temporal sin permisos de escritura            | `hdfs dfs -chmod -R 777 /tmp/hadoop-yarn/staging`                 |

### ğŸ¯ Comandos Clave

> **ğŸ“ Cheat Sheet:** Comandos esenciales para ejecuciÃ³n rÃ¡pida

---

#### Inicio RÃ¡pido:

```bash
# 1. Iniciar servicios Hadoop (HDFS + YARN)
start-dfs.sh && start-yarn.sh

# 2. Verificar servicios (deben aparecer 5-6 procesos)
jps

# 3. Configurar permisos HDFS (solo la primera vez)
hdfs dfs -chmod -R 777 /
hdfs dfs -mkdir -p /tmp/hadoop-yarn/staging
hdfs dfs -chmod -R 777 /tmp/hadoop-yarn/staging
```

#### Conectar a Hive:

```bash
# Conectar directamente a Hive
hive
```

#### ConfiguraciÃ³n Obligatoria en Hive:

> **âš ï¸ EJECUTAR SIEMPRE antes de cualquier consulta con GROUP BY**

```sql
SET hive.exec.mode.local.auto=false;
SET mapreduce.framework.name=yarn;
```

#### Monitoreo:

```bash
# Ver aplicaciones YARN en ejecuciÃ³n (actualiza cada 2 segundos)
watch -n 2 'yarn application -list'

# Acceder a interfaces web
# YARN Resource Manager (jobs MapReduce):
http://localhost:8088

# HDFS NameNode (explorador de archivos):
http://localhost:9870

# Job History Server (historial):
http://localhost:19888
```

### ğŸ“Š Resultado Final

**Lo que has logrado en esta prÃ¡ctica:**

âœ… Dataset de 15 ventas cargado en HDFS distribuido
âœ… Tabla Hive externa creada y vinculada a datos HDFS
âœ… Consulta principal con GROUP BY ejecutada vÃ­a MapReduce en YARN
âœ… 7 consultas adicionales con anÃ¡lisis avanzados (agregaciones, estadÃ­sticas, filtros)
âœ… Resultados exportados a CSV local y HDFS
âœ… Todos los errores comunes diagnosticados y resueltos

**Conceptos de Big Data demostrados:**
ğŸ“Š Procesamiento distribuido con MapReduce
ğŸ“Š Almacenamiento en HDFS con replicaciÃ³n
ğŸ“Š GestiÃ³n de recursos con YARN
ğŸ“Š SQL sobre datos distribuidos (Hive)
ğŸ“Š Monitoreo de jobs en tiempo real

---

## ğŸ”— RECURSOS ADICIONALES

### ğŸ“š DocumentaciÃ³n Oficial:

| Recurso                            | DescripciÃ³n                                | URL                                                                                         |
| ---------------------------------- | ------------------------------------------- | ------------------------------------------------------------------------------------------- |
| **Hadoop 3.4.0 Docs**        | GuÃ­a completa de configuraciÃ³n y comandos | https://hadoop.apache.org/docs/r3.4.0/                                                      |
| **Hive Language Manual**     | Referencia de HiveQL (DDL, DML, funciones)  | https://cwiki.apache.org/confluence/display/Hive/LanguageManual                             |
| **YARN ResourceManager API** | API REST para monitoreo programmÃ¡tico      | https://hadoop.apache.org/docs/r3.4.0/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html |
| **HDFS Commands Guide**      | Comandos completos de HDFS shell            | https://hadoop.apache.org/docs/r3.4.0/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html     |

### ğŸ’» Herramientas de Monitoreo:

| Interfaz                        | Puerto | PropÃ³sito                                                    | URL                    |
| ------------------------------- | ------ | ------------------------------------------------------------- | ---------------------- |
| **YARN Resource Manager** | 8088   | Monitorear jobs MapReduce, estado de cluster, uso de recursos | http://localhost:8088  |
| **HDFS NameNode**         | 9870   | Explorar archivos HDFS, ver bloques, estado de DataNodes      | http://localhost:9870  |
| **Job History Server**    | 19888  | Ver historial completo de jobs finalizados con logs           | http://localhost:19888 |

> **ğŸ’¡ Tip:** Accede a estas URLs mientras ejecutas consultas para ver el procesamiento en tiempo real

---

<div align="center">

## ğŸ‰ Â¡PrÃ¡ctica Completada!

**Hadoop 3.4.0 + Hive 3.3.1 funcionando correctamente**

âœ… MapReduce distribuido con YARN
âœ… SQL sobre Big Data con Hive
âœ… Todos los errores comunes resueltos
âœ… Monitoreo y debugging configurado

---

### ğŸ“ˆ PrÃ³ximos Pasos

**Nivel Intermedio:**

- Particionamiento de tablas Hive (`PARTITIONED BY`)
- Bucketing para optimizaciÃ³n (`CLUSTERED BY`)
- Joins entre mÃºltiples tablas
- UDFs (User Defined Functions)

**Nivel Avanzado:**

- IntegraciÃ³n con Spark SQL
- Compresiones (Snappy, ORC, Parquet)
- Hive en cluster multi-nodo
- Tuning de MapReduce (memoria, paralelismo)

---

*GuÃ­a creada en Febrero 2026*
*VersiÃ³n: 1.0 - Completa y probada*

</div>

# üé¨ Gu√≠a Pr√°ctica: Hadoop 3.4.0 + Hive 3.3.1 con Dataset MovieLens

> **An√°lisis de Ratings de Pel√≠culas con 100,000 Registros Reales**

**Autor:** Gu√≠a de Estudio Big Data
**Fecha:** Febrero 2026
**Versiones:** Hadoop 3.4.0 | Hive 3.3.1 | Java 8
**Dataset:** MovieLens 100K (943 usuarios, 1682 pel√≠culas, 100,000 ratings)

---

## üìã CONTENIDO

1. [Iniciar Servicios Hadoop y YARN](#-paso-0-iniciar-servicios-hadoop-y-yarn)
2. [Cargar Dataset desde Archivo .data](#-paso-1-cargar-dataset-desde-archivo-data-a-hdfs)
3. [Crear Tablas y Consultas en Hive](#-paso-2-crear-base-de-datos-y-tablas-en-hive)
4. [Consultas Anal√≠ticas con MapReduce](#-paso-3-consultas-anal√≠ticas-con-mapreduce-yarn)
5. [Monitoreo de Jobs YARN](#-paso-4-monitoreo-de-jobs-yarn-y-mapreduce)
6. [Exportar Resultados](#-paso-5-exportar-resultados)
7. [Consultas Avanzadas Bonus](#-paso-6-consultas-avanzadas-bonus)

---

## üöÄ PASO 0: Iniciar Servicios Hadoop y YARN

‚è±Ô∏è **Tiempo estimado:** 1 minuto

### 0.1 Iniciar Todos los Servicios

```bash
# Iniciar HDFS y YARN simult√°neamente
start-all.sh

# Esperar 15 segundos a que todos los servicios inicien
sleep 15
```

> **üí° Comandos √∫tiles:**
> - **Iniciar todo:** `start-all.sh`
> - **Detener todo:** `stop-all.sh`

---

### 0.2 Verificar que Todos los Servicios Est√°n Activos

```bash
# Ver TODOS los servicios Java activos
jps
```

**‚úÖ Salida esperada:**

```
12345 NameNode
12346 DataNode
12347 SecondaryNameNode
12348 ResourceManager
12349 NodeManager
12350 Jps
```

**üí° Explicaci√≥n de los Servicios:**

| Servicio                    | Tipo      | Responsabilidad                                            |
| --------------------------- | --------- | ---------------------------------------------------------- |
| **NameNode**          | HDFS      | Administra metadatos (nombres, ubicaci√≥n de bloques)      |
| **DataNode**          | HDFS      | Almacena bloques de datos reales                           |
| **SecondaryNameNode** | HDFS      | Realiza checkpoints del NameNode                           |
| **ResourceManager**   | YARN      | Gestiona recursos del cluster (CPU, RAM) y distribuye jobs |
| **NodeManager**       | YARN      | Ejecuta contenedores con tasks MapReduce                   |

> **‚úÖ CHECKPOINT:** Si ves los 5 servicios, puedes continuar al siguiente paso.

---

### 0.3 Verificar Interfaces Web

**Abrir en el navegador:**

| Servicio                       | URL                    | Prop√≥sito                               |
| ------------------------------ | ---------------------- | ---------------------------------------- |
| **HDFS NameNode**        | http://localhost:9870  | Explorar archivos HDFS, ver bloques      |
| **YARN ResourceManager** | http://localhost:8088  | Monitorear jobs MapReduce en tiempo real |
| **Job History Server**   | http://localhost:19888 | Historial de jobs completados (opcional) |

**üí° Tip de Estudio:**
Deja estas pesta√±as abiertas durante toda la pr√°ctica para observar c√≥mo Hadoop procesa los datos en tiempo real.

---

## üìÅ PASO 1: Cargar Dataset desde Archivo .data a HDFS

‚è±Ô∏è **Tiempo estimado:** 3-5 minutos (depende del tama√±o del archivo)

---

### 1.1 Entender el Dataset MovieLens

**Dataset:** `u.data` - 100,000 ratings de pel√≠culas
**Usuarios:** 943
**Pel√≠culas:** 1682
**Formato:** Tab-separated values (TSV)

**Estructura de cada l√≠nea:**

```
user_id <TAB> movie_id <TAB> rating <TAB> timestamp
```

**Ejemplo real:**

```
196	242	3	881250949
186	302	3	891717742
22	377	1	878887116
```

**Interpretaci√≥n:**

- Usuario 196 calific√≥ la pel√≠cula 242 con 3 estrellas el 881250949 (Unix timestamp)
- Usuario 186 calific√≥ la pel√≠cula 302 con 3 estrellas
- Usuario 22 calific√≥ la pel√≠cula 377 con 1 estrella

---

### 1.2 Verificar que el Archivo Existe Localmente

```bash
# Navegar al directorio del dataset (ajusta la ruta seg√∫n tu caso)
cd /ruta/a/tu/dataset/ml-100k/

# Verificar que el archivo existe
ls -lh u.data

# Ver primeras 10 l√≠neas del archivo
head -10 u.data

# Contar total de l√≠neas (debe ser 100,000)
wc -l u.data
```

**‚úÖ Salida esperada:**

```
-rw-r--r-- 1 usuario grupo 1.9M Feb 01 10:00 u.data
100000 u.data
```

---

### 1.3 Crear Directorio en HDFS para el Dataset

```bash
# Crear estructura de directorios en HDFS
hdfs dfs -mkdir -p /datasets/movielens

# Verificar creaci√≥n
hdfs dfs -ls /datasets/
```

**‚úÖ Salida esperada:**

```
drwxrwxrwx   - hadoop supergroup          0 2026-02-01 10:15 /datasets/movielens
```

---

### 1.4 Cargar Archivo .data desde Sistema Local a HDFS

> **üéØ CONCEPTO CLAVE:** Este es el momento donde los datos pasan del filesystem local al sistema distribuido HDFS

```bash
# M√©todo 1: Usando ruta absoluta local
hdfs dfs -put /ruta/completa/al/archivo/ml-100k/u.data /datasets/movielens/

# M√©todo 2: Desde el directorio actual (si ya est√°s en ml-100k/)
cd /ruta/a/tu/dataset/ml-100k/
hdfs dfs -put u.data /datasets/movielens/

# M√©todo 3: Con renombramiento (recomendado para claridad)
hdfs dfs -put u.data /datasets/movielens/ratings.data
```

**üí° En esta pr√°ctica usaremos el M√©todo 3:**

```bash
cd /home/hadoop/ml-100k/

hdfs dfs -put u.data /datasets/movielens/ratings.data
```

---

### 1.5 Verificar que los Datos se Cargaron Correctamente

```bash
# Ver el archivo en HDFS
hdfs dfs -ls /datasets/movielens/

# Ver primeras 20 l√≠neas del archivo EN HDFS
hdfs dfs -cat /datasets/movielens/ratings.data | head -20

# Contar l√≠neas en HDFS (debe ser 100,000)
hdfs dfs -cat /datasets/movielens/ratings.data | wc -l

# Ver informaci√≥n detallada del archivo (tama√±o, replicaci√≥n, bloques)
hdfs dfs -stat "%b bytes, %r replicas, %o bloques" /datasets/movielens/ratings.data
```

**‚úÖ Salida esperada:**

```bash
# hdfs dfs -ls /datasets/movielens/
-rw-r--r--   3 hadoop supergroup    1979173 2026-02-01 10:20 /datasets/movielens/ratings.data

# hdfs dfs -cat ... | wc -l
100000
```

**üí° Explicaci√≥n del Output:**

- `-rw-r--r--`: Permisos del archivo
- `3`: Factor de replicaci√≥n (el archivo existe en 3 DataNodes)
- `hadoop`: Usuario propietario
- `1979173`: Tama√±o en bytes (~1.9 MB)
- `2026-02-01 10:20`: Fecha de carga

---

### 1.6 Explorar Distribuci√≥n de Bloques en HDFS

> **üéØ CONCEPTO BIG DATA:** HDFS divide archivos grandes en bloques (default: 128 MB). Nuestro archivo es peque√±o (1.9 MB) as√≠ que ser√° un solo bloque.

```bash
# Ver informaci√≥n detallada de bloques
hdfs fsck /datasets/movielens/ratings.data -files -blocks -locations
```

**‚úÖ Salida esperada (ejemplo simplificado):**

```
/datasets/movielens/ratings.data 1979173 bytes, 1 block(s):
 0. BP-1234567890-127.0.0.1-1234567890123:blk_1073741825_1001 len=1979173 repl=3
    [DataNode1:50010, DataNode2:50010, DataNode3:50010]
Status: HEALTHY
```

**üí° Interpretaci√≥n:**

- El archivo tiene **1 bloque** (porque es < 128 MB)
- Est√° **replicado 3 veces** (copia en 3 DataNodes diferentes)
- Si un DataNode falla, los otros 2 tienen la copia completa

---

### 1.7 Validaci√≥n Final con Interfaz Web

**Abrir en navegador:** http://localhost:9870

**Navegaci√≥n:**

1. Clic en **"Utilities"** ‚Üí **"Browse the file system"**
2. Navegar a `/datasets/movielens/`
3. Clic en `ratings.data`
4. Ver informaci√≥n de bloques, replicaci√≥n y DataNodes

**Captura conceptual de lo que ver√°s:**

```
File Information:
Path: /datasets/movielens/ratings.data
Size: 1.89 MB (1,979,173 bytes)
Block Size: 128 MB
Replication: 3
Owner: hadoop
Permissions: rw-r--r--

Blocks:
Block ID: blk_1073741825
Block Pool ID: BP-1234567890-127.0.0.1-1234567890123
Generation Stamp: 1001
Bytes: 1,979,173
Replicas (3):
  - DataNode: localhost:50010
  - DataNode: localhost:50010
  - DataNode: localhost:50010
```

> **‚úÖ CHECKPOINT:** Si ves el archivo en la interfaz web con replicaci√≥n = 3, los datos est√°n correctamente distribuidos en HDFS.

---

## üêù PASO 2: Crear Base de Datos y Tablas en Hive

‚è±Ô∏è **Tiempo estimado:** 3-4 minutos

---

### 2.1 Conectar a Hive

```bash
# Conectar a Hive (abre terminal interactiva)
hive
```

**‚úÖ Salida esperada:**

```
SLF4J: Class path contains multiple SLF4J bindings.
...
Hive Session ID = 12345678-abcd-1234-5678-123456789abc

hive>
```

> **üí° Nota:** Los warnings de SLF4J son normales y pueden ignorarse. El prompt `hive>` indica que est√°s conectado.

---

### 2.2 ‚ö†Ô∏è CONFIGURACI√ìN OBLIGATORIA (Evitar Errores)

> **CR√çTICO:** Ejecuta estos comandos ANTES de cualquier consulta con GROUP BY o agregaciones

```sql
-- Deshabilitar modo local de Hive (fuerza uso de YARN)
SET hive.exec.mode.local.auto=false;

-- Forzar framework MapReduce en YARN
SET mapreduce.framework.name=yarn;

-- Ver configuraci√≥n actual (opcional, para verificar)
SET hive.exec.mode.local.auto;
SET mapreduce.framework.name;
```

**‚úÖ Salida esperada:**

```
hive.exec.mode.local.auto=false
mapreduce.framework.name=yarn
```

**üí° Explicaci√≥n:**

- **Problema:** Por defecto, Hive intenta ejecutar consultas en modo local (en memoria) para datasets peque√±os
- **Consecuencia:** Esto causa "Return Code 2" en consultas con GROUP BY
- **Soluci√≥n:** Forzar que Hive SIEMPRE use YARN para distribuir el trabajo con MapReduce

---

### 2.3 Crear Base de Datos

```sql
-- Crear base de datos para el proyecto MovieLens
CREATE DATABASE IF NOT EXISTS movielens
COMMENT 'Database para an√°lisis de ratings de pel√≠culas MovieLens 100K'
LOCATION '/user/hive/warehouse/movielens.db';

-- Ver bases de datos disponibles
SHOW DATABASES;

-- Usar la base de datos reci√©n creada
USE movielens;

-- Verificar que estamos en la base correcta
SELECT current_database();
```

**‚úÖ Salida esperada:**

```
OK
Time taken: 0.5 seconds

OK
default
movielens
Time taken: 0.3 seconds

OK
Time taken: 0.2 seconds

OK
movielens
Time taken: 0.1 seconds
```

---

### 2.4 Crear Tabla Externa para los Ratings

> **üéØ CONCEPTO:** Una tabla EXTERNA en Hive permite consultar datos en HDFS SIN moverlos. Si eliminamos la tabla, los datos en HDFS permanecen intactos.

```sql
-- Crear tabla externa apuntando a los datos en HDFS
CREATE EXTERNAL TABLE IF NOT EXISTS ratings (
    user_id INT COMMENT 'ID del usuario (1-943)',
    movie_id INT COMMENT 'ID de la pel√≠cula (1-1682)',
    rating INT COMMENT 'Calificaci√≥n (1-5 estrellas)',
    timestamp_unix BIGINT COMMENT 'Timestamp Unix (segundos desde 1970-01-01)'
)
COMMENT 'Tabla de 100,000 ratings de pel√≠culas del dataset MovieLens'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE
LOCATION '/datasets/movielens/'
TBLPROPERTIES (
    'skip.header.line.count'='0',
    'source'='MovieLens 100K dataset',
    'version'='1.0'
);
```

**üí° Explicaci√≥n L√≠nea por L√≠nea:**

| Cl√°usula                      | Prop√≥sito                                         |
| ------------------------------ | -------------------------------------------------- |
| `CREATE EXTERNAL TABLE`      | Crea tabla que referencia datos existentes en HDFS |
| `IF NOT EXISTS`              | No falla si la tabla ya existe                     |
| `user_id INT`                | Define columna con tipo de dato entero             |
| `COMMENT`                    | Documentaci√≥n (√∫til para equipos)                |
| `ROW FORMAT DELIMITED`       | Los campos est√°n separados por un delimitador     |
| `FIELDS TERMINATED BY '\t'`  | Usa tabulador (TAB) como separador                 |
| `STORED AS TEXTFILE`         | Archivo de texto plano (no binario)                |
| `LOCATION`                   | Ruta en HDFS donde est√°n los datos                |
| `skip.header.line.count='0'` | No tiene fila de encabezado (empieza con datos)    |

---

### 2.5 Verificar que la Tabla se Cre√≥ Correctamente

```sql
-- Ver todas las tablas en la base de datos actual
SHOW TABLES;

-- Ver estructura de la tabla (schema)
DESCRIBE ratings;

-- Ver informaci√≥n detallada de la tabla (metadata completo)
DESCRIBE FORMATTED ratings;
```

**‚úÖ Salida esperada:**

```sql
-- SHOW TABLES;
OK
ratings
Time taken: 0.2 seconds

-- DESCRIBE ratings;
OK
user_id             	int                 	ID del usuario (1-943)
movie_id            	int                 	ID de la pel√≠cula (1-1682)
rating              	int                 	Calificaci√≥n (1-5 estrellas)
timestamp_unix      	bigint              	Timestamp Unix
Time taken: 0.3 seconds

-- DESCRIBE FORMATTED ratings; (salida resumida)
# col_name            	data_type           	comment
user_id             	int                 	ID del usuario (1-943)
movie_id            	int                 	ID de la pel√≠cula (1-1682)
rating              	int                 	Calificaci√≥n (1-5 estrellas)
timestamp_unix      	bigint              	Timestamp Unix

# Detailed Table Information
Database:           	movielens
Owner:              	hadoop
CreateTime:         	Fri Feb 01 10:30:00 UTC 2026
LastAccessTime:     	UNKNOWN
Retention:          	0
Location:           	hdfs://localhost:9000/datasets/movielens/
Table Type:         	EXTERNAL_TABLE
Table Parameters:
	EXTERNAL            	TRUE
	source              	MovieLens 100K dataset
	version             	1.0
```

---

### 2.6 Prueba Inicial: Ver los Datos en Hive

```sql
-- Ver primeras 10 filas
SELECT * FROM ratings LIMIT 10;

-- Contar total de registros (debe ser 100,000)
SELECT COUNT(*) AS total_ratings FROM ratings;

-- Ver rating m√≠nimo y m√°ximo (deben ser 1 y 5)
SELECT MIN(rating) AS min_rating, MAX(rating) AS max_rating FROM ratings;
```

**‚úÖ Salida esperada:**

```sql
-- SELECT * FROM ratings LIMIT 10;
OK
196	242	3	881250949
186	302	3	891717742
22	377	1	878887116
244	51	2	880606923
166	346	1	886397596
298	474	4	884182806
115	265	2	881171488
253	465	5	891628467
305	451	3	886324817
6	86	3	883603013
Time taken: 1.2 seconds, Fetched: 10 row(s)

-- SELECT COUNT(*) AS total_ratings FROM ratings;
OK
100000
Time taken: 25.3 seconds, Fetched: 1 row(s)

-- SELECT MIN(rating) AS min_rating, MAX(rating) AS max_rating FROM ratings;
OK
1	5
Time taken: 22.1 seconds, Fetched: 1 row(s)
```

> **üí° Observaci√≥n:** El COUNT(*) toma ~25 segundos porque ejecuta un JOB MapReduce completo en YARN. Veremos esto en detalle en el siguiente paso.

---

## üîÑ PASO 3: Consultas Anal√≠ticas con MapReduce (YARN)

‚è±Ô∏è **Tiempo estimado:** 10-15 minutos (incluye observaci√≥n de jobs)

---

### üéØ Objetivo de Aprendizaje

En este paso ejecutaremos consultas que disparan **Jobs MapReduce distribuidos** gestionados por YARN. Observaremos c√≥mo Hadoop procesa 100,000 registros en paralelo.

---

### 3.1 Consulta 1: Distribuci√≥n de Ratings (1-5 estrellas)

> **üìä Pregunta de Negocio:** ¬øCu√°ntos ratings hay de cada calificaci√≥n (1, 2, 3, 4, 5 estrellas)?

#### SQL:

```sql
SELECT 
    rating,
    COUNT(*) AS cantidad,
    ROUND(COUNT(*) * 100.0 / 100000, 2) AS porcentaje
FROM ratings
GROUP BY rating
ORDER BY rating;
```

#### üîç Conceptos Big Data en Esta Consulta:

| Concepto                  | Explicaci√≥n                                                   |
| ------------------------- | -------------------------------------------------------------- |
| **GROUP BY rating** | Dispara fase**Shuffle & Sort** de MapReduce para agrupar |
| **COUNT(\*)**       | Operaci√≥n de agregaci√≥n ejecutada por**Reducers**      |
| **ORDER BY**        | Ordenamiento final en fase Reduce                              |

#### üìà Flujo MapReduce Explicado:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ INPUT (HDFS): /datasets/movielens/ratings.data         ‚îÇ
‚îÇ 100,000 registros distribuidos en bloques              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ MAP PHASE (Parallel)                                     ‚îÇ
‚îÇ - Lee registros en paralelo (m√∫ltiples mappers)        ‚îÇ
‚îÇ - Extrae la columna 'rating' de cada fila              ‚îÇ
‚îÇ - Emite pares clave-valor: (rating, 1)                 ‚îÇ
‚îÇ Ejemplo:                                                 ‚îÇ
‚îÇ   Input:  196\t242\t3\t881250949                        ‚îÇ
‚îÇ   Output: (3, 1)                                        ‚îÇ
‚îÇ   Input:  186\t302\t3\t891717742                        ‚îÇ
‚îÇ   Output: (3, 1)                                        ‚îÇ
‚îÇ   Input:  22\t377\t1\t878887116                         ‚îÇ
‚îÇ   Output: (1, 1)                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SHUFFLE & SORT (Framework Hadoop)                       ‚îÇ
‚îÇ - Agrupa TODOS los pares por clave (rating)            ‚îÇ
‚îÇ - Transfiere datos entre nodos (network shuffle)       ‚îÇ
‚îÇ Resultado:                                               ‚îÇ
‚îÇ   Rating 1: [1, 1, 1, 1, ..., 1] ‚Üí 6,110 valores       ‚îÇ
‚îÇ   Rating 2: [1, 1, 1, 1, ..., 1] ‚Üí 11,370 valores      ‚îÇ
‚îÇ   Rating 3: [1, 1, 1, 1, ..., 1] ‚Üí 27,145 valores      ‚îÇ
‚îÇ   Rating 4: [1, 1, 1, 1, ..., 1] ‚Üí 34,174 valores      ‚îÇ
‚îÇ   Rating 5: [1, 1, 1, 1, ..., 1] ‚Üí 21,201 valores      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ REDUCE PHASE (Parallel)                                 ‚îÇ
‚îÇ - Cada reducer recibe una clave y todos sus valores    ‚îÇ
‚îÇ - Suma los valores (COUNT)                              ‚îÇ
‚îÇ - Calcula porcentaje                                     ‚îÇ
‚îÇ - Ordena por rating (ORDER BY)                          ‚îÇ
‚îÇ Resultado final:                                         ‚îÇ
‚îÇ   (1, 6110, 6.11%)                                      ‚îÇ
‚îÇ   (2, 11370, 11.37%)                                    ‚îÇ
‚îÇ   (3, 27145, 27.15%)                                    ‚îÇ
‚îÇ   (4, 34174, 34.17%)                                    ‚îÇ
‚îÇ   (5, 21201, 21.20%)                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OUTPUT (Hive Result Set)                                ‚îÇ
‚îÇ 5 filas con agregaciones y porcentajes                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### ‚úÖ Resultado Esperado:

| rating | cantidad | porcentaje |
| ------ | -------- | ---------- |
| 1      | 6,110    | 6.11       |
| 2      | 11,370   | 11.37      |
| 3      | 27,145   | 27.15      |
| 4      | 34,174   | 34.17      |
| 5      | 21,201   | 21.20      |

**üìä Interpretaci√≥n:**

- La mayor√≠a de usuarios (34.17%) dan **4 estrellas**
- Solo el 6.11% dan **1 estrella** (peor calificaci√≥n)
- Dataset balanceado con tendencia positiva (m√°s 4-5 que 1-2)

---

### 3.2 Consulta 2: Top 10 Pel√≠culas M√°s Calificadas

> **üìä Pregunta de Negocio:** ¬øQu√© pel√≠culas recibieron m√°s ratings (no necesariamente las mejor calificadas)?

#### SQL:

```sql
SELECT 
    movie_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    MIN(rating) AS rating_min,
    MAX(rating) AS rating_max
FROM ratings
GROUP BY movie_id
ORDER BY num_ratings DESC
LIMIT 10;
```

#### üîç Job MapReduce Generado:

**Monitorea en:** http://localhost:8088

Ver√°s:

- **Nombre del Job:** `Stage-1` (Map) + `Stage-2` (Reduce)
- **Mappers:** T√≠picamente 2-4 (depende del tama√±o de bloques)
- **Reducers:** T√≠picamente 1-2 (para agregaci√≥n final)
- **Progreso:** Map 100% ‚Üí Shuffle 100% ‚Üí Reduce 100%

#### ‚úÖ Resultado Esperado:

| movie_id | num_ratings | rating_promedio | rating_min | rating_max |
| -------- | ----------- | --------------- | ---------- | ---------- |
| 50       | 583         | 4.36            | 1          | 5          |
| 258      | 509         | 4.16            | 1          | 5          |
| 100      | 508         | 3.59            | 1          | 5          |
| 181      | 507         | 4.07            | 1          | 5          |
| 294      | 485         | 4.20            | 1          | 5          |
| 286      | 481         | 4.22            | 1          | 5          |
| 288      | 478         | 3.86            | 1          | 5          |
| 1        | 452         | 3.88            | 1          | 5          |
| 300      | 431         | 4.07            | 1          | 5          |
| 121      | 429         | 3.43            | 1          | 5          |

**üìä Interpretaci√≥n:**

- La pel√≠cula ID 50 tiene **583 ratings** (la m√°s popular)
- Tiene un promedio de **4.36 estrellas** (alta calidad percibida)
- Todas las top 10 tienen al menos 400 ratings (estad√≠sticamente significativo)

---

### 3.3 Consulta 3: Top 10 Pel√≠culas Mejor Calificadas (con m√≠nimo de ratings)

> **üìä Pregunta de Negocio:** ¬øCu√°les son las mejores pel√≠culas con al menos 100 ratings? (Para evitar sesgos de pel√≠culas con pocos ratings)

#### SQL:

```sql
SELECT 
    movie_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    ROUND(STDDEV(rating), 2) AS desviacion_std
FROM ratings
GROUP BY movie_id
HAVING COUNT(*) >= 100
ORDER BY rating_promedio DESC, num_ratings DESC
LIMIT 10;
```

#### üîç Conceptos Nuevos:

| Cl√°usula                                           | Prop√≥sito                                             |
| --------------------------------------------------- | ------------------------------------------------------ |
| `HAVING COUNT(*) >= 100`                          | Filtra DESPU√âS de agrupar (diferente a WHERE)         |
| `STDDEV(rating)`                                  | Calcula desviaci√≥n est√°ndar (dispersi√≥n de ratings) |
| `ORDER BY rating_promedio DESC, num_ratings DESC` | Ordena por promedio primero, luego por cantidad        |

**üí° Diferencia WHERE vs HAVING:**

- `WHERE`: Filtra **filas individuales** ANTES de agrupar
- `HAVING`: Filtra **grupos completos** DESPU√âS de agrupar

Ejemplo:

```sql
-- WHERE filtra filas antes de contar
SELECT movie_id, COUNT(*) 
FROM ratings 
WHERE rating >= 4  -- Solo cuenta ratings de 4 y 5
GROUP BY movie_id;

-- HAVING filtra grupos despu√©s de contar
SELECT movie_id, COUNT(*) 
FROM ratings 
GROUP BY movie_id
HAVING COUNT(*) >= 100;  -- Solo muestra pel√≠culas con ‚â•100 ratings
```

#### ‚úÖ Resultado Esperado:

| movie_id | num_ratings | rating_promedio | desviacion_std |
| -------- | ----------- | --------------- | -------------- |
| 408      | 112         | 4.49            | 0.78           |
| 318      | 298         | 4.47            | 0.76           |
| 483      | 243         | 4.46            | 0.74           |
| 169      | 296         | 4.47            | 0.75           |
| 64       | 283         | 4.45            | 0.77           |
| 114      | 243         | 4.43            | 0.78           |
| 603      | 209         | 4.42            | 0.79           |
| 12       | 267         | 4.39            | 0.82           |
| 50       | 583         | 4.36            | 0.89           |
| 178      | 162         | 4.36            | 0.81           |

**üìä Interpretaci√≥n:**

- Pel√≠cula ID 408: **4.49 promedio** con 112 ratings (muy alta calidad)
- Desviaci√≥n est√°ndar baja (0.78) indica **consenso** entre usuarios
- Pel√≠cula ID 50 sigue en top 10 incluso con 583 ratings

---

### 3.4 Consulta 4: An√°lisis de Actividad de Usuarios

> **üìä Pregunta de Negocio:** ¬øC√≥mo se distribuye la actividad de usuarios? ¬øHay usuarios super activos?

#### SQL:

```sql
SELECT 
    user_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    MIN(rating) AS rating_min,
    MAX(rating) AS rating_max,
    COUNT(DISTINCT movie_id) AS peliculas_distintas
FROM ratings
GROUP BY user_id
ORDER BY num_ratings DESC
LIMIT 10;
```

#### üîç Concepto Nuevo: COUNT(DISTINCT)

```sql
-- COUNT(*) cuenta todas las filas (incluyendo duplicados)
SELECT user_id, COUNT(*) FROM ratings GROUP BY user_id;

-- COUNT(DISTINCT movie_id) cuenta pel√≠culas √öNICAS por usuario
SELECT user_id, COUNT(DISTINCT movie_id) FROM ratings GROUP BY user_id;
```

**Ejemplo:**

```
User 1 ratings:
  movie 50 ‚Üí 4 stars
  movie 50 ‚Üí 5 stars  (calific√≥ la misma pel√≠cula 2 veces - caso raro)
  movie 100 ‚Üí 3 stars

COUNT(*) = 3 ratings
COUNT(DISTINCT movie_id) = 2 pel√≠culas distintas
```

#### ‚úÖ Resultado Esperado:

| user_id | num_ratings | rating_promedio | rating_min | rating_max | peliculas_distintas |
| ------- | ----------- | --------------- | ---------- | ---------- | ------------------- |
| 405     | 737         | 3.33            | 1          | 5          | 737                 |
| 655     | 685         | 4.40            | 1          | 5          | 685                 |
| 13      | 636         | 3.74            | 1          | 5          | 636                 |
| 450     | 540         | 3.76            | 1          | 5          | 540                 |
| 276     | 518         | 3.51            | 1          | 5          | 518                 |
| 416     | 493         | 3.66            | 1          | 5          | 493                 |
| 537     | 490         | 3.89            | 1          | 5          | 490                 |
| 303     | 484         | 3.92            | 1          | 5          | 484                 |
| 234     | 480         | 4.10            | 1          | 5          | 480                 |
| 393     | 448         | 3.76            | 1          | 5          | 448                 |

**üìä Interpretaci√≥n:**

- Usuario 405: **737 ratings** (usuario m√°s activo)
- Usuario 655: **685 ratings** pero con promedio 4.40 (m√°s generoso)
- Usuario 13: **636 ratings** con promedio 3.74 (m√°s cr√≠tico)
- Todos tienen `num_ratings == peliculas_distintas` (no hay ratings duplicados)

---

### 3.5 Consulta 5: An√°lisis Temporal (Ratings por Mes)

> **üìä Pregunta de Negocio:** ¬øC√≥mo var√≠a la actividad de usuarios a lo largo del tiempo?

#### üîß Preparaci√≥n: Convertir Timestamp Unix a Fecha Legible

```sql
-- Primero exploramos los timestamps
SELECT 
    user_id,
    movie_id,
    rating,
    timestamp_unix,
    from_unixtime(timestamp_unix) AS fecha_completa,
    from_unixtime(timestamp_unix, 'yyyy-MM') AS anio_mes
FROM ratings
LIMIT 10;
```

**‚úÖ Salida:**

| user_id | movie_id | rating | timestamp_unix | fecha_completa      | anio_mes |
| ------- | -------- | ------ | -------------- | ------------------- | -------- |
| 196     | 242      | 3      | 881250949      | 1997-12-04 15:55:49 | 1997-12  |
| 186     | 302      | 3      | 891717742      | 1998-04-04 19:22:22 | 1998-04  |

#### SQL Principal:

```sql
SELECT 
    from_unixtime(timestamp_unix, 'yyyy-MM') AS mes,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    COUNT(DISTINCT user_id) AS usuarios_activos,
    COUNT(DISTINCT movie_id) AS peliculas_calificadas
FROM ratings
GROUP BY from_unixtime(timestamp_unix, 'yyyy-MM')
ORDER BY mes;
```

#### ‚úÖ Resultado Esperado (primeras 10 filas):

| mes     | num_ratings | rating_promedio | usuarios_activos | peliculas_calificadas |
| ------- | ----------- | --------------- | ---------------- | --------------------- |
| 1997-09 | 2,669       | 3.52            | 405              | 873                   |
| 1997-10 | 5,954       | 3.53            | 612              | 1,202                 |
| 1997-11 | 8,286       | 3.54            | 671              | 1,309                 |
| 1997-12 | 9,452       | 3.53            | 686              | 1,341                 |
| 1998-01 | 11,372      | 3.54            | 705              | 1,376                 |
| 1998-02 | 10,561      | 3.54            | 691              | 1,345                 |
| 1998-03 | 12,643      | 3.52            | 719              | 1,401                 |
| 1998-04 | 18,063      | 3.53            | 753              | 1,445                 |

**üìä Interpretaci√≥n:**

- Dataset recolectado entre **Septiembre 1997 - Abril 1998**
- Pico de actividad en **Abril 1998** (18,063 ratings)
- Rating promedio muy estable (~3.53) a trav√©s del tiempo
- Crecimiento de usuarios activos: 405 ‚Üí 753

---

## üìä PASO 4: Monitoreo de Jobs YARN y MapReduce

‚è±Ô∏è **Tiempo:** Durante la ejecuci√≥n de consultas

---

### üéØ Objetivo

Aprender a monitorear jobs MapReduce en tiempo real para entender c√≥mo Hadoop distribuye y procesa los datos.

---

### 4.1 Monitoreo desde Interfaz Web YARN

**URL:** http://localhost:8088

#### üìç Navegaci√≥n:

1. **Applications ‚Üí All Applications**

   - Ver lista de todos los jobs (RUNNING, FINISHED, FAILED)
2. **Clic en un Application ID** (ej: `application_1234567890_0001`)

   - Ver detalles del job en ejecuci√≥n
3. **Dentro del job:**

   - **Application Master:** Coordinador del job
   - **Progress:** Porcentaje de Map ‚Üí Shuffle ‚Üí Reduce
   - **Tasks:** Mappers y Reducers individuales
   - **Logs:** Salida est√°ndar y errores

#### üìä M√©tricas Clave a Observar:

| M√©trica                  | Ubicaci√≥n        | Qu√© Observar                      |
| ------------------------- | ----------------- | ---------------------------------- |
| **Estado**          | Application State | RUNNING ‚Üí SUCCEEDED (o FAILED)    |
| **Progreso Map**    | Progress          | 0% ‚Üí 100%                         |
| **Progreso Reduce** | Progress          | 0% ‚Üí 100%                         |
| **# Mappers**       | Tasks             | T√≠picamente 2-4 para 1.9 MB       |
| **# Reducers**      | Tasks             | T√≠picamente 1-2 para agregaciones |
| **Memoria**         | Resources         | RAM usada vs disponible            |
| **Duraci√≥n**       | Elapsed Time      | Tiempo total de ejecuci√≥n         |

---

### 4.2 Monitoreo desde Terminal

#### Ver aplicaciones activas:

```bash
# Listar aplicaciones en ejecuci√≥n
yarn application -list

# Actualizar cada 2 segundos (watch mode)
watch -n 2 'yarn application -list'
```

**‚úÖ Salida ejemplo:**

```
Total number of applications (application-types: [], states: [RUNNING] and tags: []):1
Application-Id	    Application-Name	Application-Type  User	  State	    Final-State	Progress
application_1234567890_0001  INSERT OVERWRITE DIRECTORY  MAPREDUCE  hadoop  RUNNING  UNDEFINED  50%
```

#### Ver estado detallado de un job:

```bash
# Reemplazar con el Application ID real
yarn application -status application_1234567890_0001
```

**‚úÖ Salida ejemplo:**

```
Application Report :
	Application-Id : application_1234567890_0001
	Application-Name : INSERT OVERWRITE DIRECTORY
	Application-Type : MAPREDUCE
	User : hadoop
	Queue : default
	Start-Time : 1704192000000
	Finish-Time : 0
	Progress : 75%
	State : RUNNING
	Final-State : UNDEFINED
	Tracking-URL : http://localhost:8088/proxy/application_1234567890_0001/
```

#### Ver logs de un job (despu√©s de que termine):

```bash
# Ver logs completos
yarn logs -applicationId application_1234567890_0001

# Ver solo los √∫ltimos 100 KB
yarn logs -applicationId application_1234567890_0001 -size -102400
```

---

### 4.3 Monitoreo desde Interfaz Web HDFS

**URL:** http://localhost:9870

#### üìç Navegaci√≥n:

1. **Overview**

   - Capacidad usada/disponible del cluster
   - DataNodes activos
2. **Datanodes**

   - Lista de nodos con su estado
   - Capacidad individual
   - Bloques almacenados
3. **Utilities ‚Üí Browse the file system**

   - Explorar archivos en HDFS
   - Ver replicaci√≥n y bloques
4. **Navegar a `/datasets/movielens/ratings.data`**

   - Ver informaci√≥n del archivo
   - Ver distribuci√≥n de bloques
   - Ver r√©plicas en diferentes DataNodes

---

### 4.4 Interpretar el Flujo de un Job MapReduce

#### Ejemplo: Ejecutar y Observar

```sql
-- En Hive, ejecuta esta consulta
SELECT rating, COUNT(*) AS cantidad 
FROM ratings 
GROUP BY rating 
ORDER BY rating;
```

#### üìä Timeline de Ejecuci√≥n:

```
T=0s   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ Hive compila SQL a plan de ejecuci√≥n MapReduce ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
T=2s   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ YARN ResourceManager asigna contenedores        ‚îÇ
       ‚îÇ - ApplicationMaster: 1 contenedor               ‚îÇ
       ‚îÇ - Mappers: 2-4 contenedores                     ‚îÇ
       ‚îÇ - Reducers: 1-2 contenedores                    ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
T=3s   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ MAP PHASE: Lee bloques de HDFS en paralelo     ‚îÇ
       ‚îÇ - Mapper 1: Procesa primeros 50,000 registros  ‚îÇ
       ‚îÇ - Mapper 2: Procesa √∫ltimos 50,000 registros   ‚îÇ
       ‚îÇ - Emite pares (rating, 1) para cada fila       ‚îÇ
       ‚îÇ Progreso: Map 0% ‚Üí 50% ‚Üí 100%                  ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
T=15s  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ SHUFFLE & SORT PHASE: Transferencia de datos   ‚îÇ
       ‚îÇ - Agrupa pares por clave (rating)              ‚îÇ
       ‚îÇ - Transfiere datos entre nodos                 ‚îÇ
       ‚îÇ - Ordena las claves                             ‚îÇ
       ‚îÇ Progreso: Shuffle 0% ‚Üí 100%                     ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
T=20s  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ REDUCE PHASE: Agregaci√≥n                        ‚îÇ
       ‚îÇ - Reducer 1: Suma valores para ratings 1-3     ‚îÇ
       ‚îÇ - Reducer 2: Suma valores para ratings 4-5     ‚îÇ
       ‚îÇ - Ordena resultado final (ORDER BY)            ‚îÇ
       ‚îÇ Progreso: Reduce 0% ‚Üí 100%                      ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
T=25s  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ OUTPUT: Escribe resultado final                 ‚îÇ
       ‚îÇ - Hive recibe 5 filas del job                  ‚îÇ
       ‚îÇ - Muestra resultado en terminal                 ‚îÇ
       ‚îÇ Estado: SUCCEEDED                               ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**üí° Observa en http://localhost:8088 durante cada fase:**

- **T=3-15s:** Ver√°s "Map Progress" aumentando
- **T=15-20s:** Ver√°s "Shuffle Progress" aumentando
- **T=20-25s:** Ver√°s "Reduce Progress" aumentando

---

### 4.5 Diagn√≥stico de Errores Comunes

#### ‚ùå Error 1: "Return Code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask"

**Causa:** Hive intenta ejecutar en modo local en lugar de YARN

**Soluci√≥n:**

```sql
SET hive.exec.mode.local.auto=false;
SET mapreduce.framework.name=yarn;
```

**Verificar en logs:**

```bash
# Ver logs del √∫ltimo job fallido
yarn logs -applicationId $(yarn application -list -appStates FAILED | tail -1 | awk '{print $1}')
```

---

#### ‚ùå Error 2: "Container killed by YARN for exceeding memory limits"

**Causa:** El job MapReduce requiere m√°s memoria de la disponible

**Diagn√≥stico en YARN UI:**

1. Ir a http://localhost:8088
2. Clic en el job FAILED
3. Ver "Diagnostics" ‚Üí "Container exited with a non-zero exit code 137"

**Soluci√≥n:**

```sql
-- Aumentar memoria para Map y Reduce tasks
SET mapreduce.map.memory.mb=2048;
SET mapreduce.reduce.memory.mb=2048;
SET mapreduce.map.java.opts=-Xmx1638m;
SET mapreduce.reduce.java.opts=-Xmx1638m;
```

---

#### ‚ùå Error 3: Job permanece en "ACCEPTED" sin ejecutarse

**Causa:** No hay recursos disponibles en YARN

**Diagn√≥stico:**

```bash
# Ver recursos del cluster
yarn node -list -all

# Ver configuraci√≥n de memoria
yarn resourcemanager -format
```

**Verificar en YARN UI:**

http://localhost:8088 ‚Üí Cluster Metrics ‚Üí "Memory Available"

---

## üíæ PASO 5: Exportar Resultados

‚è±Ô∏è **Tiempo estimado:** 2-3 minutos

---

### 5.1 Exportar a Sistema de Archivos Local (CSV)

> **üìå Uso:** Para an√°lisis externo con Excel, Python, R, etc.

#### SQL en Hive:

```sql
-- Exportar distribuci√≥n de ratings a archivo local
INSERT OVERWRITE LOCAL DIRECTORY '/tmp/movielens_export/distribucion_ratings'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
SELECT 
    rating,
    COUNT(*) AS cantidad,
    ROUND(COUNT(*) * 100.0 / 100000, 2) AS porcentaje
FROM ratings
GROUP BY rating
ORDER BY rating;
```

**üí° Explicaci√≥n:**

- `INSERT OVERWRITE LOCAL DIRECTORY`: Escribe en filesystem local (no HDFS)
- `/tmp/movielens_export/`: Ruta local donde se guardar√°n los archivos
- `ROW FORMAT DELIMITED FIELDS TERMINATED BY ','`: Formato CSV
- Hive crea m√∫ltiples archivos si hay m√∫ltiples reducers (000000_0, 000001_0, etc.)

#### Verificar en Terminal:

```bash
# Ver archivos generados
ls -lh /tmp/movielens_export/distribucion_ratings/

# Ver contenido
cat /tmp/movielens_export/distribucion_ratings/000000_0

# Formatear como tabla
column -t -s',' /tmp/movielens_export/distribucion_ratings/000000_0
```

**‚úÖ Salida esperada:**

```bash
$ cat /tmp/movielens_export/distribucion_ratings/000000_0
1,6110,6.11
2,11370,11.37
3,27145,27.15
4,34174,34.17
5,21201,21.2
```

---

### 5.2 Exportar Top Pel√≠culas a CSV con Encabezado

```sql
-- Crear archivo con encabezado (header)
INSERT OVERWRITE LOCAL DIRECTORY '/tmp/movielens_export/top_peliculas'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
SELECT * FROM (
    -- Fila de encabezado
    SELECT 'movie_id' as c1, 'num_ratings' as c2, 'rating_promedio' as c3, 0 as sort_col
  
    UNION ALL
  
    -- Datos calculados
    SELECT 
        CAST(movie_id AS STRING) as c1, 
        CAST(COUNT(*) AS STRING) as c2, 
        CAST(ROUND(AVG(rating), 2) AS STRING) as c3,
        1 as sort_col
    FROM ratings
    GROUP BY movie_id
) t
ORDER BY t.sort_col ASC, CAST(t.c2 AS INT) DESC
LIMIT 21; -- 20 pel√≠culas + 1 encabezado
```

**üí° Truco:** Usamos `UNION ALL` para agregar una fila de encabezado

#### Descargar desde servidor (si trabajas remoto):

```bash
# Comprimir exportaciones
tar -czf ~/movielens_export.tar.gz -C /tmp/ movielens_export/

# Una vez terminado, verifica que el archivo existe y tiene un tama√±o razonable:
ls -lh ~/movielens_export.tar.gz

# Intentar moverlo a tu home (aqu√≠ veremos si falla de nuevo)
mv /tmp/movielens_export.tar.gz ~/

# Copiar a tu m√°quina local (desde tu PC)
scp usuario@servidor:/tmp/movielens_export.tar.gz ~/Descargas/

# Descomprimir localmente
tar -xzf ~/Descargas/movielens_export.tar.gz
```

---

### 5.3 Exportar a HDFS (para compartir con otros procesos)

> **üìå Uso:** Guardar resultados para otros jobs Hadoop, Spark, o usuarios del cluster

#### SQL en Hive:

```sql
-- Exportar a HDFS (sin LOCAL)
INSERT OVERWRITE DIRECTORY '/results/movielens/top_peliculas'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
SELECT 
    movie_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio
FROM ratings
GROUP BY movie_id
ORDER BY num_ratings DESC
LIMIT 100;
```

#### Verificar en HDFS:

```bash
# Ver archivos en HDFS
hdfs dfs -ls /results/movielens/top_peliculas/

# Ver contenido
hdfs dfs -cat /results/movielens/top_peliculas/000000_0 | head -10

# Descargar a local si necesitas
hdfs dfs -get /results/movielens/top_peliculas/000000_0 ~/top_peliculas.csv
```

#### Ver en Interfaz Web:

http://localhost:9870 ‚Üí Utilities ‚Üí Browse ‚Üí `/results/movielens/top_peliculas/`

---

### 5.4 Crear Tabla Materializada para Consultas R√°pidas

> **üéØ CONCEPTO:** Materializar resultados de consultas costosas para reutilizarlos sin re-calcular

```sql
-- Crear tabla con estad√≠sticas pre-calculadas de pel√≠culas
CREATE TABLE movie_stats AS
SELECT 
    movie_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    ROUND(STDDEV(rating), 2) AS rating_stddev,
    MIN(rating) AS rating_min,
    MAX(rating) AS rating_max,
    PERCENTILE_APPROX(rating, 0.5) AS rating_mediana
FROM ratings
GROUP BY movie_id;

-- Ahora podemos consultar r√°pidamente SIN re-calcular
SELECT * FROM movie_stats 
WHERE num_ratings >= 100 
ORDER BY rating_promedio DESC 
LIMIT 10;
```

**üí° Ventaja:** La segunda consulta NO ejecuta MapReduce, es instant√°nea

#### Verificar ubicaci√≥n en HDFS:

```sql
DESCRIBE FORMATTED movie_stats;
```

```bash
# Ver datos en HDFS
hdfs dfs -ls /user/hive/warehouse/movielens.db/movie_stats/
hdfs dfs -cat /user/hive/warehouse/movielens.db/movie_stats/000000_0 | head -5
```

---

### 5.5 Exportar M√∫ltiples Reportes (Script Completo)

#### Crear script `export_reports.hql`:

```sql
-- Archivo: export_reports.hql
-- Configuraci√≥n inicial
USE movielens;
SET hive.exec.mode.local.auto=false;
SET mapreduce.framework.name=yarn;

-- Reporte 1: Distribuci√≥n de ratings
INSERT OVERWRITE LOCAL DIRECTORY '/tmp/reports/distribucion_ratings'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
SELECT rating, COUNT(*) AS cantidad
FROM ratings GROUP BY rating ORDER BY rating;

-- Reporte 2: Top 50 pel√≠culas
INSERT OVERWRITE LOCAL DIRECTORY '/tmp/reports/top_peliculas'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
SELECT movie_id, COUNT(*) AS num_ratings, ROUND(AVG(rating), 2) AS avg_rating
FROM ratings GROUP BY movie_id 
ORDER BY num_ratings DESC LIMIT 50;

-- Reporte 3: Actividad por mes
INSERT OVERWRITE LOCAL DIRECTORY '/tmp/reports/actividad_mensual'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
SELECT 
    from_unixtime(timestamp_unix, 'yyyy-MM') AS mes,
    COUNT(*) AS num_ratings,
    COUNT(DISTINCT user_id) AS usuarios_activos
FROM ratings 
GROUP BY from_unixtime(timestamp_unix, 'yyyy-MM')
ORDER BY mes;
```

#### Ejecutar script desde terminal:

```bash
# Ejecutar todos los reportes en batch
hive -f export_reports.hql

# Ver resultados
ls -lh /tmp/reports/*/
```

---

## üéì PASO 6: Consultas Avanzadas (Bonus)

‚è±Ô∏è **Tiempo estimado:** 15-20 minutos

---

### 6.1 An√°lisis de Consenso: Pel√≠culas Polarizantes vs Consensuadas

> **üìä Pregunta:** ¬øQu√© pel√≠culas generan m√°s desacuerdo entre usuarios?

#### SQL:

```sql
SELECT 
    movie_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    ROUND(STDDEV(rating), 2) AS desviacion,
    CASE 
        WHEN STDDEV(rating) >= 1.5 THEN 'Polarizante'
        WHEN STDDEV(rating) >= 1.0 THEN 'Mixta'
        ELSE 'Consensuada'
    END AS tipo_opinion
FROM ratings
GROUP BY movie_id
HAVING COUNT(*) >= 50  -- Solo pel√≠culas con suficientes ratings
ORDER BY desviacion DESC
LIMIT 20;
```

**üîç Conceptos:**

- **CASE WHEN**: L√≥gica condicional (como IF-ELSE)
- **Alta desviaci√≥n (> 1.5)**: Usuarios muy divididos (algunos 1‚òÖ, otros 5‚òÖ)
- **Baja desviaci√≥n (< 1.0)**: Usuarios de acuerdo en la calidad

**üìä Interpretaci√≥n:**

- Pel√≠culas polarizantes: Gustos muy divididos (ej: pel√≠culas experimentales)
- Pel√≠culas consensuadas: Acuerdo general (ej: cl√°sicos universales)

---

### 6.2 Usuarios Generosos vs Cr√≠ticos

> **üìä Pregunta:** ¬øQu√© usuarios dan las mejores vs peores calificaciones en promedio?

#### Top 10 Usuarios M√°s Generosos:

```sql
SELECT 
    user_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    SUM(CASE WHEN rating = 5 THEN 1 ELSE 0 END) AS cinco_estrellas,
    SUM(CASE WHEN rating = 1 THEN 1 ELSE 0 END) AS una_estrella
FROM ratings
GROUP BY user_id
HAVING COUNT(*) >= 100  -- Solo usuarios activos
ORDER BY rating_promedio DESC
LIMIT 10;
```

#### Top 10 Usuarios M√°s Cr√≠ticos:

```sql
SELECT 
    user_id,
    COUNT(*) AS num_ratings,
    ROUND(AVG(rating), 2) AS rating_promedio,
    SUM(CASE WHEN rating = 5 THEN 1 ELSE 0 END) AS cinco_estrellas,
    SUM(CASE WHEN rating = 1 THEN 1 ELSE 0 END) AS una_estrella
FROM ratings
GROUP BY user_id
HAVING COUNT(*) >= 100
ORDER BY rating_promedio ASC
LIMIT 10;
```

**üîç Concepto SUM + CASE:**

```sql
SUM(CASE WHEN rating = 5 THEN 1 ELSE 0 END)
```

Traduce a: "Cuenta cu√°ntos ratings de 5 estrellas tiene este usuario"

---

### 6.3 An√°lisis de Picos de Actividad (D√≠a de la Semana)

> **üìä Pregunta:** ¬øQu√© d√≠a de la semana los usuarios califican m√°s pel√≠culas?

#### SQL:

```sql
SELECT 
    CASE pmod(CAST(from_unixtime(timestamp_unix, 'u') AS INT), 7)
        WHEN 0 THEN 'Domingo'
        WHEN 1 THEN 'Lunes'
        WHEN 2 THEN 'Martes'
        WHEN 3 THEN 'Mi√©rcoles'
        WHEN 4 THEN 'Jueves'
        WHEN 5 THEN 'Viernes'
        WHEN 6 THEN 'S√°bado'
    END AS dia_semana,
    COUNT(*) AS num_ratings,
    ROUND(COUNT(*) * 100.0 / 100000, 2) AS porcentaje
FROM ratings
GROUP BY pmod(CAST(from_unixtime(timestamp_unix, 'u') AS INT), 7)
ORDER BY 
    CASE pmod(CAST(from_unixtime(timestamp_unix, 'u') AS INT), 7)
        WHEN 0 THEN 7 ELSE pmod(CAST(from_unixtime(timestamp_unix, 'u') AS INT), 7)
    END;
```

**üîç Conceptos:**

- `from_unixtime(timestamp, 'u')`: Extrae d√≠a de la semana (1-7)
- `pmod(x, 7)`: M√≥dulo positivo (maneja negativos correctamente)
- Ordenamos para que empiece en Lunes y termine en Domingo

---

### 6.4 Pel√≠culas con Mayor Variabilidad en el Tiempo

> **üìä Pregunta:** ¬øCambian los ratings de una pel√≠cula con el tiempo?

#### SQL:

```sql
-- Crear vista temporal con fechas
CREATE TEMPORARY TABLE ratings_with_date AS
SELECT 
    *,
    from_unixtime(timestamp_unix, 'yyyy-MM') AS month,
    from_unixtime(timestamp_unix, 'yyyy-MM-dd') AS date_only
FROM ratings;

-- Analizar cambio de ratings en el tiempo
SELECT 
    movie_id,
    MIN(date_only) AS primera_calificacion,
    MAX(date_only) AS ultima_calificacion,
    ROUND(AVG(CASE WHEN month <= '1997-12' THEN rating END), 2) AS rating_primeros_meses,
    ROUND(AVG(CASE WHEN month >= '1998-03' THEN rating END), 2) AS rating_ultimos_meses,
    ROUND(
        AVG(CASE WHEN month >= '1998-03' THEN rating END) - 
        AVG(CASE WHEN month <= '1997-12' THEN rating END), 
        2
    ) AS cambio_rating
FROM ratings_with_date
GROUP BY movie_id
HAVING COUNT(*) >= 50
ORDER BY ABS(cambio_rating) DESC
LIMIT 20;
```

**üí° Interpretaci√≥n:**

- `cambio_rating > 0`: La pel√≠cula mejor√≥ su percepci√≥n con el tiempo
- `cambio_rating < 0`: La pel√≠cula perdi√≥ popularidad con el tiempo

---

### 6.5 Matriz de Correlaci√≥n: Ratings por Usuario Activo

> **üìä Pregunta:** ¬øLos usuarios activos califican diferente que los pasivos?

#### SQL:

```sql
WITH user_activity AS (
    SELECT 
        user_id,
        COUNT(*) AS num_ratings,
        CASE 
            WHEN COUNT(*) >= 200 THEN 'Muy Activo'
            WHEN COUNT(*) >= 100 THEN 'Activo'
            WHEN COUNT(*) >= 50 THEN 'Moderado'
            ELSE 'Pasivo'
        END AS nivel_actividad
    FROM ratings
    GROUP BY user_id
)
SELECT 
    ua.nivel_actividad,
    COUNT(DISTINCT r.user_id) AS num_usuarios,
    COUNT(*) AS total_ratings,
    ROUND(AVG(r.rating), 2) AS rating_promedio,
    ROUND(STDDEV(r.rating), 2) AS rating_stddev
FROM ratings r
JOIN user_activity ua ON r.user_id = ua.user_id
GROUP BY ua.nivel_actividad
ORDER BY 
    CASE ua.nivel_actividad
        WHEN 'Muy Activo' THEN 1
        WHEN 'Activo' THEN 2
        WHEN 'Moderado' THEN 3
        ELSE 4
    END;
```

**üîç Concepto WITH (CTE - Common Table Expression):**

```sql
WITH user_activity AS (
    -- Subconsulta temporal nombrada
    SELECT user_id, COUNT(*) AS num_ratings
    FROM ratings GROUP BY user_id
)
-- Ahora usamos user_activity como si fuera una tabla
SELECT * FROM user_activity;
```

**Ventajas de CTE:**

- C√≥digo m√°s legible
- Evita subconsultas anidadas complejas
- Se puede referenciar m√∫ltiples veces

---

### 6.6 Top Pel√≠culas por Segmento de Rating

> **üìä Pregunta:** ¬øCu√°les son las pel√≠culas m√°s populares entre cada grupo de calificaci√≥n?

#### SQL:

```sql
SELECT 
    rating AS segmento,
    movie_id,
    COUNT(*) AS num_ratings_en_segmento,
    RANK() OVER (PARTITION BY rating ORDER BY COUNT(*) DESC) AS ranking
FROM ratings
GROUP BY rating, movie_id
HAVING RANK() OVER (PARTITION BY rating ORDER BY COUNT(*) DESC) <= 5
ORDER BY rating DESC, ranking;
```

**üîç Concepto WINDOW FUNCTIONS:**

- `RANK() OVER (...)`: Asigna un ranking dentro de cada partici√≥n
- `PARTITION BY rating`: Crea grupos por cada valor de rating (1-5)
- `ORDER BY COUNT(*) DESC`: Ordena por cantidad descendente

**Resultado conceptual:**

```
segmento=5 (5 estrellas):
  ranking 1: movie 318 (150 calificaciones de 5‚òÖ)
  ranking 2: movie 50 (140 calificaciones de 5‚òÖ)
  ...
segmento=4 (4 estrellas):
  ranking 1: movie 100 (200 calificaciones de 4‚òÖ)
  ranking 2: movie 258 (180 calificaciones de 4‚òÖ)
  ...
```

---

### 6.7 An√°lisis de "Long Tail": Distribuci√≥n de Popularidad

> **üìä Pregunta:** ¬øCu√°ntas pel√≠culas concentran el 80% de los ratings? (Principio de Pareto)

#### SQL:

```sql
WITH movie_popularity AS (
    SELECT 
        movie_id,
        COUNT(*) AS num_ratings
    FROM ratings
    GROUP BY movie_id
    ORDER BY num_ratings DESC
),
cumulative_ratings AS (
    SELECT 
        movie_id,
        num_ratings,
        SUM(num_ratings) OVER (ORDER BY num_ratings DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumsum,
        100000 AS total
    FROM movie_popularity
)
SELECT 
    COUNT(*) AS num_peliculas,
    SUM(num_ratings) AS total_ratings,
    ROUND(SUM(num_ratings) * 100.0 / 100000, 2) AS porcentaje_acumulado
FROM cumulative_ratings
WHERE cumsum <= 80000  -- 80% del total
UNION ALL
SELECT 
    COUNT(*) AS num_peliculas,
    SUM(num_ratings) AS total_ratings,
    ROUND(SUM(num_ratings) * 100.0 / 100000, 2) AS porcentaje_acumulado
FROM cumulative_ratings;
```

**üí° Interpretaci√≥n Esperada:**

- ~20% de las pel√≠culas (~336 pel√≠culas) concentran 80% de los ratings
- ~80% de las pel√≠culas (~1346 pel√≠culas) reciben solo 20% de los ratings
- Esto confirma el "efecto Long Tail" en consumo de contenido

---

## üßπ LIMPIEZA Y CIERRE

‚è±Ô∏è **Tiempo estimado:** 2-3 minutos

---

### üõë Paso 1: Salir de Hive

```sql
-- Dentro de Hive, ejecutar:
EXIT;

-- O simplemente:
quit;
```

---

### üõë Paso 2: Eliminar Datos en Hive (Opcional)

> ‚ö†Ô∏è Solo ejecutar si quieres eliminar todo lo creado en la pr√°ctica

```bash
# Conectar de nuevo a Hive
hive

# Ejecutar comandos de limpieza
```

```sql
-- Usar la base de datos
USE movielens;

-- Eliminar tablas
DROP TABLE IF EXISTS ratings;
DROP TABLE IF EXISTS movie_stats;

-- Eliminar base de datos
DROP DATABASE IF EXISTS movielens;

-- Verificar limpieza
SHOW DATABASES;
SHOW TABLES;

-- Salir
EXIT;
```

---

### üõë Paso 3: Eliminar Datos en HDFS

```bash
# Eliminar dataset original
hdfs dfs -rm -r /datasets/movielens/

# Eliminar resultados exportados
hdfs dfs -rm -r /results/movielens/

# Eliminar archivos temporales
hdfs dfs -rm -r /tmp/hive/

# Verificar limpieza
hdfs dfs -ls /datasets/
hdfs dfs -ls /results/
```

---

### üõë Paso 4: Eliminar Exportaciones Locales

```bash
# Eliminar exportaciones en filesystem local
rm -rf /tmp/movielens_export/
rm -rf /tmp/reports/

# Verificar
ls /tmp/ | grep -E 'movielens|reports'
# No debe mostrar nada
```

---

### üõë Paso 5: Detener Servicios Hadoop y YARN

```bash
# Detener YARN
stop-yarn.sh

# Detener HDFS
stop-dfs.sh

# O detener todo de una vez
stop-all.sh

# Verificar que todos los servicios se detuvieron
jps
# Solo debe aparecer: Jps
```

---

### üõë Paso 6: Verificaci√≥n Final

```bash
# Verificar que no hay procesos Java de Hadoop
jps

# Verificar que las interfaces web no responden
curl -I http://localhost:9870 2>&1 | grep "Failed to connect"
curl -I http://localhost:8088 2>&1 | grep "Failed to connect"
```

**‚úÖ Salida esperada:**

```
1234 Jps

curl: (7) Failed to connect to localhost port 9870: Connection refused
curl: (7) Failed to connect to localhost port 8088: Connection refused
```

---

## üìö RESUMEN DE APRENDIZAJE

---

### ‚úÖ Conceptos de Big Data Cubiertos

| Concepto                                         | Explicaci√≥n                                                          | D√≥nde se Aplic√≥                                        |
| ------------------------------------------------ | --------------------------------------------------------------------- | -------------------------------------------------------- |
| **HDFS (Hadoop Distributed File System)**  | Sistema de archivos distribuido que replica datos en m√∫ltiples nodos | Paso 2: Carga de u.data a HDFS con replicaci√≥n 3x       |
| **MapReduce**                              | Paradigma de programaci√≥n paralela (Map ‚Üí Shuffle ‚Üí Reduce)        | Paso 4: Todas las consultas con GROUP BY                 |
| **YARN (Yet Another Resource Negotiator)** | Gestor de recursos y scheduler de jobs                                | Paso 5: Monitoreo de jobs en http://localhost:8088       |
| **Hive**                                   | Data warehouse SQL sobre Hadoop (HiveQL)                              | Paso 3-4: Consultas SQL traducidas a MapReduce           |
| **Bloques HDFS**                           | Divisi√≥n de archivos en bloques de 128 MB (default)                  | Paso 2.6: An√°lisis de bloques con `hdfs fsck`         |
| **Replicaci√≥n**                           | Copias de bloques en m√∫ltiples DataNodes (fault tolerance)           | Paso 2.3: Factor de replicaci√≥n = 3                     |
| **Particionamiento**                       | Divisi√≥n de datos para procesamiento paralelo                        | Paso 4: Mappers procesan particiones en paralelo         |
| **Agregaciones distribuidas**              | COUNT, SUM, AVG ejecutadas en paralelo                                | Paso 4: Todas las consultas con funciones de agregaci√≥n |
| **Tablas externas**                        | Tablas Hive que referencian datos externos sin moverlos               | Paso 3.4: CREATE EXTERNAL TABLE                          |
| **Materializaci√≥n**                       | Pre-c√°lculo de resultados para queries r√°pidas                      | Paso 6.4: CREATE TABLE AS SELECT                         |

---

### üìä Estad√≠sticas del Dataset Procesado

| M√©trica                         | Valor                        |
| -------------------------------- | ---------------------------- |
| **Total de ratings**       | 100,000                      |
| **Usuarios √∫nicos**       | 943                          |
| **Pel√≠culas √∫nicas**     | 1,682                        |
| **Per√≠odo**               | Septiembre 1997 - Abril 1998 |
| **Tama√±o del archivo**    | 1.9 MB (u.data)              |
| **Formato**                | TSV (Tab-Separated Values)   |
| **Rating promedio**        | ~3.53 estrellas              |
| **Rating m√°s com√∫n**     | 4 estrellas (34.17%)         |
| **Usuario m√°s activo**    | User 405 (737 ratings)       |
| **Pel√≠cula m√°s popular** | Movie 50 (583 ratings)       |

---

### üéØ Resultados de Consultas Principales

#### 1. Distribuci√≥n de Ratings:

```
‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (5): 21,201 ratings (21.20%)
‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (4): 34,174 ratings (34.17%) ‚Üê M√°s com√∫n
‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ (3): 27,145 ratings (27.15%)
‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ (2): 11,370 ratings (11.37%)
‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ (1):  6,110 ratings (6.11%)
```

#### 2. Top 5 Pel√≠culas M√°s Calificadas:

| Rank | Movie ID | # Ratings | Avg Rating |
| ---- | -------- | --------- | ---------- |
| 1    | 50       | 583       | 4.36       |
| 2    | 258      | 509       | 4.16       |
| 3    | 100      | 508       | 3.59       |
| 4    | 181      | 507       | 4.07       |
| 5    | 294      | 485       | 4.20       |

---

### üîß Comandos Esenciales para Referencia R√°pida

#### Iniciar Hadoop:

```bash
start-dfs.sh && start-yarn.sh
jps  # Verificar servicios
```

#### Cargar datos a HDFS:

```bash
hdfs dfs -put archivo.data /ruta/en/hdfs/
hdfs dfs -ls /ruta/en/hdfs/
```

#### Conectar a Hive:

```bash
hive
```

#### Configuraci√≥n obligatoria en Hive:

```sql
SET hive.exec.mode.local.auto=false;
SET mapreduce.framework.name=yarn;
```

#### Monitorear jobs:

```
YARN UI: http://localhost:8088
HDFS UI: http://localhost:9870
```

#### Detener Hadoop:

```bash
stop-all.sh
```

---

### üéì Habilidades Desarrolladas

‚úÖ **Operaciones HDFS:**

- Cargar archivos desde sistema local a HDFS
- Explorar estructura distribuida de archivos
- Entender replicaci√≥n y bloques

‚úÖ **Gesti√≥n Hive:**

- Crear bases de datos y tablas externas
- Ejecutar consultas SQL anal√≠ticas
- Configurar ejecuci√≥n con YARN

‚úÖ **MapReduce:**

- Entender flujo Map ‚Üí Shuffle ‚Üí Reduce
- Interpretar progreso de jobs
- Analizar distribuci√≥n de trabajo

‚úÖ **Monitoreo:**

- Usar interfaces web (YARN, HDFS)
- Leer logs de aplicaciones
- Diagnosticar errores comunes

‚úÖ **Exportaci√≥n:**

- Guardar resultados en CSV local
- Exportar a HDFS para compartir
- Crear tablas materializadas

‚úÖ **An√°lisis Avanzado:**

- Window functions (RANK, OVER)
- CTEs (WITH clauses)
- Agregaciones complejas

---

## üöÄ PR√ìXIMOS PASOS

### Nivel Intermedio:

1. **Particionamiento de Tablas:**

   ```sql
   CREATE TABLE ratings_partitioned (
       user_id INT, movie_id INT, rating INT
   )
   PARTITIONED BY (year STRING, month STRING)
   STORED AS ORC;
   ```
2. **Bucketing para Optimizaci√≥n:**

   ```sql
   CREATE TABLE ratings_bucketed (
       user_id INT, movie_id INT, rating INT
   )
   CLUSTERED BY (movie_id) INTO 10 BUCKETS
   STORED AS PARQUET;
   ```
3. **Joins con Otras Tablas:**

   - Cargar `u.item` (informaci√≥n de pel√≠culas)
   - Cargar `u.user` (informaci√≥n demogr√°fica)
   - Realizar an√°lisis combinados

### Nivel Avanzado:

1. **Integraci√≥n con Spark:**

   ```bash
   spark-sql --master yarn
   ```
2. **Formatos Columnares:**

   - ORC (Optimized Row Columnar)
   - Parquet (formato Apache)
   - Comparar rendimiento
3. **Tuning de MapReduce:**

   ```sql
   SET mapreduce.job.reduces=10;
   SET mapreduce.map.memory.mb=4096;
   ```
4. **UDFs (User Defined Functions):**

   - Crear funciones personalizadas en Java
   - Registrar en Hive

---

## üîó RECURSOS ADICIONALES

| Recurso                        | URL                                                                                         |
| ------------------------------ | ------------------------------------------------------------------------------------------- |
| **Hadoop 3.4.0 Docs**    | https://hadoop.apache.org/docs/r3.4.0/                                                      |
| **Hive Language Manual** | https://cwiki.apache.org/confluence/display/Hive/LanguageManual                             |
| **MovieLens Dataset**    | https://grouplens.org/datasets/movielens/                                                   |
| **YARN REST API**        | https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html |
| **HDFS Commands**        | https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html     |

---

<div align="center">

## üéâ ¬°Pr√°ctica Completada con √âxito!

**Has procesado 100,000 registros reales con Hadoop + Hive**

‚úÖ HDFS: Sistema de archivos distribuido configurado
‚úÖ YARN: Jobs MapReduce ejecutados correctamente
‚úÖ Hive: Consultas SQL traducidas a MapReduce
‚úÖ Monitoreo: Interfaces web y logs dominados
‚úÖ Exportaci√≥n: Resultados guardados en CSV y HDFS
‚úÖ Big Data: Conceptos fundamentales aplicados

---

### üìñ Para Estudiar

1. Revisa los logs de YARN de tus consultas m√°s complejas
2. Experimenta cambiando el n√∫mero de reducers
3. Compara tiempos de ejecuci√≥n con diferentes configuraciones
4. Carga los otros archivos del dataset (u.item, u.user) y practica JOINS

---

*Gu√≠a de Estudio Big Data - Febrero 2026*
*Dataset: MovieLens 100K | Hadoop 3.4.0 | Hive 3.3.1*

</div>
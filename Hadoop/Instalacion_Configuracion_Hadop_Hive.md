# üöÄ Instalaci√≥n: CentOS + Hadoop 3.4.0 + Hive 3.1.3

> **Curso:** Sistemas Inteligentes
> **Objetivo:** Configurar un entorno Big Data completo desde cero
> **Modo:** Pseudo-distribuido (un solo nodo)
> **Fecha:** Febrero 2026

---

## üìã Tabla de Contenido

### PARTE I: Configuraci√≥n de CentOS

1. [Requisitos Previos y Descargas](#1-requisitos-previos-y-descargas)
2. [Configuraci√≥n de Red](#2-configuraci√≥n-de-red-y-actualizaci√≥n)
3. [Instalaci√≥n de Interfaz Gr√°fica](#3-instalaci√≥n-de-interfaz-gr√°fica-gui)
4. [VirtualBox Guest Additions](#4-instalaci√≥n-de-virtualbox-guest-additions)

### PARTE II: Instalaci√≥n de Hadoop 3.4.0

5. [Instalaci√≥n de Paquetes Base](#5-instalaci√≥n-de-paquetes-base)
6. [Crear Usuario Hadoop](#6-crear-usuario-hadoop)
7. [Configurar SSH para Usuario Hadoop](#7-configurar-ssh-para-usuario-hadoop)
8. [Instalaci√≥n de Java 8](#8-instalaci√≥n-de-java-8-openjdk)
9. [Registrar Java en el Sistema](#9-registrar-jdk-en-el-sistema-de-alternativas)
10. [Configurar Variables de Entorno Java](#10-configurar-java_home)
11. [Descargar Hadoop](#11-descarga-de-hadoop-340)
12. [Descomprimir Hadoop](#12-descompresi√≥n-y-organizaci√≥n)
13. [Variables de Entorno Hadoop](#13-configurar-variables-de-entorno-hadoop)
14. [Configurar Hostname](#14-cambiar-hostname-a-nodo1)
15. [Configurar core-site.xml](#15-configurar-core-sitexml)
16. [Configurar hdfs-site.xml](#16-configurar-hdfs-sitexml-y-crear-carpetas)
17. [Formatear NameNode](#17-formatear-el-namenode)
18. [Verificar Interfaz Web HDFS](#18-interfaz-web-browse-directory)
19. [Operaciones B√°sicas HDFS](#19-operaciones-b√°sicas-en-hdfs)
20. [Configurar YARN](#20-configuraci√≥n-de-yarn)
21. [Ejecutar MapReduce](#21-ejecutar-mapreduce-wordcount)

### PARTE III: Instalaci√≥n de Apache Hive

22. [Instalar Hive 3.1.3](#22-instalaci√≥n-de-apache-hive-313)
23. [Configurar Variables Hive](#23-configurar-variables-de-entorno-hive)
24. [Resolver Conflictos de Librer√≠as](#24-resolver-conflictos-de-librer√≠as-guava)
25. [Configurar Almacenamiento HDFS](#25-configurar-directorios-hdfs-para-hive)
26. [Configurar Metastore](#26-configurar-hive-sitexml-metastore)
27. [Inicializar Esquema](#27-inicializar-esquema-de-metadatos)
28. [Probar Hive](#28-ejecutar-y-probar-hive)

---

## üéØ PARTE I: CONFIGURACI√ìN DE CENTOS

---

## 1. Requisitos Previos y Descargas

### üì• Software Necesario

| Componente                      | Fuente                                         | Descripci√≥n                    |
| ------------------------------- | ---------------------------------------------- | ------------------------------- |
| **CentOS 10 (Imagen VM)** | https://www.osboxes.org/centos/#centos-10-info | M√°quina virtual preconfigurada |
| **VirtualBox**            | https://www.virtualbox.org/wiki/Downloads      | Software de virtualizaci√≥n     |

### ‚öôÔ∏è Configuraci√≥n Inicial

1. **Descomprimir** la unidad de m√°quina virtual descargada
2. **Abrir VirtualBox** ‚Üí Nueva M√°quina Virtual
3. Seleccionar: **"Usar un archivo de disco duro virtual existente"**
4. **Red**: Configurar como **Adaptador Puente** o **NAT**
5. **Credenciales por defecto:**
   - Usuario: `osboxes`
   - Password: `osboxes.org`

---

## 2. Configuraci√≥n de Red y Actualizaci√≥n

### üîÑ Actualizar el Sistema

```bash
sudo yum update
```

O alternativamente:

```bash
sudo dnf update
```

---

### üåê Soluci√≥n de Problemas de Conexi√≥n

#### Paso 1: Probar Conectividad

```bash
ping -c 4 8.8.8.8
```

**Si recibes:** `Network is unreachable` ‚Üí Tu interfaz de red est√° desactivada

---

#### Paso 2: Identificar y Activar la Interfaz

```bash
# Ver interfaces disponibles
ip addr
```

Busca tu interfaz (generalmente `enp0s3`):

```bash
# M√©todo 1: Con nmcli
sudo nmcli device connect enp0s3

# M√©todo 2: Con ip link
sudo ip link set enp0s3 up
```

---

#### Paso 3: Configurar Inicio Autom√°tico (NMTUI)

```bash
# Abrir configurador de red
sudo nmtui
```

**Navegaci√≥n en NMTUI:**

1. Seleccionar: **"Edit a connection"**
2. Seleccionar tu interfaz (ej: `enp0s3`)
3. Seleccionar: **"Edit"**
4. Marcar con `[X]`: **"Automatically connect"**
5. **OK** ‚Üí **Back** ‚Üí **Quit**

---

#### Paso 4: Solicitar IP (DHCP)

```bash
sudo dhclient
```

**Verificar conexi√≥n:**

```bash
ping -c 4 google.com
```

---

## 3. Instalaci√≥n de Interfaz Gr√°fica (GUI)

> **Nota:** Si prefieres trabajar con entorno gr√°fico en lugar de solo terminal

### üì¶ Instalar GNOME Desktop

```bash
# Instalar grupo de paquetes (800MB - 1GB)
sudo dnf groupinstall "Server with GUI"
```

---

### üñ•Ô∏è Cambiar Modo de Arranque

```bash
# Verificar modo actual
systemctl get-default

# Cambiar a modo gr√°fico
sudo systemctl set-default graphical.target

# Iniciar interfaz gr√°fica ahora (sin reiniciar)
sudo systemctl start graphical.target
```

---

## 4. Instalaci√≥n de VirtualBox Guest Additions

> **Beneficios:** Mejor resoluci√≥n de pantalla, compartir carpetas, portapapeles compartido

### üì¶ Paso A: Instalar Dependencias

```bash
# Instalar repositorio EPEL
sudo dnf install -y epel-release

# Instalar herramientas de desarrollo
sudo dnf install -y gcc make perl kernel-devel kernel-headers bzip2

# Actualizar kernel (IMPORTANTE)
sudo dnf update kernel-*
```

> ‚ö†Ô∏è **Si el kernel se actualiza, reinicia la VM antes de continuar:**

```bash
sudo reboot
```

---

### üíø Paso B: Montar e Instalar Guest Additions

**En el men√∫ de VirtualBox:**

- **Dispositivos** ‚Üí **Insertar imagen de CD de las Guest Additions**

**En la terminal de CentOS:**

```bash
# Crear punto de montaje
sudo mkdir -p /mnt/cdrom

# Montar el CD
sudo mount /dev/cdrom /mnt/cdrom

# Ejecutar instalador
cd /mnt/cdrom
sudo ./VBoxLinuxAdditions.run

# Reiniciar para aplicar cambios
sudo reboot
```

---

### ‚ö†Ô∏è Soluci√≥n de Errores Comunes

Si la instalaci√≥n falla, ejecuta estos comandos de refuerzo:

```bash
# Instalar herramientas de desarrollo completas
sudo dnf groupinstall "Development Tools"
sudo dnf install kernel-devel dkms

# Instalar m√≥dulos espec√≠ficos de VirtualBox
sudo dnf install centos-release-kmods
sudo dnf install virtualbox-guest-additions

# Habilitar y arrancar el servicio
sudo systemctl enable vboxservice
sudo systemctl start vboxservice
```

---

### üí° Tip de Estudio

> Crea **snapshots (instant√°neas)** en VirtualBox antes de realizar cambios cr√≠ticos para poder volver atr√°s si algo falla.

---

---

## üêò PARTE II: INSTALACI√ìN DE HADOOP 3.4.0

> **Basado en:** Playlist "Big Data Hadoop Espa√±ol" üî•
> **Enlace:** https://www.youtube.com/playlist?list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B

---

## 5. Instalaci√≥n de Paquetes Base

> **Video #5:** https://www.youtube.com/watch?v=49f8rpFV8BY&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=5

### üì¶ Instalar Herramientas de Red

```bash
# Herramientas de red (ifconfig, netstat, etc.)
sudo yum install net-tools

# Wget para descargas desde internet
sudo yum install wget

# Telnet para pruebas de conectividad
sudo yum install telnet
```

---

### üåê Obtener IP de la M√°quina Virtual

```bash
ifconfig
```

**Anota tu IP** (algo como `10.0.2.15` o `192.168.x.x`), la necesitar√°s m√°s adelante.

---

## 6. Crear Usuario Hadoop

> **Video #6:** https://www.youtube.com/watch?v=B9x3v4fD-4E&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=6

### üë§ Crear Usuario y Asignar Permisos

```bash
# Crear el usuario hadoop
sudo useradd hadoop

# Asignar contrase√±a
sudo passwd hadoop
# (Ingresa la contrase√±a dos veces - los caracteres no se ver√°n)
```

---

### üîê Darle Permisos de Administrador (Sudo/Root)

> **‚ö†Ô∏è IMPORTANTE:** Esto permite que el usuario hadoop ejecute comandos con privilegios de root usando `sudo`.
> **Recomendaci√≥n:** Solo para entornos de **desarrollo/aprendizaje**. En **producci√≥n**, limitar permisos espec√≠ficos.

```bash
# OPCI√ìN 1: Agregar al grupo wheel (m√©todo recomendado en CentOS/RHEL)
sudo usermod -aG wheel hadoop

# OPCI√ìN 2: Agregar entrada en sudoers (m√©todo alternativo)
# Editar archivo sudoers de forma segura
sudo visudo

# Agregar esta l√≠nea al final del archivo:
# hadoop ALL=(ALL) NOPASSWD: ALL
# (NOPASSWD permite ejecutar sudo sin pedir contrase√±a - √∫til para scripts)

# OPCI√ìN 3: Sin contrase√±a solo para comandos espec√≠ficos
# hadoop ALL=(ALL) NOPASSWD: /opt/hadoop/hadoop-3.4.0/sbin/*, /usr/bin/systemctl
```

**üí° Explicaci√≥n de Opciones:**

| Opci√≥n                                     | Seguridad | Uso                    | Requiere Password |
| ------------------------------------------- | --------- | ---------------------- | ----------------- |
| **Opci√≥n 1** (wheel)                 | Media     | Desarrollo/Producci√≥n | ‚úÖ S√≠            |
| **Opci√≥n 2** (NOPASSWD: ALL)         | Baja      | Solo desarrollo        | ‚ùå No             |
| **Opci√≥n 3** (comandos espec√≠ficos) | Alta      | Producci√≥n            | ‚ùå No             |

**‚úÖ Verificar permisos:**

```bash
# Ver grupos del usuario hadoop
groups hadoop
# Esperado: hadoop wheel

# Probar sudo (desde usuario hadoop)
sudo whoami
# Esperado: root

# Verificar entrada en sudoers
sudo grep hadoop /etc/sudoers
```

---

### üìÅ Crear Carpeta y Asignar Permisos

```bash
# Crear carpeta en /opt
sudo mkdir /opt/hadoop

# Cambiar propietario al usuario hadoop
sudo chown -R hadoop:hadoop /opt/hadoop

# Dar permisos de lectura, escritura y ejecuci√≥n
sudo chmod -R 755 /opt/hadoop
```

---

### üîÑ Cambiar al Usuario Hadoop

```bash
# Cambiar de root a hadoop (el guion '-' es importante)
su - hadoop
```

> **Tip:** El guion `-` carga las variables de entorno y te sit√∫a en `/home/hadoop`

---

## 7. Configurar SSH para Usuario Hadoop

> **‚ö†Ô∏è CR√çTICO:** Esta configuraci√≥n **DEBE** hacerse con el **usuario hadoop**, NO con root u otro usuario.
> **Si no se configura correctamente, YARN y HDFS NO podr√°n iniciar los servicios** y aparecer√°n errores de "Permission denied".

### üîë ¬øPor Qu√© es Necesario SSH?

Hadoop utiliza SSH para comunicarse entre procesos (NameNode, DataNode, ResourceManager, NodeManager) incluso en modo pseudo-distribuido (un solo nodo). Sin SSH configurado, los servicios no pueden iniciarse autom√°ticamente.

---

### üìã Pasos de Configuraci√≥n

> **IMPORTANTE:** Ejecutar TODOS estos comandos como **usuario hadoop**

```bash
# Asegurarse de estar como usuario hadoop
whoami
# Debe mostrar: hadoop

# Si no est√°s como hadoop, cambiar:
su - hadoop
```

---

### Paso 1: Generar la Llave RSA

Este comando crea la identidad digital del usuario. El par√°metro `-P ""` asegura que no se pida una frase de paso, lo cual es vital para la automatizaci√≥n de Hadoop.

```bash
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
```

**Salida esperada:**

```
Generating public/private rsa key pair.
Created directory '/home/hadoop/.ssh'.
Your identification has been saved in /home/hadoop/.ssh/id_rsa
Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub
```

---

### Paso 2: Configurar el Acceso de Confianza (Self-Login)

Hadoop necesita conectarse a `localhost` y al hostname (en este caso `nodo1`) para levantar los demonios de HDFS y YARN.

```bash
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

**üí° Explicaci√≥n:** Este comando agrega tu llave p√∫blica a la lista de llaves autorizadas, permitiendo que el usuario hadoop se conecte a s√≠ mismo sin contrase√±a.

---

### Paso 3: Establecer Permisos de Seguridad Estrictos

SSH ignorar√° las llaves si los permisos son demasiado abiertos, manteniendo el error de "Permission denied".

```bash
# Permisos del directorio .ssh (solo el propietario puede acceder)
chmod 700 ~/.ssh

# Permisos del archivo de llaves autorizadas (solo el propietario puede leer/escribir)
chmod 600 ~/.ssh/authorized_keys
```

---

### Paso 4: Validar el Acceso al Hostname

Es crucial que realices una conexi√≥n manual **la primera vez** para registrar el "fingerprint" del nodo en el archivo `known_hosts`. Ejecuta estos comandos y **escribe `yes`** cuando se te pregunte:

```bash
# Conectar a localhost
ssh localhost
# Escribir: yes
# Salir de la sesi√≥n SSH
exit

# Conectar a nodo1 (hostname que configurar√°s despu√©s)
ssh nodo1
# Escribir: yes
# Salir de la sesi√≥n SSH
exit
```

**Mensaje esperado en primera conexi√≥n:**

```
The authenticity of host 'localhost (127.0.0.1)' can't be established.
RSA key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxx.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'localhost' (RSA) to the list of known hosts.
```

---

### ‚úÖ Verificar Configuraci√≥n SSH

```bash
# Probar conexi√≥n sin contrase√±a a localhost
ssh localhost "echo 'SSH funcionando correctamente'"
```

**Salida esperada:**

```
SSH funcionando correctamente
```

**Si NO pide contrase√±a y muestra el mensaje, la configuraci√≥n es correcta.**

---

### üîß Verificar Archivos Creados

```bash
# Ver estructura del directorio .ssh
ls -la ~/.ssh/
```

**Salida esperada:**

```
drwx------  2 hadoop hadoop 4096 Feb  5 10:00 .
drwx------. 3 hadoop hadoop 4096 Feb  5 09:50 ..
-rw-------  1 hadoop hadoop 1679 Feb  5 10:00 id_rsa
-rw-r--r--  1 hadoop hadoop  394 Feb  5 10:00 id_rsa.pub
-rw-------  1 hadoop hadoop  394 Feb  5 10:00 authorized_keys
-rw-r--r--  1 hadoop hadoop  444 Feb  5 10:05 known_hosts
```

---

### ‚ö†Ô∏è Errores Comunes y Soluciones

#### Error: "Permission denied (publickey)"

**Causa:** Permisos incorrectos en archivos SSH

**Soluci√≥n:**

```bash
chmod 700 ~/.ssh
chmod 600 ~/.ssh/authorized_keys
chmod 600 ~/.ssh/id_rsa
chmod 644 ~/.ssh/id_rsa.pub
```

---

#### Error: "Could not create directory '/home/hadoop/.ssh'"

**Causa:** No tienes permisos en tu directorio home

**Soluci√≥n:**

```bash
# Como root, arreglar permisos
sudo chown -R hadoop:hadoop /home/hadoop
sudo chmod 755 /home/hadoop

# Volver a intentar como hadoop
su - hadoop
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
```

---

#### Error: "Host key verification failed"

**Causa:** No se ha aceptado el fingerprint del host

**Soluci√≥n:**

```bash
# Conectarse manualmente y aceptar con 'yes'
ssh localhost
# Escribir: yes
exit
```

---

### üéØ Resumen de Comandos (Copy-Paste R√°pido)

```bash
# 1. Cambiar a usuario hadoop (si no lo est√°s)
su - hadoop

# 2. Generar llave RSA
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa

# 3. Configurar acceso de confianza
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

# 4. Establecer permisos
chmod 700 ~/.ssh
chmod 600 ~/.ssh/authorized_keys

# 5. Validar acceso (aceptar con 'yes')
ssh localhost
exit

# 6. Verificar que funciona sin contrase√±a
ssh localhost "echo 'SSH OK'"
```

---

### üí° Importancia para Hadoop

‚úÖ **Con SSH configurado:**

- `start-dfs.sh` inicia NameNode, DataNode y SecondaryNameNode autom√°ticamente
- `start-yarn.sh` inicia ResourceManager y NodeManager autom√°ticamente
- Los servicios pueden comunicarse entre s√≠

‚ùå **Sin SSH configurado:**

- Los scripts de inicio fallan con "Permission denied"
- Necesitas iniciar cada servicio manualmente
- YARN no puede gestionar recursos correctamente
- MapReduce jobs fallar√°n

---

## 8. Instalaci√≥n de Java 8 OpenJDK

> **Video #7:** https://www.youtube.com/watch?v=1rpJHLYim_k&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=7

### üì• Descargar Java 8

**Fuente:** https://www.oracle.com/latam/java/technologies/javase/javase8-archive-downloads.html

> **Nota:** Necesitas registrarte en Oracle para descargar

**Archivo a descargar:** `jdk-8u202-linux-x64.tar.gz`

---

### üìÇ Mover y Descomprimir

```bash
# Mover el archivo desde Downloads a /opt
sudo mv /home/hadoop/Downloads/jdk-8u202-linux-x64.tar.gz /opt/

# Entrar a /opt
cd /opt/

# Descomprimir
sudo tar -zxvf jdk-8u202-linux-x64.tar.gz

# Verificar carpeta resultante
ls -l /opt/
# Deber√≠as ver: jdk1.8.0_202
```

---

### üîê Asignar Permisos al Usuario Hadoop

```bash
sudo chown -R hadoop:hadoop /opt/jdk1.8.0_202
```

---

### üßπ Limpiar Archivo Comprimido (Opcional)

```bash
# Eliminar el .tar.gz para liberar espacio
sudo rm /opt/jdk-8u202-linux-x64.tar.gz
```

---

## 9. Registrar JDK en el Sistema de Alternativas

> **Video #8:** https://www.youtube.com/watch?v=fNKL7IZs0LA&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=8

### üîß Registrar Ejecutables de Java

```bash
# Registrar 'java'
sudo alternatives --install /usr/bin/java java /opt/jdk1.8.0_202/bin/java 2

# Configurar java como predeterminado
sudo alternatives --config java
# Selecciona el n√∫mero correspondiente a /opt/jdk1.8.0_202/bin/java

# Registrar 'jar'
sudo alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_202/bin/jar 2

# Registrar 'javac' (compilador - necesario para Hadoop)
sudo alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_202/bin/javac 2
```

---

### ‚úÖ Verificar Instalaci√≥n

```bash
# Verificar versi√≥n de Java
java -version
# Salida esperada: java version "1.8.0_202"

# Verificar compilador
javac -version
# Salida esperada: javac 1.8.0_202
```

---

## 10. Configurar JAVA_HOME

> **Video #9:** https://www.youtube.com/watch?v=0VPMiQifwfo&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=9

### üîß Editar .bashrc del Usuario Hadoop

```bash
# Cambiar al usuario hadoop
su - hadoop

# Ir al home
cd /home/hadoop/

# Editar archivo de configuraci√≥n
nano .bashrc
```

---

### üìù Agregar al Final del Archivo

```bash
# Configuraci√≥n de Java
export JAVA_HOME=/opt/jdk1.8.0_202
export JRE_HOME=/opt/jdk1.8.0_202/jre
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
```

**Guardar:** `Ctrl + O` ‚Üí `Enter` ‚Üí `Ctrl + X`

---

### üîÑ Recargar Variables de Entorno

```bash
source /home/hadoop/.bashrc

# Verificar que se carg√≥ correctamente
echo $JAVA_HOME
# Salida esperada: /opt/jdk1.8.0_202
```

---

## 11. Descarga de Hadoop 3.4.0

> **Video #10:** https://www.youtube.com/watch?v=wi_DoY8jirI&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=10

### üì• Descargar Hadoop

```bash
# Entrar a la carpeta de hadoop
cd /opt/hadoop/

# Descargar con wget
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz

# Verificar descarga
ls -lh hadoop-3.4.0.tar.gz
# Deber√≠as ver el archivo (~600 MB)
```

---

## 12. Descompresi√≥n y Organizaci√≥n

> **Video #11:** https://www.youtube.com/watch?v=d3k-LZQgPoI&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=11

### üì¶ Descomprimir Hadoop

```bash
# Descomprimir en /opt/hadoop
tar -zxvf hadoop-3.4.0.tar.gz

# Verificar carpeta resultante
ls -l
# Deber√≠as ver: hadoop-3.4.0/

# Eliminar archivo comprimido (opcional)
rm hadoop-3.4.0.tar.gz
```

---

## 13. Configurar Variables de Entorno Hadoop

> **Video #12:** https://www.youtube.com/watch?v=8jEmG80fG8U&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=12

### üîß Editar .bashrc

```bash
# Ir al home del usuario hadoop
cd /home/hadoop/

# Editar .bashrc
nano .bashrc
```

---

### üìù Agregar Variables de Hadoop

```bash
# Configuraci√≥n de Hadoop
export HADOOP_HOME=/opt/hadoop/hadoop-3.4.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

**Guardar:** `Ctrl + O` ‚Üí `Enter` ‚Üí `Ctrl + X`

---

### üîÑ Recargar y Verificar

```bash
# Recargar variables
source /home/hadoop/.bashrc

# Verificar versi√≥n de Hadoop
hadoop version
```

**Salida esperada:**

```
Hadoop 3.4.0
Source code repository https://github.com/apache/hadoop.git -r ...
Compiled by ... on ...
```

---

## 14. Cambiar Hostname a nodo1

> **Video #14:** https://www.youtube.com/watch?v=tYBytDlwWIQ&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=14

### üñ•Ô∏è Configurar Nombre del Host

```bash
# Establecer hostname
sudo nmcli general hostname nodo1

# Verificar cambio
hostname
# Salida esperada: nodo1
```

---

### üìù Actualizar Archivo /etc/hosts

```bash
# Editar archivo de hosts
sudo nano /etc/hosts
```

**Agregar o modificar estas l√≠neas:**

```
127.0.0.1   localhost nodo1
::1         localhost nodo1
10.0.2.15   nodo1
```

> **Importante:** Reemplaza `10.0.2.15` con la IP que obtuviste con `ifconfig`

**Guardar:** `Ctrl + O` ‚Üí `Enter` ‚Üí `Ctrl + X`

---

## 15. Configurar core-site.xml

> **Video #16:** https://www.youtube.com/watch?v=rvloXElUp2w&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=16

### üìù Editar Archivo de Configuraci√≥n

```bash
# Editar core-site.xml
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/core-site.xml
```

---

### üîß Contenido de core-site.xml

**Agregar dentro de `<configuration>`:**

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://nodo1:9000</value>
        <description>NameNode URI</description>
    </property>
</configuration>
```

**üí° Explicaci√≥n de la Configuraci√≥n:**

- **`fs.defaultFS`**: Define el sistema de archivos predeterminado de Hadoop
  - `hdfs://nodo1:9000`: URI completo del NameNode
  - `nodo1`: Hostname del servidor donde corre el NameNode
  - `9000`: Puerto de comunicaci√≥n del NameNode
  - Esta configuraci√≥n permite que todos los componentes de Hadoop sepan d√≥nde encontrar el NameNode para acceder a HDFS

---

### üî• Abrir Puerto en Firewall

```bash
# Abrir puerto 9000 para HDFS
sudo firewall-cmd --zone=public --add-port=9000/tcp --permanent

# Recargar firewall
sudo firewall-cmd --reload

# Verificar puertos abiertos
sudo firewall-cmd --list-ports
```

---

## 16. Configurar hdfs-site.xml y Crear Carpetas

> **Video #17:** https://www.youtube.com/watch?v=eIYX_IXVoU0&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=17

### üìù Editar hdfs-site.xml

```bash
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/hdfs-site.xml
```

---

### üîß Contenido de hdfs-site.xml

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <description>Factor de replicaci√≥n (1 para un solo nodo)</description>
    </property>
  
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/datos/namenode</value>
        <description>Directorio de metadatos del NameNode</description>
    </property>
  
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/datos/datanode</value>
        <description>Directorio de almacenamiento del DataNode</description>
    </property>
</configuration>
```

**üí° Explicaci√≥n de la Configuraci√≥n:**

- **`dfs.replication`**: N√∫mero de r√©plicas de cada bloque de datos en HDFS

  - Valor `1`: Solo una copia (apropiado para entorno de un solo nodo)
  - En clusters reales se usa `3` para alta disponibilidad
  - M√°s r√©plicas = mayor tolerancia a fallos, pero m√°s espacio usado
- **`dfs.namenode.name.dir`**: Directorio donde el NameNode almacena metadatos

  - `/datos/namenode`: Ruta f√≠sica en el disco local
  - Contiene informaci√≥n sobre la estructura de archivos HDFS
  - **Cr√≠tico**: Si se pierde, se pierde toda la informaci√≥n de HDFS
  - En producci√≥n se recomienda usar m√∫ltiples directorios para redundancia
- **`dfs.datanode.data.dir`**: Directorio donde el DataNode almacena los bloques de datos

  - `/datos/datanode`: Ruta f√≠sica para almacenamiento de datos
  - Aqu√≠ se guardan los bloques reales de archivos (datos)
  - Puede configurarse con m√∫ltiples directorios separados por comas para usar varios discos

---

### üìÅ Crear Carpetas de Datos

```bash
# Ir a la ra√≠z del sistema
cd /

# Crear estructura de directorios
sudo mkdir /datos
cd /datos
sudo mkdir namenode
sudo mkdir datanode

# Asignar permisos al usuario hadoop
sudo chown -R hadoop:hadoop /datos

# Verificar
ls -l /datos
```

---

## 17. Formatear el NameNode

> **Video #18:** https://www.youtube.com/watch?v=rJFrPBtciXY&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=18

### üîß Inicializar HDFS

```bash
# Formatear el NameNode (solo la primera vez)
hdfs namenode -format
```

**Salida esperada:**

```
Storage directory /datos/namenode has been successfully formatted.
```

---

### üöÄ Iniciar Servicios HDFS

```bash
# Iniciar HDFS (NameNode, DataNode, SecondaryNameNode)
start-dfs.sh
```

**El comando iniciar√°:**

- NameNode en `nodo1`
- DataNode en `nodo1`
- Secondary NameNode en `nodo1`

---

### ‚úÖ Verificar Servicios Activos

```bash
# Ver procesos Java en ejecuci√≥n
jps
```

**Salida esperada:**

```
12345 NameNode
12346 DataNode
12347 SecondaryNameNode
12348 Jps
```

---

## 18. Interfaz Web HDFS (Browse Directory)

> **Video HDFS Hadoop #1:** https://www.youtube.com/watch?v=38DgYWd7fYg&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=19

### üåê Acceder a la Interfaz Web

**Abrir en navegador:**

```
http://localhost:9870
```

O desde otra m√°quina:

```
http://tu_ip_centos:9870
```

> **Nota:** En versiones anteriores de Hadoop el puerto era `50070`

---

### üî• Abrir Puerto para Interfaz Web

```bash
# Abrir puerto 9870
sudo firewall-cmd --zone=public --add-port=9870/tcp --permanent
sudo firewall-cmd --reload
```

---

### üìä Funciones de la Interfaz Web

| Secci√≥n                      | Descripci√≥n                                         |
| ----------------------------- | ---------------------------------------------------- |
| **Overview**            | Estado general del cluster, espacio usado/disponible |
| **Datanodes**           | Lista de DataNodes activos                           |
| **Utilities ‚Üí Browse** | Explorador de archivos HDFS                          |
| **Logs**                | Logs del NameNode                                    |

---

## 19. Operaciones B√°sicas en HDFS

> **Video HDFS Hadoop #2.1:** https://www.youtube.com/watch?v=PtcoKR9x0t0&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=20

### üìÑ Crear Archivo de Prueba

```bash
# Crear archivo local
echo "Hola Mundo Hadoop HDFS" >> prueba.txt

# Ver contenido
cat prueba.txt
```

---

### üìÅ Crear Carpeta en HDFS

```bash
# Crear directorio en HDFS
hdfs dfs -mkdir /prueba

# Listar contenido de ra√≠z
hdfs dfs -ls /
```

---

### üì§ Subir Archivo a HDFS

```bash
# Subir archivo local a HDFS
hdfs dfs -put prueba.txt /prueba/

# Verificar
hdfs dfs -ls /prueba
```

---

### üì• Descargar Archivo desde HDFS

```bash
# Descargar archivo de HDFS a local
hdfs dfs -get /prueba/prueba.txt ./prueba_descargado.txt

# Verificar
cat prueba_descargado.txt
```

---

### üëÅÔ∏è Ver Contenido de Archivo en HDFS

```bash
# Ver contenido completo
hdfs dfs -cat /prueba/prueba.txt

# Ver primeras l√≠neas
hdfs dfs -head /prueba/prueba.txt
```

---

### üóëÔ∏è Eliminar Archivos y Carpetas

```bash
# Eliminar archivo espec√≠fico
hdfs dfs -rm /prueba/prueba.txt

# Eliminar carpeta y contenido (recursivo)
hdfs dfs -rm -r /prueba

# Eliminar permanentemente (sin papelera)
hdfs dfs -rm -r -skipTrash /prueba
```

---

### üìä Comandos √ötiles Adicionales

```bash
# Ver tama√±o de archivo
hdfs dfs -du -h /ruta/archivo

# Copiar archivo dentro de HDFS
hdfs dfs -cp /origen/archivo /destino/

# Mover archivo dentro de HDFS
hdfs dfs -mv /origen/archivo /destino/

# Ver espacio usado/disponible
hdfs dfs -df -h

# Ver informaci√≥n de bloques
hdfs fsck /ruta/archivo -files -blocks -locations
```

---

## 20. Configuraci√≥n de YARN

> **Video MapReduce con Hadoop #1:** https://www.youtube.com/watch?v=R7w8FAlnhAw&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=23

### üìù Configurar mapred-site.xml

```bash
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/mapred-site.xml
```

**Contenido:**

```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                 <value>nodo1</value>
         </property>
         <property>
                 <name>yarn.nodemanager.aux-services</name>
                 <value>mapreduce_shuffle</value>
         </property>
         <property>
                 <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
                 <value>org.apache.hadoop.mapred.ShuffleHandler</value>
         </property>
</configuration>
```

**üí° Explicaci√≥n de la Configuraci√≥n:**

- **`yarn.resourcemanager.hostname`**: Especifica el host donde corre el ResourceManager de YARN

  - Valor `nodo1`: Nombre del nodo que gestionar√° los recursos del cluster
  - YARN necesita saber d√≥nde est√° el ResourceManager para coordinar jobs
- **`yarn.nodemanager.aux-services`**: Servicios auxiliares que ejecuta cada NodeManager

  - Valor `mapreduce_shuffle`: Habilita el servicio de shuffle para MapReduce
  - Shuffle: Fase donde se redistribuyen datos entre Map y Reduce
  - Esencial para que MapReduce funcione correctamente
- **`yarn.nodemanager.aux-services.mapreduce_shuffle.class`**: Clase Java que implementa el servicio de shuffle

  - `org.apache.hadoop.mapred.ShuffleHandler`: Manejador oficial de Apache
  - Gestiona la transferencia de datos entre mappers y reducers

---

### üìù Configurar yarn-site.xml

```bash
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/yarn-site.xml
```

**Contenido:**

```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>nodo1</value>
        <description>Host del ResourceManager</description>
    </property>
  
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
        <description>Servicio auxiliar para MapReduce</description>
    </property>
  
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
  
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>0.0.0.0:8088</value>
        <description>Puerto de la interfaz web de YARN</description>
    </property>
  
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
        <description>Deshabilitar verificaci√≥n de memoria virtual</description>
    </property>
</configuration>
```

**üí° Explicaci√≥n de la Configuraci√≥n:**

- **`yarn.resourcemanager.hostname`**: Host del ResourceManager (cerebro de YARN)

  - Coordina la asignaci√≥n de recursos (CPU, memoria) a las aplicaciones
  - Todos los NodeManagers se comunican con √©l
- **`yarn.nodemanager.aux-services`**: Servicios auxiliares para MapReduce

  - `mapreduce_shuffle`: Permite la fase de shuffle en jobs MapReduce
  - Sin esto, los jobs MapReduce fallar√°n
- **`yarn.nodemanager.aux-services.mapreduce_shuffle.class`**: Implementaci√≥n del shuffle

  - Define qu√© clase Java maneja el intercambio de datos
- **`yarn.resourcemanager.webapp.address`**: Puerto de la interfaz web de YARN

  - `0.0.0.0:8088`: Escucha en todas las interfaces en el puerto 8088
  - Permite monitorear jobs y recursos desde http://localhost:8088
- **`yarn.nodemanager.vmem-check-enabled`**: Desactiva verificaci√≥n de memoria virtual

  - Valor `false`: Evita errores por exceso de memoria virtual
  - En entornos de desarrollo previene problemas de l√≠mites de memoria
  - En producci√≥n se recomienda `true` para mejor control de recursos

---

### üî• Abrir Puerto YARN

```bash
# Abrir puerto 8088 para YARN
sudo firewall-cmd --zone=public --add-port=8088/tcp --permanent
sudo firewall-cmd --reload
```

---

### üöÄ Iniciar Servicios YARN

```bash
# Detener HDFS primero
stop-dfs.sh

# Reiniciar HDFS
start-dfs.sh

# Iniciar YARN
start-yarn.sh
```

---

### ‚úÖ Verificar Servicios

```bash
# Ver procesos activos
jps
```

**Salida esperada:**

```
12345 NameNode
12346 DataNode
12347 SecondaryNameNode
12348 ResourceManager
12349 NodeManager
12350 Jps
```

---

### üåê Interfaz Web de YARN

**Abrir en navegador:**

```
http://localhost:8088/cluster/
```

O desde otra m√°quina:

```
http://tu_ip_centos:8088/cluster/
```

---

### üéØ Comandos de Inicio/Cierre R√°pido

```bash
# Iniciar todo (HDFS + YARN)
start-all.sh

# Detener todo
stop-all.sh

# Solo HDFS
start-dfs.sh
stop-dfs.sh

# Solo YARN
start-yarn.sh
stop-yarn.sh
```

---

## 21. Ejecutar MapReduce (WordCount)

> **Video MapReduce con Hadoop #3:** https://www.youtube.com/watch?v=woUzV_liwto&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=25

### üìÑ Preparar Datos de Entrada

```bash
# Descargar archivo de texto (ejemplo: Los Miserables)
# Puedes usar cualquier archivo .txt grande

# Crear carpeta en HDFS
hdfs dfs -mkdir /libros

# Subir archivo
hdfs dfs -put Los_Miserables.txt /libros/

# Verificar
hdfs dfs -ls /libros
```

---

### üöÄ Ejecutar Job de MapReduce

```bash
# Ir a la carpeta de ejemplos
cd /opt/hadoop/hadoop-3.4.0/share/hadoop/mapreduce/

# Ejecutar WordCount
hadoop jar hadoop-mapreduce-examples-3.4.0.jar wordcount /libros /libros_salida
```

---

### üìä Flujo de MapReduce

**Lo que sucede internamente:**

1. **Map Phase:** Divide el texto y asigna "1" a cada palabra

   - Ejemplo: "Hadoop" ‚Üí ("Hadoop", 1)
2. **Shuffle & Sort:** YARN agrupa palabras iguales

   - Ejemplo: "Hadoop" ‚Üí [1, 1, 1]
3. **Reduce Phase:** Suma los valores

   - Ejemplo: "Hadoop" ‚Üí 3

---

### üì• Revisar Resultados

```bash
# Listar archivos generados
hdfs dfs -ls /libros_salida

# Ver contenido del resultado
hdfs dfs -cat /libros_salida/part-r-00000

# Ver primeras l√≠neas
hdfs dfs -cat /libros_salida/part-r-00000 | head -20
```

**Salida ejemplo:**

```
hadoop  150
mapreduce  89
yarn  67
hdfs  234
...
```

---

### üåê Monitoreo en YARN Web UI

Mientras el job se ejecuta, abre:

```
http://localhost:8088
```

Ver√°s:

- Estado: **RUNNING** ‚Üí **FINISHED**
- Progreso: Map % ‚Üí Shuffle % ‚Üí Reduce %
- Memoria usada
- Tiempo de ejecuci√≥n

---

### üîÑ Ejecutar de Nuevo

> **Nota:** MapReduce nunca sobreescribe carpetas de salida

```bash
# Eliminar carpeta de salida anterior
hdfs dfs -rm -r /libros_salida

# Ejecutar nuevamente
hadoop jar hadoop-mapreduce-examples-3.4.0.jar wordcount /libros /libros_salida
```

---

### üìä Otros Ejemplos de MapReduce

```bash
# Pi (estimaci√≥n de œÄ usando Monte Carlo)
hadoop jar hadoop-mapreduce-examples-3.4.0.jar pi 10 100

# Grep (buscar patrones en archivos)
hadoop jar hadoop-mapreduce-examples-3.4.0.jar grep /libros /grep_salida 'hadoop'

# TeraSort (ordenar grandes vol√∫menes de datos)
hadoop jar hadoop-mapreduce-examples-3.4.0.jar teragen 1000 /tera_input
hadoop jar hadoop-mapreduce-examples-3.4.0.jar terasort /tera_input /tera_output
```

---

---

## üêù PARTE III: INSTALACI√ìN DE APACHE HIVE

---

## 22. Instalaci√≥n de Apache Hive 3.1.3

### üì• Descargar Hive

```bash
# Ir a /opt
cd /opt

# Descargar Hive 3.1.3
sudo wget https://archive.apache.org/dist/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz

# Descomprimir
sudo tar -zxvf apache-hive-3.1.3-bin.tar.gz

# Renombrar para simplificar
sudo mv apache-hive-3.1.3-bin /opt/hive

# Asignar permisos al usuario hadoop
sudo chown -R hadoop:hadoop /opt/hive
```

---

## 23. Configurar Variables de Entorno Hive

### üîß Editar .bashrc

```bash
# Cambiar a usuario hadoop
su - hadoop

# Editar .bashrc
nano /home/hadoop/.bashrc
```

**Agregar al final:**

```bash
# Configuraci√≥n de Hive
export HIVE_HOME=/opt/hive
export PATH=$PATH:$HIVE_HOME/bin
```

**Guardar y recargar:**

```bash
source /home/hadoop/.bashrc

# Verificar
echo $HIVE_HOME
# Salida esperada: /opt/hive
```

---

## 24. Resolver Conflictos de Librer√≠as (Guava)

> **Problema:** Hive 3.1.3 incluye Guava 19.0 que es incompatible con Hadoop 3.4.0

### üîß Fix de Guava

```bash
# Eliminar librer√≠a obsoleta de Hive
rm /opt/hive/lib/guava-19.0.jar

# Copiar versi√≥n compatible desde Hadoop
cp /opt/hadoop/hadoop-3.4.0/share/hadoop/common/lib/guava-*.jar /opt/hive/lib/

# Verificar
ls /opt/hive/lib/ | grep guava
# Salida esperada: guava-27.0-jre.jar (o versi√≥n superior)
```

---

## 25. Configurar Directorios HDFS para Hive

### üìÅ Crear Carpetas en HDFS

```bash
# Asegurar que HDFS est√° corriendo
start-dfs.sh

# Crear carpeta temporal
hdfs dfs -mkdir -p /tmp

# Crear warehouse (almac√©n de tablas)
hdfs dfs -mkdir -p /user/hive/warehouse

# Dar permisos de escritura
hdfs dfs -chmod g+w /tmp
hdfs dfs -chmod g+w /user/hive/warehouse

# Verificar
hdfs dfs -ls /user/hive/
```

---

## 26. Configurar hive-site.xml (Metastore)

### üìù Crear Archivo de Configuraci√≥n

```bash
# Crear hive-site.xml
nano /opt/hive/conf/hive-site.xml
```

**Contenido completo:**

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Configuraci√≥n de Metastore con Derby -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:derby:;databaseName=metastore_db;create=true</value>
        <description>URL de conexi√≥n a la base de datos Derby embebida</description>
    </property>
  
    <!-- Directorio warehouse en HDFS -->
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
        <description>Ubicaci√≥n del warehouse en HDFS</description>
    </property>
  
    <!-- Configuraci√≥n adicional -->
    <property>
        <name>hive.metastore.uris</name>
        <value/>
        <description>URI del metastore (vac√≠o para modo embebido)</description>
    </property>
  
    <property>
        <name>hive.server2.enable.doAs</name>
        <value>false</value>
        <description>Deshabilitar suplantaci√≥n de usuario</description>
    </property>
</configuration>
```

**üí° Explicaci√≥n de la Configuraci√≥n:**

- **`javax.jdo.option.ConnectionURL`**: URL de conexi√≥n a la base de datos del metastore

  - `jdbc:derby:`: Usa Apache Derby (base de datos embebida en Java)
  - `databaseName=metastore_db`: Nombre de la base de datos para metadatos
  - `create=true`: Crea la base de datos autom√°ticamente si no existe
  - El metastore guarda informaci√≥n sobre tablas, columnas, particiones, etc.
  - **Nota**: Derby es solo para desarrollo; en producci√≥n usar MySQL/PostgreSQL
- **`hive.metastore.warehouse.dir`**: Directorio ra√≠z en HDFS donde Hive almacena datos de tablas

  - `/user/hive/warehouse`: Ubicaci√≥n predeterminada
  - Cada tabla crear√° un subdirectorio aqu√≠
  - Ejemplo: tabla `usuarios` estar√° en `/user/hive/warehouse/usuarios`
- **`hive.metastore.uris`**: URI del servicio metastore (vac√≠o para modo embebido)

  - Vac√≠o: Metastore embebido (corre en el mismo proceso que Hive)
  - En producci√≥n se configura un metastore remoto para compartir entre usuarios
- **`hive.server2.enable.doAs`**: Suplantaci√≥n de identidad de usuario

  - `false`: Todas las operaciones se ejecutan como el usuario que inici√≥ Hive
  - `true`: Cada usuario ejecutar√≠a operaciones con su propia identidad
  - En desarrollo `false` simplifica la configuraci√≥n

---

## 27. Inicializar Esquema de Metadatos

### üîß Formatear Base de Datos de Metastore

```bash
# Inicializar esquema con Derby
schematool -initSchema -dbType derby
```

**Salida esperada:**

```
Initialization script completed
schemaTool completed
```

---

### ‚ö†Ô∏è Soluci√≥n de Errores Comunes

#### Error: "schematool: command not found"

```bash
# Verificar PATH
echo $PATH | grep hive

# Si no aparece, recargar .bashrc
source ~/.bashrc
```

#### Error: "metastore_db already exists"

```bash
# Eliminar base de datos antigua
rm -rf metastore_db/

# Reinicializar
schematool -initSchema -dbType derby
```

---

## 28. Ejecutar y Probar Hive

### üöÄ Iniciar Hive

```bash
# Asegurar que HDFS y YARN est√°n corriendo
start-all.sh

# Iniciar consola de Hive
hive
```

**Prompt esperado:**

```
hive>
```

---

### üìä Comandos B√°sicos de HiveQL

#### Ver Bases de Datos

```sql
-- Ver bases de datos disponibles
SHOW DATABASES;

-- Usar base de datos
USE default;
```

---

#### Crear Tabla

```sql
-- Crear tabla simple
CREATE TABLE usuarios (
    id INT,
    nombre STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;
```

---

#### Insertar Datos

```sql
-- Insertar registros individuales
INSERT INTO usuarios VALUES (1, 'Gemini');
INSERT INTO usuarios VALUES (2, 'Hadoop');
INSERT INTO usuarios VALUES (3, 'Spark');
INSERT INTO usuarios VALUES (4, 'Kafka');
INSERT INTO usuarios VALUES (5, 'Flink');
INSERT INTO usuarios VALUES (6, 'HBase');
```

> **Nota:** Cada INSERT ejecuta un job MapReduce (lento). En producci√≥n se cargan archivos masivos.

---

#### Consultar Datos

```sql
-- Ver todos los registros
SELECT * FROM usuarios;

-- Filtrar por ID
SELECT * FROM usuarios WHERE id > 3;

-- Buscar por nombre (LIKE)
SELECT * FROM usuarios WHERE nombre LIKE 'H%';

-- Ordenar resultados
SELECT * FROM usuarios ORDER BY id DESC;

-- Contar registros
SELECT COUNT(*) AS total FROM usuarios;

-- Agregaci√≥n
SELECT COUNT(*) AS cantidad, AVG(id) AS promedio_id FROM usuarios;
```

---

#### Ver Tablas y Estructura

```sql
-- Ver todas las tablas
SHOW TABLES;

-- Ver estructura de tabla
DESCRIBE usuarios;

-- Ver informaci√≥n detallada
DESCRIBE FORMATTED usuarios;
```

---

#### Cargar Datos desde Archivo

```sql
-- Crear archivo CSV local
-- En terminal (fuera de Hive):
echo -e "7,Presto\n8,Druid\n9,Airflow" > /tmp/usuarios_nuevos.csv

-- En Hive:
LOAD DATA LOCAL INPATH '/tmp/usuarios_nuevos.csv' INTO TABLE usuarios;

-- Verificar
SELECT * FROM usuarios;
```

---

#### Crear Tabla desde Consulta (CTAS)

```sql
-- Crear tabla con resultados de consulta
CREATE TABLE usuarios_filtrados AS
SELECT * FROM usuarios WHERE id > 5;

-- Ver resultado
SELECT * FROM usuarios_filtrados;
```

---

### üìÇ Ver Datos F√≠sicos en HDFS

**Salir de Hive:**

```sql
quit;
```

**En terminal:**

```bash
# Ver archivos de la tabla en HDFS
hdfs dfs -ls /user/hive/warehouse/usuarios

# Ver contenido de los archivos
hdfs dfs -cat /user/hive/warehouse/usuarios/*
```

---

### üóëÔ∏è Eliminar Tablas

```sql
-- Eliminar tabla (mantiene datos en HDFS si es EXTERNAL)
DROP TABLE IF EXISTS usuarios;

-- Verificar
SHOW TABLES;
```

---

## üìö Conceptos Clave de Hive

| Concepto                   | Descripci√≥n                                                    |
| -------------------------- | --------------------------------------------------------------- |
| **HiveQL**           | Lenguaje SQL que se traduce a MapReduce/Tez                     |
| **Metastore**        | Base de datos con el cat√°logo de tablas (esquema)              |
| **Warehouse**        | Ubicaci√≥n f√≠sica en HDFS donde se guardan los datos           |
| **Tabla Externa**    | Tabla que referencia datos existentes en HDFS                   |
| **Tabla Gestionada** | Tabla donde Hive controla los datos (se eliminan al hacer DROP) |
| **Particionamiento** | Dividir tablas por columnas para consultas m√°s r√°pidas        |
| **Bucketing**        | Agrupar datos en buckets para optimizar joins                   |

---

---

## üéì RESUMEN Y MEJORES PR√ÅCTICAS

---

### ‚úÖ Checklist de Instalaci√≥n Completa

| Componente             | Verificaci√≥n   | Comando                                 |
| ---------------------- | --------------- | --------------------------------------- |
| **Java 8**       | ‚úÖ Instalado    | `java -version`                       |
| **Hadoop 3.4.0** | ‚úÖ Instalado    | `hadoop version`                      |
| **HDFS**         | ‚úÖ Corriendo    | `jps` ‚Üí NameNode, DataNode           |
| **YARN**         | ‚úÖ Corriendo    | `jps` ‚Üí ResourceManager, NodeManager |
| **Hive 3.1.3**   | ‚úÖ Instalado    | `hive --version`                      |
| **Metastore**    | ‚úÖ Inicializado | `ls metastore_db/`                    |

---

### üîß Comandos Esenciales para el D√≠a a D√≠a

#### Iniciar/Detener Servicios

```bash
# Iniciar todo
start-all.sh

# Detener todo
stop-all.sh

# Ver servicios activos
jps
```

---

#### HDFS

```bash
# Listar archivos
hdfs dfs -ls /ruta

# Subir archivo
hdfs dfs -put archivo.txt /ruta/

# Descargar archivo
hdfs dfs -get /ruta/archivo.txt ./

# Ver contenido
hdfs dfs -cat /ruta/archivo.txt

# Eliminar
hdfs dfs -rm -r /ruta
```

---

#### Hive

```bash
# Iniciar Hive
hive

# Ejecutar query desde archivo
hive -f script.hql

# Ejecutar query desde l√≠nea de comandos
hive -e "SELECT * FROM tabla;"

# Modo silencioso (sin logs)
hive -S -e "SELECT * FROM tabla;"
```

---

### üåê URLs de Monitoreo

| Servicio                       | URL                    | Puerto |
| ------------------------------ | ---------------------- | ------ |
| **HDFS NameNode**        | http://localhost:9870  | 9870   |
| **YARN ResourceManager** | http://localhost:8088  | 8088   |
| **Job History**          | http://localhost:19888 | 19888  |

---

### ‚ö†Ô∏è Errores Comunes y Soluciones

#### 1. "Connection refused" al acceder a interfaces web

```bash
# Verificar que los servicios est√°n corriendo
jps

# Verificar puertos abiertos en firewall
sudo firewall-cmd --list-ports

# Abrir puertos necesarios
sudo firewall-cmd --zone=public --add-port=9870/tcp --permanent
sudo firewall-cmd --zone=public --add-port=8088/tcp --permanent
sudo firewall-cmd --reload
```

---

#### 2. "Address already in use"

```bash
# Ver qu√© proceso usa el puerto
sudo netstat -tulpn | grep 9000

# Detener servicios y reiniciar
stop-all.sh
start-all.sh
```

---

#### 3. "Cannot create directory /user/hive/warehouse"

```bash
# Crear directorio manualmente
hdfs dfs -mkdir -p /user/hive/warehouse

# Dar permisos
hdfs dfs -chmod -R 777 /user/hive/warehouse
```

---

#### 4. Hive no encuentra Guava

```bash
# Copiar librer√≠a correcta
cp /opt/hadoop/hadoop-3.4.0/share/hadoop/common/lib/guava-*.jar /opt/hive/lib/

# Eliminar versi√≥n antigua
rm /opt/hive/lib/guava-19.0.jar
```

---

### üìä Estructura de Directorios Final

```
/opt/
‚îú‚îÄ‚îÄ jdk1.8.0_202/          # Java 8
‚îú‚îÄ‚îÄ hadoop/
‚îÇ   ‚îî‚îÄ‚îÄ hadoop-3.4.0/      # Hadoop
‚îÇ       ‚îú‚îÄ‚îÄ bin/           # Ejecutables
‚îÇ       ‚îú‚îÄ‚îÄ etc/hadoop/    # Configuraci√≥n
‚îÇ       ‚îî‚îÄ‚îÄ share/         # Librer√≠as
‚îî‚îÄ‚îÄ hive/                  # Hive
    ‚îú‚îÄ‚îÄ bin/               # Ejecutables
    ‚îú‚îÄ‚îÄ conf/              # Configuraci√≥n
    ‚îî‚îÄ‚îÄ lib/               # Librer√≠as

/datos/
‚îú‚îÄ‚îÄ namenode/              # Metadatos HDFS
‚îî‚îÄ‚îÄ datanode/              # Datos HDFS

/home/hadoop/              # Home del usuario
‚îî‚îÄ‚îÄ .bashrc                # Variables de entorno
```

---

### üéØ Variables de Entorno Completas

**Archivo:** `/home/hadoop/.bashrc`

```bash
# Configuraci√≥n de Java
export JAVA_HOME=/opt/jdk1.8.0_202
export JRE_HOME=/opt/jdk1.8.0_202/jre

# Configuraci√≥n de Hadoop
export HADOOP_HOME=/opt/hadoop/hadoop-3.4.0

# Configuraci√≥n de Hive
export HIVE_HOME=/opt/hive

# PATH completo
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin
```

---

### üí° Tips de Rendimiento

1. **Aumentar memoria para YARN:**

   - Editar `yarn-site.xml`
   - Aumentar `yarn.nodemanager.resource.memory-mb`
2. **Usar formatos columnares:**

   - ORC o Parquet en lugar de TEXTFILE
   - Mejora rendimiento en consultas anal√≠ticas
3. **Particionar tablas grandes:**

   - `PARTITIONED BY (year, month)`
   - Reduce escaneo de datos
4. **Usar compresi√≥n:**

   - Snappy, Gzip, LZO
   - Reduce espacio en disco y red

---

### üîí Seguridad B√°sica

> **‚ö†Ô∏è Importante:** Estos son configuraciones b√°sicas. En producci√≥n, implementar medidas de seguridad adicionales.

```bash
# Cambiar permisos de directorios sensibles
hdfs dfs -chmod 700 /user/hadoop

# Deshabilitar permisos globales (para producci√≥n)
hdfs dfs -chmod g-w /tmp
hdfs dfs -chmod g-w /user/hive/warehouse

# Usar Kerberos para autenticaci√≥n (avanzado)
# Configurar en core-site.xml y hdfs-site.xml
```

---

### üìñ Recursos Adicionales

| Recurso                           | URL                                                                      |
| --------------------------------- | ------------------------------------------------------------------------ |
| **Documentaci√≥n Hadoop**   | https://hadoop.apache.org/docs/r3.4.0/                                   |
| **Documentaci√≥n Hive**     | https://cwiki.apache.org/confluence/display/Hive/                        |
| **Playlist YouTube (base)** | https://www.youtube.com/playlist?list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B |
| **Apache Downloads**        | https://downloads.apache.org/                                            |

---

### üéì Pr√≥ximos Pasos

Una vez completada esta gu√≠a, puedes continuar con:

1. **Pr√°ctica con Dataset Real:**

   - Consulta: `Practica_Hadoop_Hive_MovieLens.md`
   - Dataset: MovieLens 100K (100,000 ratings)
2. **Integraci√≥n con Spark:**

   - Instalar Apache Spark sobre Hadoop
   - Usar Spark SQL en lugar de Hive
3. **Cluster Multi-Nodo:**

   - Configurar m√∫ltiples m√°quinas virtuales
   - Simular cluster distribuido real
4. **Herramientas Adicionales:**

   - HBase (base de datos NoSQL)
   - Pig (scripting para Hadoop)
   - Sqoop (importar/exportar desde RDBMS)
   - Flume (ingesti√≥n de logs)

---

<div align="center">

## üéâ ¬°Instalaci√≥n Completada!

**Ecosistema Big Data Funcional en CentOS**

‚úÖ Java 8 OpenJDK configurado
‚úÖ Hadoop 3.4.0 en modo pseudo-distribuido
‚úÖ HDFS operativo con replicaci√≥n
‚úÖ YARN gestionando recursos
‚úÖ MapReduce ejecutando jobs
‚úÖ Hive 3.1.3 con metastore Derby
‚úÖ Interfaces web de monitoreo activas

---

### üìö Para Estudiar

1. Practica con archivos grandes en HDFS
2. Ejecuta diferentes ejemplos de MapReduce
3. Crea tablas particionadas en Hive
4. Monitorea jobs en las interfaces web
5. Experimenta con consultas HiveQL complejas

---

*Gu√≠a de Instalaci√≥n CentOS + Hadoop + Hive*
*Versi√≥n 2.0 - Febrero 2026*
*Curso: Sistemas Inteligentes*

</div>

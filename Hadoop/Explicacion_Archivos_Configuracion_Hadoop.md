# üìù Explicaci√≥n de Archivos de Configuraci√≥n de Hadoop y Hive

> **Gu√≠a Completa de Configuraci√≥n XML**  
> **Para:** Sistemas Inteligentes - Pr√°ctica de Hadoop  
> **Fecha:** Febrero 2026

---

## üìã √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [core-site.xml](#core-sitexml)
3. [hdfs-site.xml](#hdfs-sitexml)
4. [mapred-site.xml](#mapred-sitexml)
5. [yarn-site.xml](#yarn-sitexml)
6. [hive-site.xml](#hive-sitexml)
7. [Resumen de Ubicaciones](#resumen-de-ubicaciones)
8. [Jerarqu√≠a de Configuraci√≥n](#jerarqu√≠a-de-configuraci√≥n)

---

## üéØ Introducci√≥n

### ¬øQu√© son los Archivos de Configuraci√≥n?

Los archivos XML de Hadoop definen c√≥mo se comporta el ecosistema completo:
- **Conexiones entre nodos** (IP, puertos)
- **Ubicaciones de datos** (d√≥nde se guardan)
- **L√≠mites de recursos** (memoria, CPU)
- **Comportamiento del sistema** (replicaci√≥n, timeouts)

### Estructura General de los Archivos XML

Todos los archivos siguen el mismo formato:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>nombre.de.la.propiedad</name>
        <value>valor_de_la_propiedad</value>
        <description>Descripci√≥n opcional</description>
    </property>
    
    <property>
        <name>otra.propiedad</name>
        <value>otro_valor</value>
    </property>
</configuration>
```

**Elementos:**
- `<configuration>`: Contenedor principal
- `<property>`: Cada configuraci√≥n es una propiedad
- `<name>`: Nombre de la propiedad (clave)
- `<value>`: Valor asignado
- `<description>`: Documentaci√≥n (opcional)

---

---

## üìÑ core-site.xml

### üéØ Prop√≥sito

**Configuraci√≥n central de Hadoop** - Define par√°metros globales que afectan a todos los componentes:
- URI del sistema de archivos por defecto (HDFS)
- Configuraci√≥n de I/O (buffers, compresi√≥n)
- Directorio temporal
- Configuraci√≥n de seguridad

### üìç Ubicaci√≥n

```
/opt/hadoop/hadoop-3.4.0/etc/hadoop/core-site.xml
```

---

### üîß Propiedades Principales

#### 1. `fs.defaultFS`

**Descripci√≥n:** URI del sistema de archivos por defecto (NameNode de HDFS)

```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://nodo1:9000</value>
</property>
```

**Explicaci√≥n:**
- **`hdfs://`**: Protocolo del sistema de archivos distribuido
- **`nodo1`**: Hostname o IP del servidor NameNode
- **`9000`**: Puerto por defecto del NameNode

**¬øPor qu√© es importante?**
- Todos los comandos `hdfs dfs` usan esta URI autom√°ticamente
- Define d√≥nde se conectan los clientes cuando acceden a HDFS
- Centraliza la configuraci√≥n del cluster

**Ejemplos de valores:**
```xml
<!-- Localhost -->
<value>hdfs://localhost:9000</value>

<!-- IP espec√≠fica -->
<value>hdfs://192.168.1.100:9000</value>

<!-- Sistema de archivos local (NO distribuido) -->
<value>file:///</value>
```

---

#### 2. `hadoop.tmp.dir`

**Descripci√≥n:** Directorio temporal usado por Hadoop para almacenar datos intermedios

```xml
<property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/hadoop/hadoop-3.4.0/tmp</value>
</property>
```

**¬øQu√© se guarda aqu√≠?**
- Datos temporales de NameNode y DataNode
- Metadatos de HDFS si no se especifica otra ubicaci√≥n
- Archivos temporales de MapReduce
- Datos intermedios de operaciones

**‚ö†Ô∏è IMPORTANTE:**
- **NO usar `/tmp`** del sistema (se borra al reiniciar)
- Usar directorio con suficiente espacio en disco
- Asegurar permisos correctos (`chmod 755`)
- En producci√≥n, usar disco separado

**Valores recomendados:**
```xml
<!-- Desarrollo -->
<value>/opt/hadoop/hadoop-3.4.0/tmp</value>

<!-- Producci√≥n (disco dedicado) -->
<value>/data/hadoop/tmp</value>

<!-- M√∫ltiples discos (separados por comas) -->
<value>/disk1/hadoop/tmp,/disk2/hadoop/tmp,/disk3/hadoop/tmp</value>
```

---

#### 3. `io.file.buffer.size`

**Descripci√≥n:** Tama√±o del buffer de lectura/escritura en bytes

```xml
<property>
    <name>io.file.buffer.size</name>
    <value>131072</value>
</property>
```

**Explicaci√≥n:**
- **131072 bytes** = **128 KB**
- Buffer m√°s grande = menos llamadas I/O = mejor rendimiento
- Buffer m√°s peque√±o = menos memoria usada

**Conversiones:**
- 4096 = 4 KB (muy peque√±o)
- 65536 = 64 KB (peque√±o)
- 131072 = 128 KB (recomendado)
- 262144 = 256 KB (grande)

**¬øCu√°ndo aumentar?**
- Archivos grandes (GBs)
- Red r√°pida (10 Gbps+)
- Mucha RAM disponible

**¬øCu√°ndo disminuir?**
- RAM limitada
- Muchos usuarios concurrentes
- Archivos peque√±os

---

#### 4. Propiedades Adicionales Comunes

##### `fs.trash.interval`

```xml
<property>
    <name>fs.trash.interval</name>
    <value>1440</value>
    <description>Minutos antes de vaciar papelera autom√°ticamente</description>
</property>
```

**Valores:**
- `0`: Deshabilitado (eliminar permanentemente)
- `1440`: 24 horas
- `10080`: 7 d√≠as

---

##### `hadoop.http.staticuser.user`

```xml
<property>
    <name>hadoop.http.staticuser.user</name>
    <value>hadoop</value>
    <description>Usuario para acceso web UI</description>
</property>
```

---

##### `hadoop.proxyuser.hadoop.hosts`

```xml
<property>
    <name>hadoop.proxyuser.hadoop.hosts</name>
    <value>*</value>
    <description>Hosts desde donde el usuario puede hacer proxy</description>
</property>
```

**Valores:**
- `*`: Todos los hosts (desarrollo)
- `localhost`: Solo local
- `192.168.1.*`: Subnet espec√≠fico

---

##### `hadoop.proxyuser.hadoop.groups`

```xml
<property>
    <name>hadoop.proxyuser.hadoop.groups</name>
    <value>*</value>
    <description>Grupos que pueden usar proxy</description>
</property>
```

---

### üìù Ejemplo Completo: core-site.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Sistema de archivos por defecto (HDFS) -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://nodo1:9000</value>
        <description>URI del NameNode de HDFS</description>
    </property>
    
    <!-- Directorio temporal -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/hadoop/hadoop-3.4.0/tmp</value>
        <description>Directorio para archivos temporales</description>
    </property>
    
    <!-- Buffer de I/O -->
    <property>
        <name>io.file.buffer.size</name>
        <value>131072</value>
        <description>Tama√±o del buffer: 128 KB</description>
    </property>
    
    <!-- Papelera de reciclaje -->
    <property>
        <name>fs.trash.interval</name>
        <value>1440</value>
        <description>Retenci√≥n de papelera: 24 horas</description>
    </property>
    
    <!-- Usuario para Web UI -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>hadoop</value>
    </property>
    
    <!-- Configuraci√≥n de proxy -->
    <property>
        <name>hadoop.proxyuser.hadoop.hosts</name>
        <value>*</value>
    </property>
    
    <property>
        <name>hadoop.proxyuser.hadoop.groups</name>
        <value>*</value>
    </property>
</configuration>
```

---

---

## üìÑ hdfs-site.xml

### üéØ Prop√≥sito

**Configuraci√≥n espec√≠fica de HDFS** - Define c√≥mo funciona el sistema de archivos distribuido:
- Factor de replicaci√≥n de datos
- Ubicaci√≥n de NameNode y DataNode
- Tama√±o de bloques
- Permisos y seguridad

### üìç Ubicaci√≥n

```
/opt/hadoop/hadoop-3.4.0/etc/hadoop/hdfs-site.xml
```

---

### üîß Propiedades Principales

#### 1. `dfs.replication`

**Descripci√≥n:** N√∫mero de r√©plicas de cada bloque de datos

```xml
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
```

**Explicaci√≥n:**
- **1**: Modo pseudo-distribuido (una sola m√°quina) ‚ö†Ô∏è SIN REDUNDANCIA
- **2**: M√≠nimo para producci√≥n peque√±a
- **3**: Est√°ndar en producci√≥n (RECOMENDADO) ‚úÖ
- **5+**: Alta disponibilidad cr√≠tica

**Ventajas de replicaci√≥n:**
- ‚úÖ **Tolerancia a fallos**: Si un DataNode falla, los datos siguen disponibles
- ‚úÖ **Balanceo de carga**: Lecturas distribuidas entre r√©plicas
- ‚úÖ **Localidad de datos**: MapReduce usa r√©plica m√°s cercana

**Desventajas:**
- ‚ùå **M√°s espacio**: 3 r√©plicas = 3x espacio usado
- ‚ùå **M√°s red**: Escribir consume m√°s ancho de banda

**Ejemplos por escenario:**
```xml
<!-- DESARROLLO / PRUEBAS (1 m√°quina) -->
<value>1</value>

<!-- PRODUCCI√ìN PEQUE√ëA (3-5 nodos) -->
<value>2</value>

<!-- PRODUCCI√ìN EST√ÅNDAR (5+ nodos) -->
<value>3</value>

<!-- DATOS CR√çTICOS (muchos nodos) -->
<value>5</value>
```

---

#### 2. `dfs.namenode.name.dir`

**Descripci√≥n:** Directorio donde el NameNode guarda los metadatos de HDFS

```xml
<property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///opt/hadoop/hadoop-3.4.0/dfs/namenode</value>
</property>
```

**¬øQu√© se guarda aqu√≠?**
- **FSImage**: Snapshot completo del sistema de archivos
- **EditLog**: Registro de todas las transacciones
- **Metadatos**: Nombres de archivos, permisos, ubicaci√≥n de bloques

**‚ö†Ô∏è CR√çTICO:**
- Si se pierde este directorio, **SE PIERDE TODO EL SISTEMA DE ARCHIVOS**
- En producci√≥n, usar **m√∫ltiples ubicaciones** (RAID, NFS, discos separados)
- Hacer **backups regulares**

**Formato del valor:**
```xml
<!-- Una ubicaci√≥n -->
<value>file:///opt/hadoop/hadoop-3.4.0/dfs/namenode</value>

<!-- M√∫ltiples ubicaciones (separadas por comas) - RECOMENDADO -->
<value>file:///disk1/hadoop/namenode,file:///disk2/hadoop/namenode</value>

<!-- Con NFS para backup -->
<value>file:///local/namenode,file:///nfs/backup/namenode</value>
```

**Estructura interna:**
```
namenode/
‚îú‚îÄ‚îÄ current/
‚îÇ   ‚îú‚îÄ‚îÄ fsimage_0000000000000000123  (Snapshot del filesystem)
‚îÇ   ‚îú‚îÄ‚îÄ fsimage_0000000000000000123.md5
‚îÇ   ‚îú‚îÄ‚îÄ edits_0000000000000000001-0000000000000000123  (Log de cambios)
‚îÇ   ‚îú‚îÄ‚îÄ seen_txid
‚îÇ   ‚îî‚îÄ‚îÄ VERSION
‚îî‚îÄ‚îÄ in_use.lock
```

---

#### 3. `dfs.datanode.data.dir`

**Descripci√≥n:** Directorios donde los DataNodes guardan los bloques de datos reales

```xml
<property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///opt/hadoop/hadoop-3.4.0/dfs/datanode</value>
</property>
```

**¬øQu√© se guarda aqu√≠?**
- **Bloques de datos**: Los archivos divididos en chunks de 128 MB
- **Metadatos de bloques**: Checksums, versiones
- Contenido real de archivos subidos a HDFS

**Recomendaciones:**
- Usar **m√∫ltiples discos** para m√°s I/O paralelo
- Usar discos **grandes y r√°pidos** (SATA, SAS, SSD)
- Evitar compartir disco con sistema operativo

**Ejemplos:**
```xml
<!-- Una ubicaci√≥n (desarrollo) -->
<value>file:///opt/hadoop/hadoop-3.4.0/dfs/datanode</value>

<!-- M√∫ltiples discos (RECOMENDADO en producci√≥n) -->
<value>file:///disk1/hadoop/datanode,file:///disk2/hadoop/datanode,file:///disk3/hadoop/datanode</value>

<!-- Con SSD para hot data -->
<value>file:///ssd/hadoop/datanode,file:///hdd1/hadoop/datanode,file:///hdd2/hadoop/datanode</value>
```

**Estructura interna:**
```
datanode/
‚îî‚îÄ‚îÄ current/
    ‚îú‚îÄ‚îÄ BP-123456-127.0.0.1-123456/
    ‚îÇ   ‚îî‚îÄ‚îÄ current/
    ‚îÇ       ‚îî‚îÄ‚îÄ finalized/
    ‚îÇ           ‚îî‚îÄ‚îÄ subdir0/
    ‚îÇ               ‚îî‚îÄ‚îÄ subdir0/
    ‚îÇ                   ‚îú‚îÄ‚îÄ blk_1073741825  (Bloque de datos)
    ‚îÇ                   ‚îî‚îÄ‚îÄ blk_1073741825_1001.meta  (Checksum)
    ‚îî‚îÄ‚îÄ VERSION
```

---

#### 4. `dfs.blocksize`

**Descripci√≥n:** Tama√±o de cada bloque de datos en HDFS (en bytes)

```xml
<property>
    <name>dfs.blocksize</name>
    <value>134217728</value>
</property>
```

**Conversiones:**
- **67108864** = 64 MB
- **134217728** = 128 MB (DEFAULT) ‚úÖ
- **268435456** = 256 MB
- **536870912** = 512 MB

**¬øC√≥mo funciona?**
- Archivo de 1 GB con bloques de 128 MB = **8 bloques**
- Archivo de 50 MB con bloques de 128 MB = **1 bloque** (no desperdicia espacio)
- Cada bloque se replica seg√∫n `dfs.replication`

**Ventajas de bloques grandes (256 MB, 512 MB):**
- ‚úÖ Menos metadatos en NameNode
- ‚úÖ Menos overhead de red
- ‚úÖ Mejor para archivos grandes (logs, videos, datasets masivos)

**Ventajas de bloques peque√±os (64 MB, 128 MB):**
- ‚úÖ Mejor paralelizaci√≥n (m√°s bloques = m√°s tareas Map)
- ‚úÖ Mejor balanceo de carga
- ‚úÖ Menos desperdicio con archivos peque√±os

**Recomendaciones por caso:**
```xml
<!-- Muchos archivos peque√±os (1-100 MB) -->
<value>67108864</value>  <!-- 64 MB -->

<!-- Uso general (DEFAULT) -->
<value>134217728</value>  <!-- 128 MB -->

<!-- Big Data masivo (archivos de GBs) -->
<value>268435456</value>  <!-- 256 MB -->

<!-- Procesamiento de logs enormes -->
<value>536870912</value>  <!-- 512 MB -->
```

---

#### 5. `dfs.namenode.http-address`

**Descripci√≥n:** Direcci√≥n y puerto del interfaz web del NameNode

```xml
<property>
    <name>dfs.namenode.http-address</name>
    <value>0.0.0.0:9870</value>
</property>
```

**Explicaci√≥n:**
- **0.0.0.0**: Escuchar en todas las interfaces de red
- **9870**: Puerto web (antes era 50070 en Hadoop 2.x)

**Acceso:**
```
http://localhost:9870
http://192.168.1.100:9870
```

**Informaci√≥n disponible en Web UI:**
- Estado del cluster (live/dead DataNodes)
- Espacio usado/disponible
- Lista de archivos en HDFS
- Navegador de filesystem
- Logs del NameNode
- Informaci√≥n de bloques

**Valores comunes:**
```xml
<!-- Accesible desde cualquier IP -->
<value>0.0.0.0:9870</value>

<!-- Solo localhost -->
<value>localhost:9870</value>

<!-- IP espec√≠fica -->
<value>192.168.1.100:9870</value>
```

---

#### 6. `dfs.datanode.http-address`

**Descripci√≥n:** Direcci√≥n y puerto del interfaz web del DataNode

```xml
<property>
    <name>dfs.datanode.http-address</name>
    <value>0.0.0.0:9864</value>
</property>
```

**Puerto por defecto:** 9864 (antes 50075 en Hadoop 2.x)

---

#### 7. `dfs.permissions.enabled`

**Descripci√≥n:** Habilitar/deshabilitar sistema de permisos HDFS

```xml
<property>
    <name>dfs.permissions.enabled</name>
    <value>false</value>
</property>
```

**Valores:**
- **true**: Permisos estrictos (como Linux: rwxr-xr-x)
- **false**: Sin restricciones (cualquiera puede hacer todo)

**Recomendaci√≥n:**
- **Desarrollo/Pruebas**: `false` (m√°s f√°cil)
- **Producci√≥n**: `true` (seguridad)

---

#### 8. `dfs.webhdfs.enabled`

**Descripci√≥n:** Habilitar API REST de HDFS

```xml
<property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
</property>
```

**¬øPara qu√© sirve?**
- Acceder a HDFS v√≠a HTTP/REST
- Integraci√≥n con aplicaciones web
- No requiere cliente Java

**Ejemplo de uso:**
```bash
# Listar archivos v√≠a REST
curl "http://nodo1:9870/webhdfs/v1/datos?op=LISTSTATUS&user.name=hadoop"

# Subir archivo
curl -i -X PUT "http://nodo1:9870/webhdfs/v1/datos/archivo.txt?op=CREATE&user.name=hadoop"
```

---

### üìù Ejemplo Completo: hdfs-site.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Factor de replicaci√≥n -->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <description>N√∫mero de r√©plicas por bloque (1=pseudo-distribuido, 3=producci√≥n)</description>
    </property>
    
    <!-- Directorio de metadatos del NameNode -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///opt/hadoop/hadoop-3.4.0/dfs/namenode</value>
        <description>Ubicaci√≥n de FSImage y EditLog (CR√çTICO - hacer backup)</description>
    </property>
    
    <!-- Directorio de datos del DataNode -->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///opt/hadoop/hadoop-3.4.0/dfs/datanode</value>
        <description>Ubicaci√≥n de bloques de datos reales</description>
    </property>
    
    <!-- Tama√±o de bloque -->
    <property>
        <name>dfs.blocksize</name>
        <value>134217728</value>
        <description>Tama√±o de bloque: 128 MB</description>
    </property>
    
    <!-- Web UI del NameNode -->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>0.0.0.0:9870</value>
        <description>Interfaz web del NameNode</description>
    </property>
    
    <!-- Web UI del DataNode -->
    <property>
        <name>dfs.datanode.http-address</name>
        <value>0.0.0.0:9864</value>
        <description>Interfaz web del DataNode</description>
    </property>
    
    <!-- Permisos de HDFS -->
    <property>
        <name>dfs.permissions.enabled</name>
        <value>false</value>
        <description>false=desarrollo, true=producci√≥n</description>
    </property>
    
    <!-- WebHDFS (API REST) -->
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
        <description>Habilitar acceso REST a HDFS</description>
    </property>
</configuration>
```

---

---

## üìÑ mapred-site.xml

### üéØ Prop√≥sito

**Configuraci√≥n de MapReduce** - Define c√≥mo funcionan los trabajos de procesamiento distribuido:
- Framework de ejecuci√≥n (YARN, local, classic)
- Configuraci√≥n de memoria para Map y Reduce
- Directorio de staging
- Job History Server

### üìç Ubicaci√≥n

```
/opt/hadoop/hadoop-3.4.0/etc/hadoop/mapred-site.xml
```

---

### üîß Propiedades Principales

#### 1. `mapreduce.framework.name`

**Descripci√≥n:** Framework que ejecutar√° los trabajos MapReduce

```xml
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
```

**Valores posibles:**

| Valor | Descripci√≥n | Uso |
|-------|-------------|-----|
| **`local`** | Ejecuci√≥n en un solo proceso (sin distribuci√≥n) | Desarrollo y debug |
| **`classic`** | MapReduce v1 (obsoleto en Hadoop 3.x) | Legacy |
| **`yarn`** | MapReduce v2 con YARN (RECOMENDADO) ‚úÖ | Producci√≥n |

**¬øPor qu√© YARN?**
- ‚úÖ Gesti√≥n de recursos centralizada
- ‚úÖ M√∫ltiples frameworks (no solo MapReduce)
- ‚úÖ Mejor utilizaci√≥n de recursos
- ‚úÖ Escalabilidad mejorada

---

#### 2. `mapreduce.application.classpath`

**Descripci√≥n:** Classpath de Java para aplicaciones MapReduce

```xml
<property>
    <name>mapreduce.application.classpath</name>
    <value>
        $HADOOP_HOME/share/hadoop/mapreduce/*,
        $HADOOP_HOME/share/hadoop/mapreduce/lib/*,
        $HADOOP_HOME/share/hadoop/common/*,
        $HADOOP_HOME/share/hadoop/common/lib/*,
        $HADOOP_HOME/share/hadoop/yarn/*,
        $HADOOP_HOME/share/hadoop/yarn/lib/*,
        $HADOOP_HOME/share/hadoop/hdfs/*,
        $HADOOP_HOME/share/hadoop/hdfs/lib/*
    </value>
</property>
```

**¬øPara qu√© sirve?**
- Define d√≥nde buscar librer√≠as Java (.jar)
- Necesario para que MapReduce funcione correctamente
- Incluye HDFS, YARN, y dependencias

**‚ö†Ô∏è Si no se configura:**
- Error: `ClassNotFoundException`
- Jobs no inician

---

#### 3. `yarn.app.mapreduce.am.env`

**Descripci√≥n:** Variables de entorno para el Application Master de MapReduce

```xml
<property>
    <name>yarn.app.mapreduce.am.env</name>
    <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
</property>
```

**¬øQu√© es Application Master?**
- Proceso que coordina un job MapReduce espec√≠fico
- Uno por cada job ejecutado
- Gestiona tareas Map y Reduce

---

#### 4. `mapreduce.map.env`

**Descripci√≥n:** Variables de entorno para tareas Map

```xml
<property>
    <name>mapreduce.map.env</name>
    <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
</property>
```

---

#### 5. `mapreduce.reduce.env`

**Descripci√≥n:** Variables de entorno para tareas Reduce

```xml
<property>
    <name>mapreduce.reduce.env</name>
    <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
</property>
```

---

#### 6. `mapreduce.map.memory.mb`

**Descripci√≥n:** Memoria m√°xima (en MB) para cada tarea Map

```xml
<property>
    <name>mapreduce.map.memory.mb</name>
    <value>1536</value>
</property>
```

**Valores t√≠picos:**
- **1024 MB**: M√≠nimo funcional
- **1536 MB**: Desarrollo
- **2048 MB**: Producci√≥n peque√±a
- **4096 MB**: Producci√≥n con datos grandes

**C√°lculo recomendado:**
```
mapreduce.map.memory.mb = (RAM_nodo / n√∫m_containers_simult√°neos) * 0.8
```

**Ejemplo:**
- Nodo con 16 GB RAM
- 8 containers simult√°neos
- `(16384 MB / 8) * 0.8 = 1638 MB` ‚âà **1536 MB**

---

#### 7. `mapreduce.reduce.memory.mb`

**Descripci√≥n:** Memoria m√°xima (en MB) para cada tarea Reduce

```xml
<property>
    <name>mapreduce.reduce.memory.mb</name>
    <value>3072</value>
</property>
```

**Generalmente:**
```
mapreduce.reduce.memory.mb = 2 * mapreduce.map.memory.mb
```

**¬øPor qu√© m√°s memoria para Reduce?**
- Reduce agrupa datos de m√∫ltiples Maps
- Necesita buffers para sorting
- Operaciones de agregaci√≥n consumen m√°s RAM

---

#### 8. `mapreduce.map.java.opts`

**Descripci√≥n:** Opciones de JVM para tareas Map

```xml
<property>
    <name>mapreduce.map.java.opts</name>
    <value>-Xmx1024m</value>
</property>
```

**Explicaci√≥n:**
- `-Xmx1024m`: Heap m√°ximo de 1024 MB
- Debe ser **menor** que `mapreduce.map.memory.mb`
- Dejar ~20% para overhead de JVM

**F√≥rmula:**
```
-Xmx = mapreduce.map.memory.mb * 0.8
```

**Ejemplo:**
```xml
<!-- Si mapreduce.map.memory.mb = 1536 -->
<value>-Xmx1024m</value>  <!-- 1536 * 0.66 ‚âà 1024 -->
```

---

#### 9. `mapreduce.reduce.java.opts`

**Descripci√≥n:** Opciones de JVM para tareas Reduce

```xml
<property>
    <name>mapreduce.reduce.java.opts</name>
    <value>-Xmx2048m</value>
</property>
```

**F√≥rmula:**
```
-Xmx = mapreduce.reduce.memory.mb * 0.8
```

**Ejemplo:**
```xml
<!-- Si mapreduce.reduce.memory.mb = 3072 -->
<value>-Xmx2048m</value>  <!-- 3072 * 0.66 ‚âà 2048 -->
```

---

#### 10. `mapreduce.jobhistory.address`

**Descripci√≥n:** Direcci√≥n del Job History Server

```xml
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>nodo1:10020</value>
</property>
```

**¬øQu√© es Job History Server?**
- Almacena historial de jobs completados
- Permite ver logs de jobs antiguos
- √ötil para debugging y auditor√≠a

---

#### 11. `mapreduce.jobhistory.webapp.address`

**Descripci√≥n:** Web UI del Job History Server

```xml
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>0.0.0.0:19888</value>
</property>
```

**Acceso:**
```
http://localhost:19888
```

**Informaci√≥n disponible:**
- Jobs completados
- Jobs fallidos
- Tiempo de ejecuci√≥n
- Estad√≠sticas de recursos
- Logs completos

---

### üìù Ejemplo Completo: mapred-site.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Framework de ejecuci√≥n -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
        <description>Usar YARN como gestor de recursos</description>
    </property>
    
    <!-- Classpath de MapReduce -->
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_HOME/share/hadoop/mapreduce/*,$HADOOP_HOME/share/hadoop/mapreduce/lib/*,$HADOOP_HOME/share/hadoop/common/*,$HADOOP_HOME/share/hadoop/common/lib/*,$HADOOP_HOME/share/hadoop/yarn/*,$HADOOP_HOME/share/hadoop/yarn/lib/*,$HADOOP_HOME/share/hadoop/hdfs/*,$HADOOP_HOME/share/hadoop/hdfs/lib/*</value>
    </property>
    
    <!-- Variables de entorno -->
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
    
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
    
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
    
    <!-- Memoria para tareas Map -->
    <property>
        <name>mapreduce.map.memory.mb</name>
        <value>1536</value>
        <description>Memoria f√≠sica para Map: 1.5 GB</description>
    </property>
    
    <!-- Memoria para tareas Reduce -->
    <property>
        <name>mapreduce.reduce.memory.mb</name>
        <value>3072</value>
        <description>Memoria f√≠sica para Reduce: 3 GB</description>
    </property>
    
    <!-- Heap de JVM para Map -->
    <property>
        <name>mapreduce.map.java.opts</name>
        <value>-Xmx1024m</value>
        <description>Heap m√°ximo para Map: 1 GB</description>
    </property>
    
    <!-- Heap de JVM para Reduce -->
    <property>
        <name>mapreduce.reduce.java.opts</name>
        <value>-Xmx2048m</value>
        <description>Heap m√°ximo para Reduce: 2 GB</description>
    </property>
    
    <!-- Job History Server -->
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>nodo1:10020</value>
        <description>Direcci√≥n del servidor de historial</description>
    </property>
    
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>0.0.0.0:19888</value>
        <description>Web UI del historial de jobs</description>
    </property>
</configuration>
```

---

---

## üìÑ yarn-site.xml

### üéØ Prop√≥sito

**Configuraci√≥n de YARN (Yet Another Resource Negotiator)** - Define c√≥mo se gestionan recursos y se ejecutan aplicaciones:
- ResourceManager (coordinador global)
- NodeManager (ejecutor en cada nodo)
- Scheduler de recursos
- L√≠mites de memoria y CPU

### üìç Ubicaci√≥n

```
/opt/hadoop/hadoop-3.4.0/etc/hadoop/yarn-site.xml
```

---

### üîß Propiedades Principales

#### 1. `yarn.nodemanager.aux-services`

**Descripci√≥n:** Servicios auxiliares que ejecuta el NodeManager

```xml
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
```

**¬øQu√© es mapreduce_shuffle?**
- Servicio que transfiere datos entre Map y Reduce
- **OBLIGATORIO** para que MapReduce funcione
- Maneja el "shuffle" (mezcla) de datos intermedios

**Flujo MapReduce:**
```
Map ‚Üí [mapreduce_shuffle] ‚Üí Reduce
```

**Si no est√° configurado:**
- Error: "Failed to run job: no aux-services configured"
- MapReduce no funcionar√°

---

#### 2. `yarn.nodemanager.aux-services.mapreduce_shuffle.class`

**Descripci√≥n:** Clase Java que implementa el servicio shuffle

```xml
<property>
    <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
```

**Nota:** Esta es la clase est√°ndar, raramente se cambia.

---

#### 3. `yarn.resourcemanager.hostname`

**Descripci√≥n:** Hostname del ResourceManager

```xml
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>nodo1</value>
</property>
```

**¬øQu√© es ResourceManager?**
- **Cerebro del cluster YARN**
- Asigna recursos (RAM, CPU) a aplicaciones
- Un √∫nico RM por cluster (puede tener HA con standby)

**Valores posibles:**
```xml
<value>localhost</value>
<value>nodo1</value>
<value>192.168.1.100</value>
<value>hadoop-master.domain.com</value>
```

---

#### 4. `yarn.resourcemanager.address`

**Descripci√≥n:** Direcci√≥n para clientes que env√≠an aplicaciones

```xml
<property>
    <name>yarn.resourcemanager.address</name>
    <value>nodo1:8032</value>
</property>
```

**Puerto 8032:** Puerto RPC para comunicaci√≥n cliente-RM

---

#### 5. `yarn.resourcemanager.scheduler.address`

**Descripci√≥n:** Direcci√≥n del scheduler para ApplicationMasters

```xml
<property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>nodo1:8030</value>
</property>
```

**Puerto 8030:** Puerto para que AMs soliciten recursos

---

#### 6. `yarn.resourcemanager.resource-tracker.address`

**Descripci√≥n:** Direcci√≥n para NodeManagers que reportan al RM

```xml
<property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>nodo1:8031</value>
</property>
```

**Puerto 8031:** Puerto para heartbeats de NodeManagers

---

#### 7. `yarn.resourcemanager.webapp.address`

**Descripci√≥n:** Web UI del ResourceManager

```xml
<property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>0.0.0.0:8088</value>
</property>
```

**Puerto 8088:** Puerto web del ResourceManager

**Acceso:**
```
http://localhost:8088
http://192.168.1.100:8088
```

**Informaci√≥n disponible:**
- Aplicaciones en ejecuci√≥n
- Aplicaciones completadas/fallidas
- Uso de recursos (RAM, CPU)
- Estado de NodeManagers
- Queue de trabajos
- M√©tricas del cluster

---

#### 8. `yarn.nodemanager.resource.memory-mb`

**Descripci√≥n:** Memoria total (en MB) que el NodeManager puede asignar a contenedores

```xml
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>8192</value>
</property>
```

**¬øC√≥mo calcular este valor?**

```
yarn.nodemanager.resource.memory-mb = (RAM_total - RAM_SO - RAM_otros_servicios)
```

**Ejemplo con 16 GB RAM:**
```
RAM total:           16 GB (16384 MB)
- Sistema operativo: 2 GB  (2048 MB)
- Otros servicios:   2 GB  (2048 MB)
- HDFS/NameNode:     1 GB  (1024 MB)
= YARN disponible:   11 GB (11264 MB)
```

```xml
<value>11264</value>
```

**Valores t√≠picos:**

| RAM Total | Valor Recomendado |
|-----------|-------------------|
| 4 GB | 2048 MB |
| 8 GB | 6144 MB |
| 16 GB | 12288 MB |
| 32 GB | 26624 MB |
| 64 GB | 57344 MB |

---

#### 9. `yarn.scheduler.minimum-allocation-mb`

**Descripci√≥n:** Memoria m√≠nima (en MB) que se puede solicitar para un contenedor

```xml
<property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
    <value>1024</value>
</property>
```

**¬øPara qu√© sirve?**
- Evita contenedores muy peque√±os (ineficientes)
- Todas las solicitudes se redondean a m√∫ltiplos de este valor

**Ejemplo:**
- Si pides 1200 MB y el m√≠nimo es 1024 MB
- YARN asignar√° 2048 MB (siguiente m√∫ltiplo)

---

#### 10. `yarn.scheduler.maximum-allocation-mb`

**Descripci√≥n:** Memoria m√°xima (en MB) que se puede solicitar para un contenedor

```xml
<property>
    <name>yarn.scheduler.maximum-allocation-mb</name>
    <value>8192</value>
</property>
```

**Regla:**
```
yarn.scheduler.maximum-allocation-mb ‚â§ yarn.nodemanager.resource.memory-mb
```

**Generalmente:**
```
yarn.scheduler.maximum-allocation-mb = yarn.nodemanager.resource.memory-mb * 0.8
```

---

#### 11. `yarn.nodemanager.resource.cpu-vcores`

**Descripci√≥n:** N√∫mero de CPUs virtuales disponibles para contenedores

```xml
<property>
    <name>yarn.nodemanager.resource.cpu-vcores</name>
    <value>4</value>
</property>
```

**¬øC√≥mo calcular?**
- **Desarrollo:** N√∫cleos f√≠sicos - 1
- **Producci√≥n:** N√∫cleos f√≠sicos * 1.5 (oversubscription)

**Ejemplos:**

| CPUs F√≠sicos | Desarrollo | Producci√≥n |
|--------------|------------|------------|
| 2 | 1 | 3 |
| 4 | 3 | 6 |
| 8 | 7 | 12 |
| 16 | 15 | 24 |

```bash
# Ver n√∫cleos disponibles
nproc
lscpu | grep "^CPU(s):"
```

---

#### 12. `yarn.nodemanager.vmem-check-enabled`

**Descripci√≥n:** Habilitar verificaci√≥n de memoria virtual

```xml
<property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
</property>
```

**Valores:**
- **false**: No verificar (RECOMENDADO para desarrollo)
- **true**: Verificar l√≠mites estrictos

**¬øPor qu√© deshabilitar?**
- Evita errores como "Container killed on request. Exit code is 143"
- Java tiende a usar mucha memoria virtual
- En producci√≥n, considerar `true` para control estricto

---

#### 13. `yarn.nodemanager.pmem-check-enabled`

**Descripci√≥n:** Habilitar verificaci√≥n de memoria f√≠sica

```xml
<property>
    <name>yarn.nodemanager.pmem-check-enabled</name>
    <value>false</value>
</property>
```

**Recomendaci√≥n:** `false` en desarrollo, `true` en producci√≥n

---

#### 14. `yarn.log-aggregation-enable`

**Descripci√≥n:** Agregar logs de contenedores en HDFS despu√©s de completar aplicaci√≥n

```xml
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
```

**Ventajas:**
- ‚úÖ Logs persisten despu√©s de que el contenedor termina
- ‚úÖ Accesibles v√≠a `yarn logs -applicationId`
- ‚úÖ No se pierden si el nodo falla

**Desventajas:**
- ‚ùå Consume espacio en HDFS
- ‚ùå Peque√±o overhead al finalizar aplicaci√≥n

---

#### 15. `yarn.nodemanager.local-dirs`

**Descripci√≥n:** Directorios locales para datos intermedios de contenedores

```xml
<property>
    <name>yarn.nodemanager.local-dirs</name>
    <value>/opt/hadoop/hadoop-3.4.0/yarn/local</value>
</property>
```

**¬øQu√© se guarda aqu√≠?**
- Datos temporales de contenedores
- JAR files de aplicaciones
- Archivos de trabajo intermedios

**Recomendaci√≥n:**
- Usar **m√∫ltiples discos** para I/O paralelo
- Usar discos r√°pidos (SSD si es posible)

```xml
<!-- M√∫ltiples discos -->
<value>/disk1/yarn/local,/disk2/yarn/local,/disk3/yarn/local</value>
```

---

#### 16. `yarn.nodemanager.log-dirs`

**Descripci√≥n:** Directorios locales para logs de contenedores

```xml
<property>
    <name>yarn.nodemanager.log-dirs</name>
    <value>/opt/hadoop/hadoop-3.4.0/yarn/logs</value>
</property>
```

**Nota:** Si `yarn.log-aggregation-enable=true`, estos logs se copian a HDFS

---

### üìù Ejemplo Completo: yarn-site.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Servicios auxiliares -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
        <description>Servicio de shuffle para MapReduce</description>
    </property>
    
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    
    <!-- ResourceManager -->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>nodo1</value>
        <description>Hostname del ResourceManager</description>
    </property>
    
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>nodo1:8032</value>
    </property>
    
    <property>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>nodo1:8030</value>
    </property>
    
    <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>nodo1:8031</value>
    </property>
    
    <!-- Web UI del ResourceManager -->
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>0.0.0.0:8088</value>
        <description>Interfaz web: http://localhost:8088</description>
    </property>
    
    <!-- Recursos de memoria -->
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>8192</value>
        <description>Memoria total disponible: 8 GB</description>
    </property>
    
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>1024</value>
        <description>Asignaci√≥n m√≠nima: 1 GB</description>
    </property>
    
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>8192</value>
        <description>Asignaci√≥n m√°xima: 8 GB</description>
    </property>
    
    <!-- Recursos de CPU -->
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>4</value>
        <description>CPUs virtuales disponibles</description>
    </property>
    
    <!-- Verificaci√≥n de memoria -->
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
        <description>Deshabilitar check de virtual memory</description>
    </property>
    
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
        <description>Deshabilitar check de physical memory</description>
    </property>
    
    <!-- Agregaci√≥n de logs -->
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
        <description>Guardar logs en HDFS</description>
    </property>
    
    <!-- Directorios locales -->
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/opt/hadoop/hadoop-3.4.0/yarn/local</value>
        <description>Datos temporales de contenedores</description>
    </property>
    
    <property>
        <name>yarn.nodemanager.log-dirs</name>
        <value>/opt/hadoop/hadoop-3.4.0/yarn/logs</value>
        <description>Logs locales de contenedores</description>
    </property>
</configuration>
```

---

---

## üìÑ hive-site.xml

### üéØ Prop√≥sito

**Configuraci√≥n de Apache Hive** - Define c√≥mo funciona el data warehouse sobre Hadoop:
- Conexi√≥n a metastore (base de datos de metadatos)
- Warehouse (ubicaci√≥n de datos)
- Modo de ejecuci√≥n (local vs YARN)
- Optimizaciones y paralelismo

### üìç Ubicaci√≥n

```
/opt/hive/conf/hive-site.xml
```

---

### üîß Propiedades Principales

#### 1. `javax.jdo.option.ConnectionURL`

**Descripci√≥n:** URL de conexi√≥n a la base de datos del metastore

```xml
<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:derby:;databaseName=/opt/hive/metastore_db;create=true</value>
</property>
```

**¬øQu√© es el Metastore?**
- Base de datos que guarda metadatos de Hive:
  - Nombres de tablas y columnas
  - Tipos de datos
  - Ubicaci√≥n de archivos en HDFS
  - Particiones
  - Estad√≠sticas

**Opciones de base de datos:**

##### Apache Derby (embedded - para desarrollo)
```xml
<value>jdbc:derby:;databaseName=/opt/hive/metastore_db;create=true</value>
```
- ‚úÖ No requiere instalaci√≥n adicional
- ‚úÖ F√°cil setup
- ‚ùå Solo una conexi√≥n simult√°nea
- ‚ùå NO para producci√≥n

##### MySQL (recomendado para producci√≥n)
```xml
<value>jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true&amp;useSSL=false</value>
```
- ‚úÖ M√∫ltiples conexiones
- ‚úÖ Robusto y confiable
- ‚úÖ Backups f√°ciles
- ‚ö†Ô∏è Requiere instalar MySQL

##### PostgreSQL
```xml
<value>jdbc:postgresql://localhost:5432/metastore</value>
```

---

#### 2. `javax.jdo.option.ConnectionDriverName`

**Descripci√≥n:** Driver JDBC de la base de datos

```xml
<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.apache.derby.jdbc.EmbeddedDriver</value>
</property>
```

**Drivers por tipo de BD:**

| Base de Datos | Driver |
|---------------|--------|
| Derby | `org.apache.derby.jdbc.EmbeddedDriver` |
| MySQL | `com.mysql.cj.jdbc.Driver` o `com.mysql.jdbc.Driver` |
| PostgreSQL | `org.postgresql.Driver` |
| Oracle | `oracle.jdbc.OracleDriver` |
| SQL Server | `com.microsoft.sqlserver.jdbc.SQLServerDriver` |

---

#### 3. `javax.jdo.option.ConnectionUserName`

**Descripci√≥n:** Usuario de la base de datos del metastore

```xml
<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
</property>
```

**Para Derby:** No se usa (puede dejarse vac√≠o)

**Para MySQL:**
```xml
<value>hive</value>  <!-- o root -->
```

---

#### 4. `javax.jdo.option.ConnectionPassword`

**Descripci√≥n:** Contrase√±a del usuario de la base de datos

```xml
<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hivepassword</value>
</property>
```

**Para Derby:** No se usa (puede dejarse vac√≠o)

**Para MySQL:**
```xml
<value>tu_password_mysql</value>
```

**‚ö†Ô∏è Seguridad:**
- No usar contrase√±as d√©biles en producci√≥n
- Considerar encriptar con Hadoop Credential Provider

---

#### 5. `hive.metastore.warehouse.dir`

**Descripci√≥n:** Directorio en HDFS donde se guardan las tablas de Hive

```xml
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
</property>
```

**¬øQu√© se guarda aqu√≠?**
- Datos de tablas **managed** (gestionadas por Hive)
- Estructura de directorios por base de datos y tabla:

```
/user/hive/warehouse/
‚îú‚îÄ‚îÄ mi_base_de_datos.db/
‚îÇ   ‚îú‚îÄ‚îÄ tabla1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 000000_0
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 000000_1
‚îÇ   ‚îî‚îÄ‚îÄ tabla2/
‚îÇ       ‚îî‚îÄ‚îÄ 000000_0
‚îî‚îÄ‚îÄ otra_db.db/
    ‚îî‚îÄ‚îÄ usuarios/
        ‚îî‚îÄ‚îÄ part-00000
```

**Nota:** Tablas **EXTERNAL** se guardan donde se especifique en `LOCATION`

---

#### 6. `hive.metastore.uris`

**Descripci√≥n:** URI del servicio Metastore (para modo remoto)

```xml
<property>
    <name>hive.metastore.uris</name>
    <value>thrift://nodo1:9083</value>
</property>
```

**Modos de Metastore:**

##### Embedded Mode (desarrollo)
```xml
<value></value>  <!-- Vac√≠o -->
```
- Metastore en mismo proceso que Hive
- No requiere servicio separado

##### Remote Mode (producci√≥n)
```xml
<value>thrift://nodo1:9083</value>
```
- Metastore como servicio independiente
- M√∫ltiples clientes Hive pueden conectarse
- Requiere iniciar: `hive --service metastore`

---

#### 7. `hive.server2.thrift.port`

**Descripci√≥n:** Puerto de HiveServer2 para conexiones JDBC/ODBC

```xml
<property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
</property>
```

**¬øQu√© es HiveServer2?**
- Servicio que permite conexiones remotas a Hive
- Usado por:
  - Beeline (CLI alternativo)
  - Herramientas BI (Tableau, Power BI)
  - Aplicaciones JDBC

**Iniciar HiveServer2:**
```bash
hive --service hiveserver2
```

**Conectar con Beeline:**
```bash
beeline -u jdbc:hive2://localhost:10000/default -n hadoop
```

---

#### 8. `hive.server2.thrift.bind.host`

**Descripci√≥n:** IP/hostname donde escucha HiveServer2

```xml
<property>
    <name>hive.server2.thrift.bind.host</name>
    <value>0.0.0.0</value>
</property>
```

**Valores:**
- `0.0.0.0`: Todas las interfaces (acceso desde cualquier IP)
- `localhost`: Solo acceso local
- `192.168.1.100`: IP espec√≠fica

---

#### 9. `hive.exec.mode.local.auto`

**Descripci√≥n:** Habilitar modo local autom√°tico para jobs peque√±os

```xml
<property>
    <name>hive.exec.mode.local.auto</name>
    <value>true</value>
</property>
```

**¬øQu√© hace?**
- Jobs peque√±os se ejecutan localmente (sin YARN)
- Evita overhead de distribuir tarea peque√±a
- M√°s r√°pido para queries simples

**Criterios (se ejecuta localmente si se cumplen TODOS):**
- Input < 128 MB
- Maps < 4
- Reduces = 1

---

#### 10. `hive.exec.mode.local.auto.inputbytes.max`

**Descripci√≥n:** M√°ximo de bytes de entrada para modo local

```xml
<property>
    <name>hive.exec.mode.local.auto.inputbytes.max</name>
    <value>134217728</value>
</property>
```

**Valor por defecto:** 134217728 bytes = 128 MB

---

#### 11. `hive.exec.mode.local.auto.input.files.max`

**Descripci√≥n:** M√°ximo de archivos de entrada para modo local

```xml
<property>
    <name>hive.exec.mode.local.auto.input.files.max</name>
    <value>4</value>
</property>
```

---

#### 12. `hive.exec.dynamic.partition`

**Descripci√≥n:** Habilitar particionamiento din√°mico

```xml
<property>
    <name>hive.exec.dynamic.partition</name>
    <value>true</value>
</property>
```

**¬øQu√© es particionamiento?**
- Dividir tabla en subdirectorios por columna(s)
- Ejemplo: particionar ventas por a√±o y mes

```
/warehouse/ventas/
‚îú‚îÄ‚îÄ year=2023/
‚îÇ   ‚îú‚îÄ‚îÄ month=01/
‚îÇ   ‚îú‚îÄ‚îÄ month=02/
‚îÇ   ‚îî‚îÄ‚îÄ month=03/
‚îî‚îÄ‚îÄ year=2024/
    ‚îú‚îÄ‚îÄ month=01/
    ‚îî‚îÄ‚îÄ month=02/
```

**Ventajas:**
- ‚úÖ Queries m√°s r√°pidos (skip particiones irrelevantes)
- ‚úÖ Mejor organizaci√≥n

---

#### 13. `hive.exec.dynamic.partition.mode`

**Descripci√≥n:** Modo de particionamiento din√°mico

```xml
<property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
</property>
```

**Valores:**
- **`strict`**: Requiere al menos una partici√≥n est√°tica
- **`nonstrict`**: Todas las particiones pueden ser din√°micas

---

#### 14. `hive.exec.max.dynamic.partitions`

**Descripci√≥n:** M√°ximo de particiones din√°micas totales

```xml
<property>
    <name>hive.exec.max.dynamic.partitions</name>
    <value>1000</value>
</property>
```

**Evita:** Crear miles de particiones accidentalmente

---

#### 15. `hive.exec.parallel`

**Descripci√≥n:** Ejecutar stages de query en paralelo cuando sea posible

```xml
<property>
    <name>hive.exec.parallel</name>
    <value>true</value>
</property>
```

**Efecto:**
- ‚úÖ Queries m√°s r√°pidos
- ‚úÖ Mejor uso de recursos

---

#### 16. `hive.exec.parallel.thread.number`

**Descripci√≥n:** N√∫mero de threads para ejecuci√≥n paralela

```xml
<property>
    <name>hive.exec.parallel.thread.number</name>
    <value>8</value>
</property>
```

**Recomendaci√≥n:** N√∫mero de cores disponibles

---

#### 17. `hive.vectorized.execution.enabled`

**Descripci√≥n:** Habilitar ejecuci√≥n vectorizada (procesar m√∫ltiples filas a la vez)

```xml
<property>
    <name>hive.vectorized.execution.enabled</name>
    <value>true</value>
</property>
```

**Ventaja:** Queries 3-10x m√°s r√°pidos

---

#### 18. `hive.compute.query.using.stats`

**Descripci√≥n:** Usar estad√≠sticas para responder queries simples

```xml
<property>
    <name>hive.compute.query.using.stats</name>
    <value>true</value>
</property>
```

**Ejemplo:**
```sql
SELECT COUNT(*) FROM tabla;
```
- Sin stats: Lee toda la tabla
- Con stats: Lee metastore (mucho m√°s r√°pido)

---

#### 19. `hive.support.concurrency`

**Descripci√≥n:** Habilitar control de concurrencia

```xml
<property>
    <name>hive.support.concurrency</name>
    <value>true</value>
</property>
```

**Necesario para:**
- Transacciones ACID
- INSERT, UPDATE, DELETE
- M√∫ltiples usuarios simult√°neos

---

#### 20. `hive.txn.manager`

**Descripci√≥n:** Gestor de transacciones

```xml
<property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
</property>
```

**Requerido para:** Transacciones ACID

---

### üìù Ejemplo Completo: hive-site.xml

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Configuraci√≥n del Metastore (Derby) -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:derby:;databaseName=/opt/hive/metastore_db;create=true</value>
        <description>URL de conexi√≥n a Derby (embedded)</description>
    </property>
    
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.apache.derby.jdbc.EmbeddedDriver</value>
        <description>Driver JDBC de Derby</description>
    </property>
    
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>APP</value>
    </property>
    
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>mine</value>
    </property>
    
    <!-- Warehouse en HDFS -->
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
        <description>Ubicaci√≥n de datos de tablas en HDFS</description>
    </property>
    
    <!-- Metastore remoto (comentado para modo embedded) -->
    <!--
    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://nodo1:9083</value>
        <description>URI del metastore remoto</description>
    </property>
    -->
    
    <!-- HiveServer2 -->
    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
        <description>Puerto de HiveServer2</description>
    </property>
    
    <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>0.0.0.0</value>
        <description>Escuchar en todas las interfaces</description>
    </property>
    
    <!-- Modo local autom√°tico -->
    <property>
        <name>hive.exec.mode.local.auto</name>
        <value>true</value>
        <description>Ejecutar jobs peque√±os localmente</description>
    </property>
    
    <property>
        <name>hive.exec.mode.local.auto.inputbytes.max</name>
        <value>134217728</value>
        <description>M√°ximo 128 MB para modo local</description>
    </property>
    
    <property>
        <name>hive.exec.mode.local.auto.input.files.max</name>
        <value>4</value>
        <description>M√°ximo 4 archivos para modo local</description>
    </property>
    
    <!-- Particionamiento din√°mico -->
    <property>
        <name>hive.exec.dynamic.partition</name>
        <value>true</value>
        <description>Habilitar particiones din√°micas</description>
    </property>
    
    <property>
        <name>hive.exec.dynamic.partition.mode</name>
        <value>nonstrict</value>
        <description>Permitir todas las particiones din√°micas</description>
    </property>
    
    <property>
        <name>hive.exec.max.dynamic.partitions</name>
        <value>1000</value>
        <description>M√°ximo de particiones din√°micas</description>
    </property>
    
    <!-- Ejecuci√≥n paralela -->
    <property>
        <name>hive.exec.parallel</name>
        <value>true</value>
        <description>Ejecutar stages en paralelo</description>
    </property>
    
    <property>
        <name>hive.exec.parallel.thread.number</name>
        <value>8</value>
        <description>Threads para ejecuci√≥n paralela</description>
    </property>
    
    <!-- Optimizaciones -->
    <property>
        <name>hive.vectorized.execution.enabled</name>
        <value>true</value>
        <description>Ejecuci√≥n vectorizada (m√°s r√°pido)</description>
    </property>
    
    <property>
        <name>hive.compute.query.using.stats</name>
        <value>true</value>
        <description>Usar estad√≠sticas para queries simples</description>
    </property>
    
    <!-- Transacciones ACID -->
    <property>
        <name>hive.support.concurrency</name>
        <value>true</value>
        <description>Habilitar control de concurrencia</description>
    </property>
    
    <property>
        <name>hive.txn.manager</name>
        <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
        <description>Gestor de transacciones ACID</description>
    </property>
    
    <!-- Compatibilidad MapReduce -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
        <description>Usar YARN para ejecutar jobs</description>
    </property>
</configuration>
```

---

---

## üìÇ Resumen de Ubicaciones

### Tabla de Archivos de Configuraci√≥n

| Archivo | Ubicaci√≥n | Prop√≥sito |
|---------|-----------|-----------|
| **core-site.xml** | `/opt/hadoop/hadoop-3.4.0/etc/hadoop/` | Configuraci√≥n central de Hadoop |
| **hdfs-site.xml** | `/opt/hadoop/hadoop-3.4.0/etc/hadoop/` | Configuraci√≥n de HDFS |
| **mapred-site.xml** | `/opt/hadoop/hadoop-3.4.0/etc/hadoop/` | Configuraci√≥n de MapReduce |
| **yarn-site.xml** | `/opt/hadoop/hadoop-3.4.0/etc/hadoop/` | Configuraci√≥n de YARN |
| **hive-site.xml** | `/opt/hive/conf/` | Configuraci√≥n de Hive |

---

### Comandos para Editar

```bash
# Editar core-site.xml
nano /opt/hadoop/hadoop-3.4.0/etc/hadoop/core-site.xml

# Editar hdfs-site.xml
nano /opt/hadoop/hadoop-3.4.0/etc/hadoop/hdfs-site.xml

# Editar mapred-site.xml
nano /opt/hadoop/hadoop-3.4.0/etc/hadoop/mapred-site.xml

# Editar yarn-site.xml
nano /opt/hadoop/hadoop-3.4.0/etc/hadoop/yarn-site.xml

# Editar hive-site.xml
nano /opt/hive/conf/hive-site.xml
```

---

---

## üîÑ Jerarqu√≠a de Configuraci√≥n

### Orden de Precedencia (de mayor a menor)

1. **Par√°metros en l√≠nea de comandos**
   ```bash
   hadoop jar mi_app.jar -Dmapreduce.map.memory.mb=4096
   ```

2. **Variables de configuraci√≥n en c√≥digo**
   ```java
   Configuration conf = new Configuration();
   conf.set("mapreduce.map.memory.mb", "4096");
   ```

3. **Archivos *-site.xml** (estos archivos)
   ```xml
   <property>
       <name>mapreduce.map.memory.mb</name>
       <value>1536</value>
   </property>
   ```

4. **Archivos *-default.xml** (valores por defecto de Hadoop)
   - Dentro de los JARs de Hadoop
   - No editables

---

### Aplicar Cambios en Configuraci√≥n

**‚ö†Ô∏è IMPORTANTE:** Despu√©s de editar cualquier archivo XML:

```bash
# Detener servicios
stop-all.sh

# Reiniciar servicios
start-all.sh

# Verificar que todo est√© corriendo
jps
```

**Output esperado de `jps`:**
```
12345 NameNode
12346 DataNode
12347 SecondaryNameNode
12348 ResourceManager
12349 NodeManager
12350 Jps
```

---

---

## üìä Tabla Resumen de Propiedades Cr√≠ticas

### Por Archivo

#### core-site.xml
| Propiedad | Valor T√≠pico | Descripci√≥n |
|-----------|--------------|-------------|
| `fs.defaultFS` | `hdfs://nodo1:9000` | URI del NameNode |
| `hadoop.tmp.dir` | `/opt/hadoop/hadoop-3.4.0/tmp` | Directorio temporal |
| `io.file.buffer.size` | `131072` (128 KB) | Buffer de I/O |

#### hdfs-site.xml
| Propiedad | Valor T√≠pico | Descripci√≥n |
|-----------|--------------|-------------|
| `dfs.replication` | `1` (dev), `3` (prod) | Factor de replicaci√≥n |
| `dfs.namenode.name.dir` | `file:///opt/.../namenode` | Metadatos de HDFS |
| `dfs.datanode.data.dir` | `file:///opt/.../datanode` | Bloques de datos |
| `dfs.blocksize` | `134217728` (128 MB) | Tama√±o de bloque |

#### mapred-site.xml
| Propiedad | Valor T√≠pico | Descripci√≥n |
|-----------|--------------|-------------|
| `mapreduce.framework.name` | `yarn` | Framework de ejecuci√≥n |
| `mapreduce.map.memory.mb` | `1536` | Memoria para Map |
| `mapreduce.reduce.memory.mb` | `3072` | Memoria para Reduce |
| `mapreduce.map.java.opts` | `-Xmx1024m` | Heap de JVM para Map |

#### yarn-site.xml
| Propiedad | Valor T√≠pico | Descripci√≥n |
|-----------|--------------|-------------|
| `yarn.nodemanager.aux-services` | `mapreduce_shuffle` | Servicio shuffle |
| `yarn.resourcemanager.hostname` | `nodo1` | Hostname del RM |
| `yarn.nodemanager.resource.memory-mb` | `8192` | Memoria total YARN |
| `yarn.scheduler.minimum-allocation-mb` | `1024` | Memoria m√≠nima |
| `yarn.scheduler.maximum-allocation-mb` | `8192` | Memoria m√°xima |

#### hive-site.xml
| Propiedad | Valor T√≠pico | Descripci√≥n |
|-----------|--------------|-------------|
| `javax.jdo.option.ConnectionURL` | `jdbc:derby:...` | Conexi√≥n a metastore |
| `hive.metastore.warehouse.dir` | `/user/hive/warehouse` | Ubicaci√≥n de datos |
| `hive.exec.mode.local.auto` | `true` | Modo local autom√°tico |
| `hive.exec.dynamic.partition` | `true` | Particiones din√°micas |

---

---

## üí° Tips Finales

### 1. Validar Configuraci√≥n

```bash
# Ver configuraci√≥n activa de Hadoop
hadoop conf

# Ver configuraci√≥n espec√≠fica
hadoop conf | grep fs.defaultFS
```

### 2. Backup de Configuraci√≥n

```bash
# Hacer backup antes de cambiar
cd /opt/hadoop/hadoop-3.4.0/etc/hadoop/
cp core-site.xml core-site.xml.backup
cp hdfs-site.xml hdfs-site.xml.backup
cp mapred-site.xml mapred-site.xml.backup
cp yarn-site.xml yarn-site.xml.backup
```

### 3. Validar Sintaxis XML

```bash
# Verificar que XML est√© bien formado
xmllint --noout core-site.xml

# Si no tienes xmllint, instalar
sudo yum install libxml2
```

### 4. Ver Configuraci√≥n en Web UI

**HDFS NameNode:**
```
http://localhost:9870/conf
```

**YARN ResourceManager:**
```
http://localhost:8088/conf
```

### 5. Logs de Errores

```bash
# Ver logs si algo falla
tail -f /opt/hadoop/hadoop-3.4.0/logs/hadoop-hadoop-namenode-*.log
tail -f /opt/hadoop/hadoop-3.4.0/logs/hadoop-hadoop-datanode-*.log
tail -f /opt/hadoop/hadoop-3.4.0/logs/yarn-hadoop-resourcemanager-*.log
```

---

---

## üéì Ejemplos de Configuraci√≥n por Escenario

### Escenario 1: Desarrollo Local (1 m√°quina, 8 GB RAM)

**core-site.xml:**
```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
</property>
```

**hdfs-site.xml:**
```xml
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
```

**yarn-site.xml:**
```xml
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>4096</value>
</property>
```

---

### Escenario 2: Cluster Peque√±o (3 nodos, 16 GB RAM cada uno)

**core-site.xml:**
```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://master:9000</value>
</property>
```

**hdfs-site.xml:**
```xml
<property>
    <name>dfs.replication</name>
    <value>2</value>
</property>

<property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///disk1/hadoop/namenode,file:///disk2/hadoop/namenode</value>
</property>
```

**yarn-site.xml:**
```xml
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>12288</value>
</property>

<property>
    <name>yarn.scheduler.maximum-allocation-mb</name>
    <value>12288</value>
</property>
```

---

### Escenario 3: Producci√≥n (10+ nodos, 64 GB RAM cada uno)

**hdfs-site.xml:**
```xml
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>

<property>
    <name>dfs.blocksize</name>
    <value>268435456</value>  <!-- 256 MB -->
</property>

<property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///disk1/hadoop/data,file:///disk2/hadoop/data,file:///disk3/hadoop/data,file:///disk4/hadoop/data</value>
</property>
```

**yarn-site.xml:**
```xml
<property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>57344</value>  <!-- 56 GB -->
</property>

<property>
    <name>yarn.scheduler.maximum-allocation-mb</name>
    <value>16384</value>  <!-- 16 GB -->
</property>

<property>
    <name>yarn.nodemanager.resource.cpu-vcores</name>
    <value>24</value>
</property>
```

**mapred-site.xml:**
```xml
<property>
    <name>mapreduce.map.memory.mb</name>
    <value>4096</value>
</property>

<property>
    <name>mapreduce.reduce.memory.mb</name>
    <value>8192</value>
</property>

<property>
    <name>mapreduce.map.java.opts</name>
    <value>-Xmx3072m</value>
</property>

<property>
    <name>mapreduce.reduce.java.opts</name>
    <value>-Xmx6144m</value>
</property>
```

---

<div align="center">

## üéì Fin de la Gu√≠a de Configuraci√≥n

**Referencia Completa de Archivos XML de Hadoop y Hive**

‚úÖ 5 archivos explicados en detalle  
‚úÖ 80+ propiedades documentadas  
‚úÖ Valores por defecto y recomendados  
‚úÖ Ejemplos por escenario  
‚úÖ Tips de troubleshooting  
‚úÖ F√≥rmulas de c√°lculo de recursos  

---

*Gu√≠a de Configuraci√≥n - Sistemas Inteligentes*  
*Febrero 2026*

</div>

# üöÄ Gu√≠a Completa: CentOS + Hadoop 3.4.0 + Hive 3.1.3

> **Curso:** Sistemas Inteligentes
> **Objetivo:** Configurar un entorno Big Data completo desde cero
> **Modo:** Pseudo-distribuido (un solo nodo)
> **Fecha:** Febrero 2026

---

## üìã Tabla de Contenido

### PARTE I: Configuraci√≥n de CentOS

1. [Requisitos Previos y Descargas](#1-requisitos-previos-y-descargas)
2. [Configuraci√≥n de Red](#2-configuraci√≥n-de-red-y-actualizaci√≥n)
3. [Instalaci√≥n de Interfaz Gr√°fica](#3-instalaci√≥n-de-interfaz-gr√°fica-gui)
4. [VirtualBox Guest Additions](#4-instalaci√≥n-de-virtualbox-guest-additions)

### PARTE II: Instalaci√≥n de Hadoop 3.4.0

5. [Instalaci√≥n de Paquetes Base](#5-instalaci√≥n-de-paquetes-base)
6. [Crear Usuario Hadoop](#6-crear-usuario-hadoop)
7. [Instalaci√≥n de Java 8](#7-instalaci√≥n-de-java-8-openjdk)
8. [Registrar Java en el Sistema](#8-registrar-jdk-en-el-sistema-de-alternativas)
9. [Configurar Variables de Entorno Java](#9-configurar-java_home)
10. [Descargar Hadoop](#10-descarga-de-hadoop-340)
11. [Descomprimir Hadoop](#11-descompresi√≥n-y-organizaci√≥n)
12. [Variables de Entorno Hadoop](#12-configurar-variables-de-entorno-hadoop)
13. [Configurar Hostname](#13-cambiar-hostname-a-nodo1)
14. [Configurar core-site.xml](#14-configurar-core-sitexml)
15. [Configurar hdfs-site.xml](#15-configurar-hdfs-sitexml-y-crear-carpetas)
16. [Formatear NameNode](#16-formatear-el-namenode)
17. [Verificar Interfaz Web HDFS](#17-interfaz-web-browse-directory)
18. [Operaciones B√°sicas HDFS](#18-operaciones-b√°sicas-en-hdfs)
19. [Configurar YARN](#19-configuraci√≥n-de-yarn)
20. [Ejecutar MapReduce](#20-ejecutar-mapreduce-wordcount)

### PARTE III: Instalaci√≥n de Apache Hive

21. [Instalar Hive 3.1.3](#21-instalaci√≥n-de-apache-hive-313)
22. [Configurar Variables Hive](#22-configurar-variables-de-entorno-hive)
23. [Resolver Conflictos de Librer√≠as](#23-resolver-conflictos-de-librer√≠as-guava)
24. [Configurar Almacenamiento HDFS](#24-configurar-directorios-hdfs-para-hive)
25. [Configurar Metastore](#25-configurar-hive-sitexml-metastore)
26. [Inicializar Esquema](#26-inicializar-esquema-de-metadatos)
27. [Probar Hive](#27-ejecutar-y-probar-hive)

---

## üéØ PARTE I: CONFIGURACI√ìN DE CENTOS

---

## 1. Requisitos Previos y Descargas

### üì• Software Necesario

| Componente                      | Fuente                                         | Descripci√≥n                    |
| ------------------------------- | ---------------------------------------------- | ------------------------------- |
| **CentOS 10 (Imagen VM)** | https://www.osboxes.org/centos/#centos-10-info | M√°quina virtual preconfigurada |
| **VirtualBox**            | https://www.virtualbox.org/wiki/Downloads      | Software de virtualizaci√≥n     |

### ‚öôÔ∏è Configuraci√≥n Inicial

1. **Descomprimir** la unidad de m√°quina virtual descargada
2. **Abrir VirtualBox** ‚Üí Nueva M√°quina Virtual
3. Seleccionar: **"Usar un archivo de disco duro virtual existente"**
4. **Red**: Configurar como **Adaptador Puente** o **NAT**
5. **Credenciales por defecto:**
   - Usuario: `osboxes`
   - Password: `osboxes.org`

---

## 2. Configuraci√≥n de Red y Actualizaci√≥n

### üîÑ Actualizar el Sistema

```bash
sudo yum update
```

O alternativamente:

```bash
sudo dnf update
```

---

### üåê Soluci√≥n de Problemas de Conexi√≥n

#### Paso 1: Probar Conectividad

```bash
ping -c 4 8.8.8.8
```

**Si recibes:** `Network is unreachable` ‚Üí Tu interfaz de red est√° desactivada

---

#### Paso 2: Identificar y Activar la Interfaz

```bash
# Ver interfaces disponibles
ip addr
```

Busca tu interfaz (generalmente `enp0s3`):

```bash
# M√©todo 1: Con nmcli
sudo nmcli device connect enp0s3

# M√©todo 2: Con ip link
sudo ip link set enp0s3 up
```

---

#### Paso 3: Configurar Inicio Autom√°tico (NMTUI)

```bash
# Abrir configurador de red
sudo nmtui
```

**Navegaci√≥n en NMTUI:**

1. Seleccionar: **"Edit a connection"**
2. Seleccionar tu interfaz (ej: `enp0s3`)
3. Seleccionar: **"Edit"**
4. Marcar con `[X]`: **"Automatically connect"**
5. **OK** ‚Üí **Back** ‚Üí **Quit**

---

#### Paso 4: Solicitar IP (DHCP)

```bash
sudo dhclient
```

**Verificar conexi√≥n:**

```bash
ping -c 4 google.com
```

---

## 3. Instalaci√≥n de Interfaz Gr√°fica (GUI)

> **Nota:** Si prefieres trabajar con entorno gr√°fico en lugar de solo terminal

### üì¶ Instalar GNOME Desktop

```bash
# Instalar grupo de paquetes (800MB - 1GB)
sudo dnf groupinstall "Server with GUI"
```

---

### üñ•Ô∏è Cambiar Modo de Arranque

```bash
# Verificar modo actual
systemctl get-default

# Cambiar a modo gr√°fico
sudo systemctl set-default graphical.target

# Iniciar interfaz gr√°fica ahora (sin reiniciar)
sudo systemctl start graphical.target
```

---

## 4. Instalaci√≥n de VirtualBox Guest Additions

> **Beneficios:** Mejor resoluci√≥n de pantalla, compartir carpetas, portapapeles compartido

### üì¶ Paso A: Instalar Dependencias

```bash
# Instalar repositorio EPEL
sudo dnf install -y epel-release

# Instalar herramientas de desarrollo
sudo dnf install -y gcc make perl kernel-devel kernel-headers bzip2

# Actualizar kernel (IMPORTANTE)
sudo dnf update kernel-*
```

> ‚ö†Ô∏è **Si el kernel se actualiza, reinicia la VM antes de continuar:**

```bash
sudo reboot
```

---

### üíø Paso B: Montar e Instalar Guest Additions

**En el men√∫ de VirtualBox:**

- **Dispositivos** ‚Üí **Insertar imagen de CD de las Guest Additions**

**En la terminal de CentOS:**

```bash
# Crear punto de montaje
sudo mkdir -p /mnt/cdrom

# Montar el CD
sudo mount /dev/cdrom /mnt/cdrom

# Ejecutar instalador
cd /mnt/cdrom
sudo ./VBoxLinuxAdditions.run

# Reiniciar para aplicar cambios
sudo reboot
```

---

### ‚ö†Ô∏è Soluci√≥n de Errores Comunes

Si la instalaci√≥n falla, ejecuta estos comandos de refuerzo:

```bash
# Instalar herramientas de desarrollo completas
sudo dnf groupinstall "Development Tools"
sudo dnf install kernel-devel dkms

# Instalar m√≥dulos espec√≠ficos de VirtualBox
sudo dnf install centos-release-kmods
sudo dnf install virtualbox-guest-additions

# Habilitar y arrancar el servicio
sudo systemctl enable vboxservice
sudo systemctl start vboxservice
```

---

### üí° Tip de Estudio

> Crea **snapshots (instant√°neas)** en VirtualBox antes de realizar cambios cr√≠ticos para poder volver atr√°s si algo falla.

---

---

## üêò PARTE II: INSTALACI√ìN DE HADOOP 3.4.0

> **Basado en:** Playlist "Big Data Hadoop Espa√±ol" üî•
> **Enlace:** https://www.youtube.com/playlist?list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B

---

## 5. Instalaci√≥n de Paquetes Base

> **Video #5:** https://www.youtube.com/watch?v=49f8rpFV8BY&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=5

### üì¶ Instalar Herramientas de Red

```bash
# Herramientas de red (ifconfig, netstat, etc.)
sudo yum install net-tools

# Wget para descargas desde internet
sudo yum install wget

# Telnet para pruebas de conectividad
sudo yum install telnet
```

---

### üåê Obtener IP de la M√°quina Virtual

```bash
ifconfig
```

**Anota tu IP** (algo como `10.0.2.15` o `192.168.x.x`), la necesitar√°s m√°s adelante.

---

## 6. Crear Usuario Hadoop

> **Video #6:** https://www.youtube.com/watch?v=B9x3v4fD-4E&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=6

### üë§ Crear Usuario y Asignar Permisos

```bash
# Crear el usuario hadoop
sudo useradd hadoop

# Asignar contrase√±a
sudo passwd hadoop
# (Ingresa la contrase√±a dos veces - los caracteres no se ver√°n)
```

---

### üîê Darle Permisos de Administrador (Sudo/Root)

> **‚ö†Ô∏è IMPORTANTE:** Esto permite que el usuario hadoop ejecute comandos con privilegios de root usando `sudo`.  
> **Recomendaci√≥n:** Solo para entornos de **desarrollo/aprendizaje**. En **producci√≥n**, limitar permisos espec√≠ficos.

```bash
# OPCI√ìN 1: Agregar al grupo wheel (m√©todo recomendado en CentOS/RHEL)
sudo usermod -aG wheel hadoop

# OPCI√ìN 2: Agregar entrada en sudoers (m√©todo alternativo)
# Editar archivo sudoers de forma segura
sudo visudo

# Agregar esta l√≠nea al final del archivo:
# hadoop ALL=(ALL) NOPASSWD: ALL
# (NOPASSWD permite ejecutar sudo sin pedir contrase√±a - √∫til para scripts)

# OPCI√ìN 3: Sin contrase√±a solo para comandos espec√≠ficos
# hadoop ALL=(ALL) NOPASSWD: /opt/hadoop/hadoop-3.4.0/sbin/*, /usr/bin/systemctl
```

**üí° Explicaci√≥n de Opciones:**

| Opci√≥n | Seguridad | Uso | Requiere Password |
|--------|-----------|-----|-------------------|
| **Opci√≥n 1** (wheel) | Media | Desarrollo/Producci√≥n | ‚úÖ S√≠ |
| **Opci√≥n 2** (NOPASSWD: ALL) | Baja | Solo desarrollo | ‚ùå No |
| **Opci√≥n 3** (comandos espec√≠ficos) | Alta | Producci√≥n | ‚ùå No |

**‚úÖ Verificar permisos:**

```bash
# Ver grupos del usuario hadoop
groups hadoop
# Esperado: hadoop wheel

# Probar sudo (desde usuario hadoop)
sudo whoami
# Esperado: root

# Verificar entrada en sudoers
sudo grep hadoop /etc/sudoers
```

---

### üìÅ Crear Carpeta y Asignar Permisos

```bash
# Crear carpeta en /opt
sudo mkdir /opt/hadoop

# Cambiar propietario al usuario hadoop
sudo chown -R hadoop:hadoop /opt/hadoop

# Dar permisos de lectura, escritura y ejecuci√≥n
sudo chmod -R 755 /opt/hadoop
```

---

### üîÑ Cambiar al Usuario Hadoop

```bash
# Cambiar de root a hadoop (el guion '-' es importante)
su - hadoop
```

> **Tip:** El guion `-` carga las variables de entorno y te sit√∫a en `/home/hadoop`

---

## 7. Instalaci√≥n de Java 8 OpenJDK

> **Video #7:** https://www.youtube.com/watch?v=1rpJHLYim_k&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=7

### üì• Descargar Java 8

**Fuente:** https://www.oracle.com/latam/java/technologies/javase/javase8-archive-downloads.html

> **Nota:** Necesitas registrarte en Oracle para descargar

**Archivo a descargar:** `jdk-8u202-linux-x64.tar.gz`

---

### üìÇ Mover y Descomprimir

```bash
# Mover el archivo desde Downloads a /opt
sudo mv /home/hadoop/Downloads/jdk-8u202-linux-x64.tar.gz /opt/

# Entrar a /opt
cd /opt/

# Descomprimir
sudo tar -zxvf jdk-8u202-linux-x64.tar.gz

# Verificar carpeta resultante
ls -l /opt/
# Deber√≠as ver: jdk1.8.0_202
```

---

### üîê Asignar Permisos al Usuario Hadoop

```bash
sudo chown -R hadoop:hadoop /opt/jdk1.8.0_202
```

---

### üßπ Limpiar Archivo Comprimido (Opcional)

```bash
# Eliminar el .tar.gz para liberar espacio
sudo rm /opt/jdk-8u202-linux-x64.tar.gz
```

---

## 8. Registrar JDK en el Sistema de Alternativas

> **Video #8:** https://www.youtube.com/watch?v=fNKL7IZs0LA&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=8

### üîß Registrar Ejecutables de Java

```bash
# Registrar 'java'
sudo alternatives --install /usr/bin/java java /opt/jdk1.8.0_202/bin/java 2

# Configurar java como predeterminado
sudo alternatives --config java
# Selecciona el n√∫mero correspondiente a /opt/jdk1.8.0_202/bin/java

# Registrar 'jar'
sudo alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_202/bin/jar 2

# Registrar 'javac' (compilador - necesario para Hadoop)
sudo alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_202/bin/javac 2
```

---

### ‚úÖ Verificar Instalaci√≥n

```bash
# Verificar versi√≥n de Java
java -version
# Salida esperada: java version "1.8.0_202"

# Verificar compilador
javac -version
# Salida esperada: javac 1.8.0_202
```

---

## 9. Configurar JAVA_HOME

> **Video #9:** https://www.youtube.com/watch?v=0VPMiQifwfo&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=9

### üîß Editar .bashrc del Usuario Hadoop

```bash
# Cambiar al usuario hadoop
su - hadoop

# Ir al home
cd /home/hadoop/

# Editar archivo de configuraci√≥n
nano .bashrc
```

---

### üìù Agregar al Final del Archivo

```bash
# Configuraci√≥n de Java
export JAVA_HOME=/opt/jdk1.8.0_202
export JRE_HOME=/opt/jdk1.8.0_202/jre
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
```

**Guardar:** `Ctrl + O` ‚Üí `Enter` ‚Üí `Ctrl + X`

---

### üîÑ Recargar Variables de Entorno

```bash
source /home/hadoop/.bashrc

# Verificar que se carg√≥ correctamente
echo $JAVA_HOME
# Salida esperada: /opt/jdk1.8.0_202
```

---

## 10. Descarga de Hadoop 3.4.0

> **Video #10:** https://www.youtube.com/watch?v=wi_DoY8jirI&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=10

### üì• Descargar Hadoop

```bash
# Entrar a la carpeta de hadoop
cd /opt/hadoop/

# Descargar con wget
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz

# Verificar descarga
ls -lh hadoop-3.4.0.tar.gz
# Deber√≠as ver el archivo (~600 MB)
```

---

## 11. Descompresi√≥n y Organizaci√≥n

> **Video #11:** https://www.youtube.com/watch?v=d3k-LZQgPoI&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=11

### üì¶ Descomprimir Hadoop

```bash
# Descomprimir en /opt/hadoop
tar -zxvf hadoop-3.4.0.tar.gz

# Verificar carpeta resultante
ls -l
# Deber√≠as ver: hadoop-3.4.0/

# Eliminar archivo comprimido (opcional)
rm hadoop-3.4.0.tar.gz
```

---

## 12. Configurar Variables de Entorno Hadoop

> **Video #12:** https://www.youtube.com/watch?v=8jEmG80fG8U&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=12

### üîß Editar .bashrc

```bash
# Ir al home del usuario hadoop
cd /home/hadoop/

# Editar .bashrc
nano .bashrc
```

---

### üìù Agregar Variables de Hadoop

```bash
# Configuraci√≥n de Hadoop
export HADOOP_HOME=/opt/hadoop/hadoop-3.4.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

**Guardar:** `Ctrl + O` ‚Üí `Enter` ‚Üí `Ctrl + X`

---

### üîÑ Recargar y Verificar

```bash
# Recargar variables
source /home/hadoop/.bashrc

# Verificar versi√≥n de Hadoop
hadoop version
```

**Salida esperada:**

```
Hadoop 3.4.0
Source code repository https://github.com/apache/hadoop.git -r ...
Compiled by ... on ...
```

---

## 13. Cambiar Hostname a nodo1

> **Video #14:** https://www.youtube.com/watch?v=tYBytDlwWIQ&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=14

### üñ•Ô∏è Configurar Nombre del Host

```bash
# Establecer hostname
sudo nmcli general hostname nodo1

# Verificar cambio
hostname
# Salida esperada: nodo1
```

---

### üìù Actualizar Archivo /etc/hosts

```bash
# Editar archivo de hosts
sudo nano /etc/hosts
```

**Agregar o modificar estas l√≠neas:**

```
127.0.0.1   localhost nodo1
::1         localhost nodo1
10.0.2.15   nodo1
```

> **Importante:** Reemplaza `10.0.2.15` con la IP que obtuviste con `ifconfig`

**Guardar:** `Ctrl + O` ‚Üí `Enter` ‚Üí `Ctrl + X`

---

## 14. Configurar core-site.xml

> **Video #16:** https://www.youtube.com/watch?v=rvloXElUp2w&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=16

### üìù Editar Archivo de Configuraci√≥n

```bash
# Editar core-site.xml
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/core-site.xml
```

---

### üîß Contenido de core-site.xml

**Agregar dentro de `<configuration>`:**

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://nodo1:9000</value>
        <description>NameNode URI</description>
    </property>
</configuration>
```

---

### üî• Abrir Puerto en Firewall

```bash
# Abrir puerto 9000 para HDFS
sudo firewall-cmd --zone=public --add-port=9000/tcp --permanent

# Recargar firewall
sudo firewall-cmd --reload

# Verificar puertos abiertos
sudo firewall-cmd --list-ports
```

---

## 15. Configurar hdfs-site.xml y Crear Carpetas

> **Video #17:** https://www.youtube.com/watch?v=eIYX_IXVoU0&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=17

### üìù Editar hdfs-site.xml

```bash
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/hdfs-site.xml
```

---

### üîß Contenido de hdfs-site.xml

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <description>Factor de replicaci√≥n (1 para un solo nodo)</description>
    </property>
  
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/datos/namenode</value>
        <description>Directorio de metadatos del NameNode</description>
    </property>
  
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/datos/datanode</value>
        <description>Directorio de almacenamiento del DataNode</description>
    </property>
</configuration>
```

---

### üìÅ Crear Carpetas de Datos

```bash
# Ir a la ra√≠z del sistema
cd /

# Crear estructura de directorios
sudo mkdir /datos
cd /datos
sudo mkdir namenode
sudo mkdir datanode

# Asignar permisos al usuario hadoop
sudo chown -R hadoop:hadoop /datos

# Verificar
ls -l /datos
```

---

## 16. Formatear el NameNode

> **Video #18:** https://www.youtube.com/watch?v=rJFrPBtciXY&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=18

### üîß Inicializar HDFS

```bash
# Formatear el NameNode (solo la primera vez)
hdfs namenode -format
```

**Salida esperada:**

```
Storage directory /datos/namenode has been successfully formatted.
```

---

### üöÄ Iniciar Servicios HDFS

```bash
# Iniciar HDFS (NameNode, DataNode, SecondaryNameNode)
start-dfs.sh
```

**El comando iniciar√°:**

- NameNode en `nodo1`
- DataNode en `nodo1`
- Secondary NameNode en `nodo1`

---

### ‚úÖ Verificar Servicios Activos

```bash
# Ver procesos Java en ejecuci√≥n
jps
```

**Salida esperada:**

```
12345 NameNode
12346 DataNode
12347 SecondaryNameNode
12348 Jps
```

---

## 17. Interfaz Web Browse Directory

> **Video HDFS Hadoop #1:** https://www.youtube.com/watch?v=38DgYWd7fYg&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=19

### üåê Acceder a la Interfaz Web

**Abrir en navegador:**

```
http://localhost:9870
```

O desde otra m√°quina:

```
http://tu_ip_centos:9870
```

> **Nota:** En versiones anteriores de Hadoop el puerto era `50070`

---

### üî• Abrir Puerto para Interfaz Web

```bash
# Abrir puerto 9870
sudo firewall-cmd --zone=public --add-port=9870/tcp --permanent
sudo firewall-cmd --reload
```

---

### üìä Funciones de la Interfaz Web

| Secci√≥n                      | Descripci√≥n                                         |
| ----------------------------- | ---------------------------------------------------- |
| **Overview**            | Estado general del cluster, espacio usado/disponible |
| **Datanodes**           | Lista de DataNodes activos                           |
| **Utilities ‚Üí Browse** | Explorador de archivos HDFS                          |
| **Logs**                | Logs del NameNode                                    |

---

## 18. Operaciones B√°sicas en HDFS

> **Video HDFS Hadoop #2.1:** https://www.youtube.com/watch?v=PtcoKR9x0t0&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=20

### üìÑ Crear Archivo de Prueba

```bash
# Crear archivo local
echo "Hola Mundo Hadoop HDFS" >> prueba.txt

# Ver contenido
cat prueba.txt
```

---

### üìÅ Crear Carpeta en HDFS

```bash
# Crear directorio en HDFS
hdfs dfs -mkdir /prueba

# Listar contenido de ra√≠z
hdfs dfs -ls /
```

---

### üì§ Subir Archivo a HDFS

```bash
# Subir archivo local a HDFS
hdfs dfs -put prueba.txt /prueba/

# Verificar
hdfs dfs -ls /prueba
```

---

### üì• Descargar Archivo desde HDFS

```bash
# Descargar archivo de HDFS a local
hdfs dfs -get /prueba/prueba.txt ./prueba_descargado.txt

# Verificar
cat prueba_descargado.txt
```

---

### üëÅÔ∏è Ver Contenido de Archivo en HDFS

```bash
# Ver contenido completo
hdfs dfs -cat /prueba/prueba.txt

# Ver primeras l√≠neas
hdfs dfs -head /prueba/prueba.txt
```

---

### üóëÔ∏è Eliminar Archivos y Carpetas

```bash
# Eliminar archivo espec√≠fico
hdfs dfs -rm /prueba/prueba.txt

# Eliminar carpeta y contenido (recursivo)
hdfs dfs -rm -r /prueba

# Eliminar permanentemente (sin papelera)
hdfs dfs -rm -r -skipTrash /prueba
```

---

### üìä Comandos √ötiles Adicionales

```bash
# Ver tama√±o de archivo
hdfs dfs -du -h /ruta/archivo

# Copiar archivo dentro de HDFS
hdfs dfs -cp /origen/archivo /destino/

# Mover archivo dentro de HDFS
hdfs dfs -mv /origen/archivo /destino/

# Ver espacio usado/disponible
hdfs dfs -df -h

# Ver informaci√≥n de bloques
hdfs fsck /ruta/archivo -files -blocks -locations
```

---

## 19. Configuraci√≥n de YARN

> **Video MapReduce con Hadoop #1:** https://www.youtube.com/watch?v=R7w8FAlnhAw&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=23

### üìù Configurar mapred-site.xml

```bash
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/mapred-site.xml
```

**Contenido:**

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
        <description>Framework para MapReduce</description>
    </property>
  
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
```

---

### üìù Configurar yarn-site.xml

```bash
vi /opt/hadoop/hadoop-3.4.0/etc/hadoop/yarn-site.xml
```

**Contenido:**

```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>nodo1</value>
        <description>Host del ResourceManager</description>
    </property>
  
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
        <description>Servicio auxiliar para MapReduce</description>
    </property>
  
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
  
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>0.0.0.0:8088</value>
        <description>Puerto de la interfaz web de YARN</description>
    </property>
  
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
        <description>Deshabilitar verificaci√≥n de memoria virtual</description>
    </property>
</configuration>
```

---

### üî• Abrir Puerto YARN

```bash
# Abrir puerto 8088 para YARN
sudo firewall-cmd --zone=public --add-port=8088/tcp --permanent
sudo firewall-cmd --reload
```

---

### üöÄ Iniciar Servicios YARN

```bash
# Detener HDFS primero
stop-dfs.sh

# Reiniciar HDFS
start-dfs.sh

# Iniciar YARN
start-yarn.sh
```

---

### ‚úÖ Verificar Servicios

```bash
# Ver procesos activos
jps
```

**Salida esperada:**

```
12345 NameNode
12346 DataNode
12347 SecondaryNameNode
12348 ResourceManager
12349 NodeManager
12350 Jps
```

---

### üåê Interfaz Web de YARN

**Abrir en navegador:**

```
http://localhost:8088/cluster/
```

O desde otra m√°quina:

```
http://tu_ip_centos:8088/cluster/
```

---

### üéØ Comandos de Inicio/Cierre R√°pido

```bash
# Iniciar todo (HDFS + YARN)
start-all.sh

# Detener todo
stop-all.sh

# Solo HDFS
start-dfs.sh
stop-dfs.sh

# Solo YARN
start-yarn.sh
stop-yarn.sh
```

---

## 20. Ejecutar MapReduce (WordCount)

> **Video MapReduce con Hadoop #3:** https://www.youtube.com/watch?v=woUzV_liwto&list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B&index=25

### üìÑ Preparar Datos de Entrada

```bash
# Descargar archivo de texto (ejemplo: Los Miserables)
# Puedes usar cualquier archivo .txt grande

# Crear carpeta en HDFS
hdfs dfs -mkdir /libros

# Subir archivo
hdfs dfs -put Los_Miserables.txt /libros/

# Verificar
hdfs dfs -ls /libros
```

---

### üöÄ Ejecutar Job de MapReduce

```bash
# Ir a la carpeta de ejemplos
cd /opt/hadoop/hadoop-3.4.0/share/hadoop/mapreduce/

# Ejecutar WordCount
hadoop jar hadoop-mapreduce-examples-3.4.0.jar wordcount /libros /libros_salida
```

---

### üìä Flujo de MapReduce

**Lo que sucede internamente:**

1. **Map Phase:** Divide el texto y asigna "1" a cada palabra

   - Ejemplo: "Hadoop" ‚Üí ("Hadoop", 1)
2. **Shuffle & Sort:** YARN agrupa palabras iguales

   - Ejemplo: "Hadoop" ‚Üí [1, 1, 1]
3. **Reduce Phase:** Suma los valores

   - Ejemplo: "Hadoop" ‚Üí 3

---

### üì• Revisar Resultados

```bash
# Listar archivos generados
hdfs dfs -ls /libros_salida

# Ver contenido del resultado
hdfs dfs -cat /libros_salida/part-r-00000

# Ver primeras l√≠neas
hdfs dfs -cat /libros_salida/part-r-00000 | head -20
```

**Salida ejemplo:**

```
hadoop  150
mapreduce  89
yarn  67
hdfs  234
...
```

---

### üåê Monitoreo en YARN Web UI

Mientras el job se ejecuta, abre:

```
http://localhost:8088
```

Ver√°s:

- Estado: **RUNNING** ‚Üí **FINISHED**
- Progreso: Map % ‚Üí Shuffle % ‚Üí Reduce %
- Memoria usada
- Tiempo de ejecuci√≥n

---

### üîÑ Ejecutar de Nuevo

> **Nota:** MapReduce nunca sobreescribe carpetas de salida

```bash
# Eliminar carpeta de salida anterior
hdfs dfs -rm -r /libros_salida

# Ejecutar nuevamente
hadoop jar hadoop-mapreduce-examples-3.4.0.jar wordcount /libros /libros_salida
```

---

### üìä Otros Ejemplos de MapReduce

```bash
# Pi (estimaci√≥n de œÄ usando Monte Carlo)
hadoop jar hadoop-mapreduce-examples-3.4.0.jar pi 10 100

# Grep (buscar patrones en archivos)
hadoop jar hadoop-mapreduce-examples-3.4.0.jar grep /libros /grep_salida 'hadoop'

# TeraSort (ordenar grandes vol√∫menes de datos)
hadoop jar hadoop-mapreduce-examples-3.4.0.jar teragen 1000 /tera_input
hadoop jar hadoop-mapreduce-examples-3.4.0.jar terasort /tera_input /tera_output
```

---

---

## üêù PARTE III: INSTALACI√ìN DE APACHE HIVE

---

## 21. Instalaci√≥n de Apache Hive 3.1.3

### üì• Descargar Hive

```bash
# Ir a /opt
cd /opt

# Descargar Hive 3.1.3
sudo wget https://archive.apache.org/dist/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz

# Descomprimir
sudo tar -zxvf apache-hive-3.1.3-bin.tar.gz

# Renombrar para simplificar
sudo mv apache-hive-3.1.3-bin /opt/hive

# Asignar permisos al usuario hadoop
sudo chown -R hadoop:hadoop /opt/hive
```

---

## 22. Configurar Variables de Entorno Hive

### üîß Editar .bashrc

```bash
# Cambiar a usuario hadoop
su - hadoop

# Editar .bashrc
nano ~/.bashrc
```

**Agregar al final:**

```bash
# Configuraci√≥n de Hive
export HIVE_HOME=/opt/hive
export PATH=$PATH:$HIVE_HOME/bin
```

**Guardar y recargar:**

```bash
source ~/.bashrc

# Verificar
echo $HIVE_HOME
# Salida esperada: /opt/hive
```

---

## 23. Resolver Conflictos de Librer√≠as (Guava)

> **Problema:** Hive 3.1.3 incluye Guava 19.0 que es incompatible con Hadoop 3.4.0

### üîß Fix de Guava

```bash
# Eliminar librer√≠a obsoleta de Hive
rm /opt/hive/lib/guava-19.0.jar

# Copiar versi√≥n compatible desde Hadoop
cp /opt/hadoop/hadoop-3.4.0/share/hadoop/common/lib/guava-*.jar /opt/hive/lib/

# Verificar
ls /opt/hive/lib/ | grep guava
# Salida esperada: guava-27.0-jre.jar (o versi√≥n superior)
```

---

## 24. Configurar Directorios HDFS para Hive

### üìÅ Crear Carpetas en HDFS

```bash
# Asegurar que HDFS est√° corriendo
start-dfs.sh

# Crear carpeta temporal
hdfs dfs -mkdir -p /tmp

# Crear warehouse (almac√©n de tablas)
hdfs dfs -mkdir -p /user/hive/warehouse

# Dar permisos de escritura
hdfs dfs -chmod g+w /tmp
hdfs dfs -chmod g+w /user/hive/warehouse

# Verificar
hdfs dfs -ls /user/hive/
```

---

## 25. Configurar hive-site.xml (Metastore)

### üìù Crear Archivo de Configuraci√≥n

```bash
# Crear hive-site.xml
nano /opt/hive/conf/hive-site.xml
```

**Contenido completo:**

```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Configuraci√≥n de Metastore con Derby -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:derby:;databaseName=metastore_db;create=true</value>
        <description>URL de conexi√≥n a la base de datos Derby embebida</description>
    </property>
  
    <!-- Directorio warehouse en HDFS -->
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
        <description>Ubicaci√≥n del warehouse en HDFS</description>
    </property>
  
    <!-- Configuraci√≥n adicional -->
    <property>
        <name>hive.metastore.uris</name>
        <value/>
        <description>URI del metastore (vac√≠o para modo embebido)</description>
    </property>
  
    <property>
        <name>hive.server2.enable.doAs</name>
        <value>false</value>
        <description>Deshabilitar suplantaci√≥n de usuario</description>
    </property>
</configuration>
```

**Guardar:** `Ctrl + O` ‚Üí `Enter` ‚Üí `Ctrl + X`

---

## 26. Inicializar Esquema de Metadatos

### üîß Formatear Base de Datos de Metastore

```bash
# Inicializar esquema con Derby
schematool -initSchema -dbType derby
```

**Salida esperada:**

```
Initialization script completed
schemaTool completed
```

---

### ‚ö†Ô∏è Soluci√≥n de Errores Comunes

#### Error: "schematool: command not found"

```bash
# Verificar PATH
echo $PATH | grep hive

# Si no aparece, recargar .bashrc
source ~/.bashrc
```

#### Error: "metastore_db already exists"

```bash
# Eliminar base de datos antigua
rm -rf metastore_db/

# Reinicializar
schematool -initSchema -dbType derby
```

---

## 27. Ejecutar y Probar Hive

### üöÄ Iniciar Hive

```bash
# Asegurar que HDFS y YARN est√°n corriendo
start-all.sh

# Iniciar consola de Hive
hive
```

**Prompt esperado:**

```
hive>
```

---

### üìä Comandos B√°sicos de HiveQL

#### Ver Bases de Datos

```sql
-- Ver bases de datos disponibles
SHOW DATABASES;

-- Usar base de datos
USE default;
```

---

#### Crear Tabla

```sql
-- Crear tabla simple
CREATE TABLE usuarios (
    id INT,
    nombre STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;
```

---

#### Insertar Datos

```sql
-- Insertar registros individuales
INSERT INTO usuarios VALUES (1, 'Gemini');
INSERT INTO usuarios VALUES (2, 'Hadoop');
INSERT INTO usuarios VALUES (3, 'Spark');
INSERT INTO usuarios VALUES (4, 'Kafka');
INSERT INTO usuarios VALUES (5, 'Flink');
INSERT INTO usuarios VALUES (6, 'HBase');
```

> **Nota:** Cada INSERT ejecuta un job MapReduce (lento). En producci√≥n se cargan archivos masivos.

---

#### Consultar Datos

```sql
-- Ver todos los registros
SELECT * FROM usuarios;

-- Filtrar por ID
SELECT * FROM usuarios WHERE id > 3;

-- Buscar por nombre (LIKE)
SELECT * FROM usuarios WHERE nombre LIKE 'H%';

-- Ordenar resultados
SELECT * FROM usuarios ORDER BY id DESC;

-- Contar registros
SELECT COUNT(*) AS total FROM usuarios;

-- Agregaci√≥n
SELECT COUNT(*) AS cantidad, AVG(id) AS promedio_id FROM usuarios;
```

---

#### Ver Tablas y Estructura

```sql
-- Ver todas las tablas
SHOW TABLES;

-- Ver estructura de tabla
DESCRIBE usuarios;

-- Ver informaci√≥n detallada
DESCRIBE FORMATTED usuarios;
```

---

#### Cargar Datos desde Archivo

```sql
-- Crear archivo CSV local
-- En terminal (fuera de Hive):
echo -e "7,Presto\n8,Druid\n9,Airflow" > /tmp/usuarios_nuevos.csv

-- En Hive:
LOAD DATA LOCAL INPATH '/tmp/usuarios_nuevos.csv' INTO TABLE usuarios;

-- Verificar
SELECT * FROM usuarios;
```

---

#### Crear Tabla desde Consulta (CTAS)

```sql
-- Crear tabla con resultados de consulta
CREATE TABLE usuarios_filtrados AS
SELECT * FROM usuarios WHERE id > 5;

-- Ver resultado
SELECT * FROM usuarios_filtrados;
```

---

### üìÇ Ver Datos F√≠sicos en HDFS

**Salir de Hive:**

```sql
quit;
```

**En terminal:**

```bash
# Ver archivos de la tabla en HDFS
hdfs dfs -ls /user/hive/warehouse/usuarios

# Ver contenido de los archivos
hdfs dfs -cat /user/hive/warehouse/usuarios/*
```

---

### üóëÔ∏è Eliminar Tablas

```sql
-- Eliminar tabla (mantiene datos en HDFS si es EXTERNAL)
DROP TABLE IF EXISTS usuarios;

-- Verificar
SHOW TABLES;
```

---

## üìö Conceptos Clave de Hive

| Concepto                   | Descripci√≥n                                                    |
| -------------------------- | --------------------------------------------------------------- |
| **HiveQL**           | Lenguaje SQL que se traduce a MapReduce/Tez                     |
| **Metastore**        | Base de datos con el cat√°logo de tablas (esquema)              |
| **Warehouse**        | Ubicaci√≥n f√≠sica en HDFS donde se guardan los datos           |
| **Tabla Externa**    | Tabla que referencia datos existentes en HDFS                   |
| **Tabla Gestionada** | Tabla donde Hive controla los datos (se eliminan al hacer DROP) |
| **Particionamiento** | Dividir tablas por columnas para consultas m√°s r√°pidas        |
| **Bucketing**        | Agrupar datos en buckets para optimizar joins                   |

---

---

## üéì RESUMEN Y MEJORES PR√ÅCTICAS

---

### ‚úÖ Checklist de Instalaci√≥n Completa

| Componente             | Verificaci√≥n   | Comando                                 |
| ---------------------- | --------------- | --------------------------------------- |
| **Java 8**       | ‚úÖ Instalado    | `java -version`                       |
| **Hadoop 3.4.0** | ‚úÖ Instalado    | `hadoop version`                      |
| **HDFS**         | ‚úÖ Corriendo    | `jps` ‚Üí NameNode, DataNode           |
| **YARN**         | ‚úÖ Corriendo    | `jps` ‚Üí ResourceManager, NodeManager |
| **Hive 3.1.3**   | ‚úÖ Instalado    | `hive --version`                      |
| **Metastore**    | ‚úÖ Inicializado | `ls metastore_db/`                    |

---

### üîß Comandos Esenciales para el D√≠a a D√≠a

#### Iniciar/Detener Servicios

```bash
# Iniciar todo
start-all.sh

# Detener todo
stop-all.sh

# Ver servicios activos
jps
```

---

#### HDFS

```bash
# Listar archivos
hdfs dfs -ls /ruta

# Subir archivo
hdfs dfs -put archivo.txt /ruta/

# Descargar archivo
hdfs dfs -get /ruta/archivo.txt ./

# Ver contenido
hdfs dfs -cat /ruta/archivo.txt

# Eliminar
hdfs dfs -rm -r /ruta
```

---

#### Hive

```bash
# Iniciar Hive
hive

# Ejecutar query desde archivo
hive -f script.hql

# Ejecutar query desde l√≠nea de comandos
hive -e "SELECT * FROM tabla;"

# Modo silencioso (sin logs)
hive -S -e "SELECT * FROM tabla;"
```

---

### üåê URLs de Monitoreo

| Servicio                       | URL                    | Puerto |
| ------------------------------ | ---------------------- | ------ |
| **HDFS NameNode**        | http://localhost:9870  | 9870   |
| **YARN ResourceManager** | http://localhost:8088  | 8088   |
| **Job History**          | http://localhost:19888 | 19888  |

---

### ‚ö†Ô∏è Errores Comunes y Soluciones

#### 1. "Connection refused" al acceder a interfaces web

```bash
# Verificar que los servicios est√°n corriendo
jps

# Verificar puertos abiertos en firewall
sudo firewall-cmd --list-ports

# Abrir puertos necesarios
sudo firewall-cmd --zone=public --add-port=9870/tcp --permanent
sudo firewall-cmd --zone=public --add-port=8088/tcp --permanent
sudo firewall-cmd --reload
```

---

#### 2. "Address already in use"

```bash
# Ver qu√© proceso usa el puerto
sudo netstat -tulpn | grep 9000

# Detener servicios y reiniciar
stop-all.sh
start-all.sh
```

---

#### 3. "Cannot create directory /user/hive/warehouse"

```bash
# Crear directorio manualmente
hdfs dfs -mkdir -p /user/hive/warehouse

# Dar permisos
hdfs dfs -chmod -R 777 /user/hive/warehouse
```

---

#### 4. Hive no encuentra Guava

```bash
# Copiar librer√≠a correcta
cp /opt/hadoop/hadoop-3.4.0/share/hadoop/common/lib/guava-*.jar /opt/hive/lib/

# Eliminar versi√≥n antigua
rm /opt/hive/lib/guava-19.0.jar
```

---

### üìä Estructura de Directorios Final

```
/opt/
‚îú‚îÄ‚îÄ jdk1.8.0_202/          # Java 8
‚îú‚îÄ‚îÄ hadoop/
‚îÇ   ‚îî‚îÄ‚îÄ hadoop-3.4.0/      # Hadoop
‚îÇ       ‚îú‚îÄ‚îÄ bin/           # Ejecutables
‚îÇ       ‚îú‚îÄ‚îÄ etc/hadoop/    # Configuraci√≥n
‚îÇ       ‚îî‚îÄ‚îÄ share/         # Librer√≠as
‚îî‚îÄ‚îÄ hive/                  # Hive
    ‚îú‚îÄ‚îÄ bin/               # Ejecutables
    ‚îú‚îÄ‚îÄ conf/              # Configuraci√≥n
    ‚îî‚îÄ‚îÄ lib/               # Librer√≠as

/datos/
‚îú‚îÄ‚îÄ namenode/              # Metadatos HDFS
‚îî‚îÄ‚îÄ datanode/              # Datos HDFS

/home/hadoop/              # Home del usuario
‚îî‚îÄ‚îÄ .bashrc                # Variables de entorno
```

---

### üéØ Variables de Entorno Completas

**Archivo:** `/home/hadoop/.bashrc`

```bash
# Configuraci√≥n de Java
export JAVA_HOME=/opt/jdk1.8.0_202
export JRE_HOME=/opt/jdk1.8.0_202/jre

# Configuraci√≥n de Hadoop
export HADOOP_HOME=/opt/hadoop/hadoop-3.4.0

# Configuraci√≥n de Hive
export HIVE_HOME=/opt/hive

# PATH completo
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin
```

---

### üí° Tips de Rendimiento

1. **Aumentar memoria para YARN:**

   - Editar `yarn-site.xml`
   - Aumentar `yarn.nodemanager.resource.memory-mb`
2. **Usar formatos columnares:**

   - ORC o Parquet en lugar de TEXTFILE
   - Mejora rendimiento en consultas anal√≠ticas
3. **Particionar tablas grandes:**

   - `PARTITIONED BY (year, month)`
   - Reduce escaneo de datos
4. **Usar compresi√≥n:**

   - Snappy, Gzip, LZO
   - Reduce espacio en disco y red

---

### üîí Seguridad B√°sica

```bash
# Cambiar permisos de directorios sensibles
hdfs dfs -chmod 700 /user/hadoop

# Deshabilitar permisos globales (para producci√≥n)
hdfs dfs -chmod g-w /tmp
hdfs dfs -chmod g-w /user/hive/warehouse

# Usar Kerberos para autenticaci√≥n (avanzado)
# Configurar en core-site.xml y hdfs-site.xml
```

---

### üìñ Recursos Adicionales

| Recurso                           | URL                                                                      |
| --------------------------------- | ------------------------------------------------------------------------ |
| **Documentaci√≥n Hadoop**   | https://hadoop.apache.org/docs/r3.4.0/                                   |
| **Documentaci√≥n Hive**     | https://cwiki.apache.org/confluence/display/Hive/                        |
| **Playlist YouTube (base)** | https://www.youtube.com/playlist?list=PLG1t8jaLbxA_DG_cmlBYgkGW-TZw5DP3B |
| **Apache Downloads**        | https://downloads.apache.org/                                            |

---

### üéì Pr√≥ximos Pasos

Una vez completada esta gu√≠a, puedes continuar con:

1. **Pr√°ctica con Dataset Real:**

   - Consulta: `Practica_Hadoop_Hive_MovieLens.md`
   - Dataset: MovieLens 100K (100,000 ratings)
2. **Integraci√≥n con Spark:**

   - Instalar Apache Spark sobre Hadoop
   - Usar Spark SQL en lugar de Hive
3. **Cluster Multi-Nodo:**

   - Configurar m√∫ltiples m√°quinas virtuales
   - Simular cluster distribuido real
4. **Herramientas Adicionales:**

   - HBase (base de datos NoSQL)
   - Pig (scripting para Hadoop)
   - Sqoop (importar/exportar desde RDBMS)
   - Flume (ingesti√≥n de logs)

---

<div align="center">

## üéâ ¬°Instalaci√≥n Completada!

**Ecosistema Big Data Funcional en CentOS**

‚úÖ Java 8 OpenJDK configurado
‚úÖ Hadoop 3.4.0 en modo pseudo-distribuido
‚úÖ HDFS operativo con replicaci√≥n
‚úÖ YARN gestionando recursos
‚úÖ MapReduce ejecutando jobs
‚úÖ Hive 3.1.3 con metastore Derby
‚úÖ Interfaces web de monitoreo activas

---

### üìö Para Estudiar

1. Practica con archivos grandes en HDFS
2. Ejecuta diferentes ejemplos de MapReduce
3. Crea tablas particionadas en Hive
4. Monitorea jobs en las interfaces web
5. Experimenta con consultas HiveQL complejas

---

*Gu√≠a de Instalaci√≥n CentOS + Hadoop + Hive*
*Versi√≥n 2.0 - Febrero 2026*
*Curso: Sistemas Inteligentes*

</div>
